{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import config\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MachineLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitData2/'\n",
    "model_dir = '/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitModel'\n",
    "CFP = config.CFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv[1] = 'evaluation'\n",
    "data_dir = '/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitData2/'\n",
    "model_dir = '/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitModel'\n",
    "CFP = config.CFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.ReadConfigFile()\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "from importlib import reload\n",
    "try:\n",
    "    reload(MachineLearning)\n",
    "except NameError:\n",
    "    import MachineLearning\n",
    "try:\n",
    "    reload(MLOnline)\n",
    "except NameError:\n",
    "    import MLOnline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML class restores model from:/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitModel/checkpoint_20000\n",
      "INFO:tensorflow:Restoring parameters from /Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitModel/checkpoint_20000\n"
     ]
    }
   ],
   "source": [
    "ml = MLOnline.ML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGen = MachineLearning.DataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataGen._X\n",
    "Y = dataGen._Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = MachineLearning._X\n",
    "Y = MachineLearning._Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred = ml.evaluate(None,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.019687292857927"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((Ypred - Y) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saver restore from:/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitModel/checkpoint_20000\n",
      "INFO:tensorflow:Restoring parameters from /Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitModel/checkpoint_20000\n",
      "Predict complete, cost [  0] seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26.019687292857927"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.ReadConfigFile()\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "from importlib import reload\n",
    "try:\n",
    "    reload(MachineLearning)\n",
    "except NameError:\n",
    "    import MachineLearning\n",
    "pred_eval,loss_eval = MachineLearning.test()\n",
    "loss_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning Training: global variable initialization...\n",
      "[ Tue Dec  4 21:06:57 2018], epoch [  20], lr[0.10000000] ,loss[0.3259779513]\n",
      "[ Tue Dec  4 21:06:57 2018], validation: iter [  20], loss[0.2835147977]\n",
      "[ Tue Dec  4 21:06:58 2018], epoch [  40], lr[0.10000000] ,loss[0.2970823050]\n",
      "[ Tue Dec  4 21:06:58 2018], validation: iter [  40], loss[0.2593260109]\n",
      "[ Tue Dec  4 21:06:59 2018], epoch [  60], lr[0.10000000] ,loss[0.2897350192]\n",
      "[ Tue Dec  4 21:06:59 2018], validation: iter [  60], loss[0.2529624701]\n",
      "[ Tue Dec  4 21:07:00 2018], epoch [  80], lr[0.10000000] ,loss[0.2477287799]\n",
      "[ Tue Dec  4 21:07:00 2018], validation: iter [  80], loss[0.2107638866]\n",
      "[ Tue Dec  4 21:07:00 2018], epoch [ 100], lr[0.10000000] ,loss[0.2267061919]\n",
      "[ Tue Dec  4 21:07:00 2018], validation: iter [ 100], loss[0.1870429367]\n",
      "[ Tue Dec  4 21:07:01 2018], epoch [ 120], lr[0.10000000] ,loss[0.1726277918]\n",
      "[ Tue Dec  4 21:07:01 2018], validation: iter [ 120], loss[0.1362935752]\n",
      "[ Tue Dec  4 21:07:02 2018], epoch [ 140], lr[0.10000000] ,loss[0.1423933506]\n",
      "[ Tue Dec  4 21:07:02 2018], validation: iter [ 140], loss[0.1048679501]\n",
      "[ Tue Dec  4 21:07:02 2018], epoch [ 160], lr[0.10000000] ,loss[0.1135069653]\n",
      "[ Tue Dec  4 21:07:02 2018], validation: iter [ 160], loss[0.0753349587]\n",
      "[ Tue Dec  4 21:07:03 2018], epoch [ 180], lr[0.10000000] ,loss[0.1066109538]\n",
      "[ Tue Dec  4 21:07:03 2018], validation: iter [ 180], loss[0.0666564777]\n",
      "[ Tue Dec  4 21:07:03 2018], epoch [ 200], lr[0.10000000] ,loss[0.1048524976]\n",
      "[ Tue Dec  4 21:07:03 2018], validation: iter [ 200], loss[0.0649622381]\n",
      "[ Tue Dec  4 21:07:04 2018], epoch [ 220], lr[0.10000000] ,loss[0.1037606969]\n",
      "[ Tue Dec  4 21:07:04 2018], validation: iter [ 220], loss[0.0638875291]\n",
      "[ Tue Dec  4 21:07:05 2018], epoch [ 240], lr[0.10000000] ,loss[0.1021591574]\n",
      "[ Tue Dec  4 21:07:05 2018], validation: iter [ 240], loss[0.0622088686]\n",
      "[ Tue Dec  4 21:07:06 2018], epoch [ 260], lr[0.10000000] ,loss[0.1002854705]\n",
      "[ Tue Dec  4 21:07:06 2018], validation: iter [ 260], loss[0.0594762042]\n",
      "[ Tue Dec  4 21:07:06 2018], epoch [ 280], lr[0.10000000] ,loss[0.0998088717]\n",
      "[ Tue Dec  4 21:07:06 2018], validation: iter [ 280], loss[0.0835349411]\n",
      "[ Tue Dec  4 21:07:07 2018], epoch [ 300], lr[0.10000000] ,loss[0.1235117614]\n",
      "[ Tue Dec  4 21:07:07 2018], validation: iter [ 300], loss[0.0860433802]\n",
      "[ Tue Dec  4 21:07:08 2018], epoch [ 320], lr[0.10000000] ,loss[0.1046173126]\n",
      "[ Tue Dec  4 21:07:08 2018], validation: iter [ 320], loss[0.0626360402]\n",
      "[ Tue Dec  4 21:07:08 2018], epoch [ 340], lr[0.10000000] ,loss[0.0900740251]\n",
      "[ Tue Dec  4 21:07:08 2018], validation: iter [ 340], loss[0.0480614156]\n",
      "[ Tue Dec  4 21:07:09 2018], epoch [ 360], lr[0.10000000] ,loss[0.0880361795]\n",
      "[ Tue Dec  4 21:07:09 2018], validation: iter [ 360], loss[0.0462387875]\n",
      "[ Tue Dec  4 21:07:10 2018], epoch [ 380], lr[0.10000000] ,loss[0.0880884975]\n",
      "[ Tue Dec  4 21:07:10 2018], validation: iter [ 380], loss[0.0479858555]\n",
      "[ Tue Dec  4 21:07:10 2018], epoch [ 400], lr[0.10000000] ,loss[0.0866494104]\n",
      "[ Tue Dec  4 21:07:10 2018], validation: iter [ 400], loss[0.0451453030]\n",
      "[ Tue Dec  4 21:07:11 2018], epoch [ 420], lr[0.10000000] ,loss[0.0850553587]\n",
      "[ Tue Dec  4 21:07:11 2018], validation: iter [ 420], loss[0.0429568402]\n",
      "[ Tue Dec  4 21:07:12 2018], epoch [ 440], lr[0.10000000] ,loss[0.0821726248]\n",
      "[ Tue Dec  4 21:07:12 2018], validation: iter [ 440], loss[0.0393255502]\n",
      "[ Tue Dec  4 21:07:12 2018], epoch [ 460], lr[0.10000000] ,loss[0.0811136886]\n",
      "[ Tue Dec  4 21:07:12 2018], validation: iter [ 460], loss[0.0385308601]\n",
      "[ Tue Dec  4 21:07:13 2018], epoch [ 480], lr[0.10000000] ,loss[0.0808232501]\n",
      "[ Tue Dec  4 21:07:13 2018], validation: iter [ 480], loss[0.0405100808]\n",
      "[ Tue Dec  4 21:07:14 2018], epoch [ 500], lr[0.10000000] ,loss[0.0790445507]\n",
      "[ Tue Dec  4 21:07:14 2018], validation: iter [ 500], loss[0.0364387855]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_500']\n",
      "[ Tue Dec  4 21:07:15 2018], epoch [ 520], lr[0.10000000] ,loss[0.0784153640]\n",
      "[ Tue Dec  4 21:07:15 2018], validation: iter [ 520], loss[0.0353600495]\n",
      "[ Tue Dec  4 21:07:15 2018], epoch [ 540], lr[0.10000000] ,loss[0.0881674662]\n",
      "[ Tue Dec  4 21:07:15 2018], validation: iter [ 540], loss[0.0492172465]\n",
      "[ Tue Dec  4 21:07:16 2018], epoch [ 560], lr[0.10000000] ,loss[0.0795434639]\n",
      "[ Tue Dec  4 21:07:16 2018], validation: iter [ 560], loss[0.0351875052]\n",
      "[ Tue Dec  4 21:07:17 2018], epoch [ 580], lr[0.10000000] ,loss[0.0772188902]\n",
      "[ Tue Dec  4 21:07:17 2018], validation: iter [ 580], loss[0.0341935903]\n",
      "[ Tue Dec  4 21:07:17 2018], epoch [ 600], lr[0.10000000] ,loss[0.0782785863]\n",
      "[ Tue Dec  4 21:07:17 2018], validation: iter [ 600], loss[0.0364834927]\n",
      "[ Tue Dec  4 21:07:18 2018], epoch [ 620], lr[0.10000000] ,loss[0.0780053288]\n",
      "[ Tue Dec  4 21:07:18 2018], validation: iter [ 620], loss[0.0345162340]\n",
      "[ Tue Dec  4 21:07:19 2018], epoch [ 640], lr[0.10000000] ,loss[0.0888181478]\n",
      "[ Tue Dec  4 21:07:19 2018], validation: iter [ 640], loss[0.0526415221]\n",
      "[ Tue Dec  4 21:07:20 2018], epoch [ 660], lr[0.10000000] ,loss[0.0783804134]\n",
      "[ Tue Dec  4 21:07:20 2018], validation: iter [ 660], loss[0.0369201191]\n",
      "[ Tue Dec  4 21:07:20 2018], epoch [ 680], lr[0.10000000] ,loss[0.0773324743]\n",
      "[ Tue Dec  4 21:07:20 2018], validation: iter [ 680], loss[0.0338114984]\n",
      "[ Tue Dec  4 21:07:21 2018], epoch [ 700], lr[0.10000000] ,loss[0.0766243264]\n",
      "[ Tue Dec  4 21:07:21 2018], validation: iter [ 700], loss[0.0333748087]\n",
      "[ Tue Dec  4 21:07:22 2018], epoch [ 720], lr[0.10000000] ,loss[0.0770602226]\n",
      "[ Tue Dec  4 21:07:22 2018], validation: iter [ 720], loss[0.0339018181]\n",
      "[ Tue Dec  4 21:07:22 2018], epoch [ 740], lr[0.10000000] ,loss[0.0768099055]\n",
      "[ Tue Dec  4 21:07:22 2018], validation: iter [ 740], loss[0.0345559455]\n",
      "[ Tue Dec  4 21:07:23 2018], epoch [ 760], lr[0.10000000] ,loss[0.0767304227]\n",
      "[ Tue Dec  4 21:07:23 2018], validation: iter [ 760], loss[0.0331052095]\n",
      "[ Tue Dec  4 21:07:23 2018], epoch [ 780], lr[0.10000000] ,loss[0.0795322731]\n",
      "[ Tue Dec  4 21:07:23 2018], validation: iter [ 780], loss[0.0347077064]\n",
      "[ Tue Dec  4 21:07:24 2018], epoch [ 800], lr[0.10000000] ,loss[0.0765286908]\n",
      "[ Tue Dec  4 21:07:24 2018], validation: iter [ 800], loss[0.0331232622]\n",
      "[ Tue Dec  4 21:07:25 2018], epoch [ 820], lr[0.10000000] ,loss[0.0909614787]\n",
      "[ Tue Dec  4 21:07:25 2018], validation: iter [ 820], loss[0.0421753414]\n",
      "[ Tue Dec  4 21:07:25 2018], epoch [ 840], lr[0.10000000] ,loss[0.0766062587]\n",
      "[ Tue Dec  4 21:07:25 2018], validation: iter [ 840], loss[0.0330995172]\n",
      "[ Tue Dec  4 21:07:26 2018], epoch [ 860], lr[0.10000000] ,loss[0.0766102150]\n",
      "[ Tue Dec  4 21:07:26 2018], validation: iter [ 860], loss[0.0334286094]\n",
      "[ Tue Dec  4 21:07:27 2018], epoch [ 880], lr[0.10000000] ,loss[0.0784044787]\n",
      "[ Tue Dec  4 21:07:27 2018], validation: iter [ 880], loss[0.0356523842]\n",
      "[ Tue Dec  4 21:07:28 2018], epoch [ 900], lr[0.10000000] ,loss[0.0775581077]\n",
      "[ Tue Dec  4 21:07:28 2018], validation: iter [ 900], loss[0.0341771245]\n",
      "[ Tue Dec  4 21:07:28 2018], epoch [ 920], lr[0.10000000] ,loss[0.0758656412]\n",
      "[ Tue Dec  4 21:07:28 2018], validation: iter [ 920], loss[0.0326310880]\n",
      "[ Tue Dec  4 21:07:29 2018], epoch [ 940], lr[0.10000000] ,loss[0.0777517036]\n",
      "[ Tue Dec  4 21:07:29 2018], validation: iter [ 940], loss[0.0335736051]\n",
      "[ Tue Dec  4 21:07:30 2018], epoch [ 960], lr[0.10000000] ,loss[0.0758229196]\n",
      "[ Tue Dec  4 21:07:30 2018], validation: iter [ 960], loss[0.0325661823]\n",
      "[ Tue Dec  4 21:07:30 2018], epoch [ 980], lr[0.10000000] ,loss[0.0839594081]\n",
      "[ Tue Dec  4 21:07:30 2018], validation: iter [ 980], loss[0.0356366374]\n",
      "[ Tue Dec  4 21:07:31 2018], epoch [1000], lr[0.10000000] ,loss[0.0771051645]\n",
      "[ Tue Dec  4 21:07:31 2018], validation: iter [1000], loss[0.0330291875]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_1000']\n",
      "[ Tue Dec  4 21:07:32 2018], epoch [1020], lr[0.10000000] ,loss[0.0757861137]\n",
      "[ Tue Dec  4 21:07:32 2018], validation: iter [1020], loss[0.0324464999]\n",
      "[ Tue Dec  4 21:07:33 2018], epoch [1040], lr[0.10000000] ,loss[0.0756896287]\n",
      "[ Tue Dec  4 21:07:33 2018], validation: iter [1040], loss[0.0324099250]\n",
      "[ Tue Dec  4 21:07:33 2018], epoch [1060], lr[0.10000000] ,loss[0.0785202533]\n",
      "[ Tue Dec  4 21:07:33 2018], validation: iter [1060], loss[0.0382047705]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 21:07:34 2018], epoch [1080], lr[0.10000000] ,loss[0.0758621171]\n",
      "[ Tue Dec  4 21:07:34 2018], validation: iter [1080], loss[0.0327248648]\n",
      "[ Tue Dec  4 21:07:35 2018], epoch [1100], lr[0.10000000] ,loss[0.0756169930]\n",
      "[ Tue Dec  4 21:07:35 2018], validation: iter [1100], loss[0.0322089009]\n",
      "[ Tue Dec  4 21:07:35 2018], epoch [1120], lr[0.10000000] ,loss[0.0776209235]\n",
      "[ Tue Dec  4 21:07:35 2018], validation: iter [1120], loss[0.0344328806]\n",
      "[ Tue Dec  4 21:07:36 2018], epoch [1140], lr[0.10000000] ,loss[0.0759279951]\n",
      "[ Tue Dec  4 21:07:36 2018], validation: iter [1140], loss[0.0324369334]\n",
      "[ Tue Dec  4 21:07:37 2018], epoch [1160], lr[0.10000000] ,loss[0.0756441504]\n",
      "[ Tue Dec  4 21:07:37 2018], validation: iter [1160], loss[0.0321782716]\n",
      "[ Tue Dec  4 21:07:38 2018], epoch [1180], lr[0.10000000] ,loss[0.0758556798]\n",
      "[ Tue Dec  4 21:07:38 2018], validation: iter [1180], loss[0.0331811458]\n",
      "[ Tue Dec  4 21:07:38 2018], epoch [1200], lr[0.10000000] ,loss[0.0764317736]\n",
      "[ Tue Dec  4 21:07:38 2018], validation: iter [1200], loss[0.0330462977]\n",
      "[ Tue Dec  4 21:07:39 2018], epoch [1220], lr[0.10000000] ,loss[0.0780525729]\n",
      "[ Tue Dec  4 21:07:39 2018], validation: iter [1220], loss[0.0354323909]\n",
      "[ Tue Dec  4 21:07:40 2018], epoch [1240], lr[0.10000000] ,loss[0.0778967738]\n",
      "[ Tue Dec  4 21:07:40 2018], validation: iter [1240], loss[0.0330705531]\n",
      "[ Tue Dec  4 21:07:41 2018], epoch [1260], lr[0.10000000] ,loss[0.0753583387]\n",
      "[ Tue Dec  4 21:07:41 2018], validation: iter [1260], loss[0.0321044326]\n",
      "[ Tue Dec  4 21:07:42 2018], epoch [1280], lr[0.10000000] ,loss[0.0769413263]\n",
      "[ Tue Dec  4 21:07:42 2018], validation: iter [1280], loss[0.0330923051]\n",
      "[ Tue Dec  4 21:07:42 2018], epoch [1300], lr[0.10000000] ,loss[0.0754362568]\n",
      "[ Tue Dec  4 21:07:42 2018], validation: iter [1300], loss[0.0319555923]\n",
      "[ Tue Dec  4 21:07:43 2018], epoch [1320], lr[0.10000000] ,loss[0.0934279412]\n",
      "[ Tue Dec  4 21:07:43 2018], validation: iter [1320], loss[0.0549021661]\n",
      "[ Tue Dec  4 21:07:44 2018], epoch [1340], lr[0.10000000] ,loss[0.0765720084]\n",
      "[ Tue Dec  4 21:07:44 2018], validation: iter [1340], loss[0.0346854590]\n",
      "[ Tue Dec  4 21:07:45 2018], epoch [1360], lr[0.10000000] ,loss[0.0758009404]\n",
      "[ Tue Dec  4 21:07:45 2018], validation: iter [1360], loss[0.0321441889]\n",
      "[ Tue Dec  4 21:07:45 2018], epoch [1380], lr[0.10000000] ,loss[0.0755190700]\n",
      "[ Tue Dec  4 21:07:45 2018], validation: iter [1380], loss[0.0320124999]\n",
      "[ Tue Dec  4 21:07:46 2018], epoch [1400], lr[0.10000000] ,loss[0.0812618062]\n",
      "[ Tue Dec  4 21:07:46 2018], validation: iter [1400], loss[0.0391014032]\n",
      "[ Tue Dec  4 21:07:46 2018], epoch [1420], lr[0.10000000] ,loss[0.0757697746]\n",
      "[ Tue Dec  4 21:07:46 2018], validation: iter [1420], loss[0.0324053466]\n",
      "[ Tue Dec  4 21:07:47 2018], epoch [1440], lr[0.10000000] ,loss[0.0777627379]\n",
      "[ Tue Dec  4 21:07:47 2018], validation: iter [1440], loss[0.0357861184]\n",
      "[ Tue Dec  4 21:07:48 2018], epoch [1460], lr[0.10000000] ,loss[0.0764056742]\n",
      "[ Tue Dec  4 21:07:48 2018], validation: iter [1460], loss[0.0332207195]\n",
      "[ Tue Dec  4 21:07:48 2018], epoch [1480], lr[0.10000000] ,loss[0.0761673525]\n",
      "[ Tue Dec  4 21:07:48 2018], validation: iter [1480], loss[0.0327263884]\n",
      "[ Tue Dec  4 21:07:49 2018], epoch [1500], lr[0.10000000] ,loss[0.0771947429]\n",
      "[ Tue Dec  4 21:07:49 2018], validation: iter [1500], loss[0.0331667885]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_1500']\n",
      "[ Tue Dec  4 21:07:50 2018], epoch [1520], lr[0.10000000] ,loss[0.0758786425]\n",
      "[ Tue Dec  4 21:07:50 2018], validation: iter [1520], loss[0.0324608050]\n",
      "[ Tue Dec  4 21:07:51 2018], epoch [1540], lr[0.10000000] ,loss[0.0767090097]\n",
      "[ Tue Dec  4 21:07:51 2018], validation: iter [1540], loss[0.0323808603]\n",
      "[ Tue Dec  4 21:07:51 2018], epoch [1560], lr[0.10000000] ,loss[0.0762638599]\n",
      "[ Tue Dec  4 21:07:51 2018], validation: iter [1560], loss[0.0329024121]\n",
      "[ Tue Dec  4 21:07:52 2018], epoch [1580], lr[0.10000000] ,loss[0.0792278126]\n",
      "[ Tue Dec  4 21:07:52 2018], validation: iter [1580], loss[0.0360224694]\n",
      "[ Tue Dec  4 21:07:52 2018], epoch [1600], lr[0.10000000] ,loss[0.0754523426]\n",
      "[ Tue Dec  4 21:07:52 2018], validation: iter [1600], loss[0.0318521000]\n",
      "[ Tue Dec  4 21:07:53 2018], epoch [1620], lr[0.10000000] ,loss[0.0885557756]\n",
      "[ Tue Dec  4 21:07:53 2018], validation: iter [1620], loss[0.0397284813]\n",
      "[ Tue Dec  4 21:07:54 2018], epoch [1640], lr[0.10000000] ,loss[0.0763997883]\n",
      "[ Tue Dec  4 21:07:54 2018], validation: iter [1640], loss[0.0337421522]\n",
      "[ Tue Dec  4 21:07:54 2018], epoch [1660], lr[0.10000000] ,loss[0.0753771514]\n",
      "[ Tue Dec  4 21:07:54 2018], validation: iter [1660], loss[0.0318749957]\n",
      "[ Tue Dec  4 21:07:55 2018], epoch [1680], lr[0.10000000] ,loss[0.0756967887]\n",
      "[ Tue Dec  4 21:07:55 2018], validation: iter [1680], loss[0.0324874707]\n",
      "[ Tue Dec  4 21:07:56 2018], epoch [1700], lr[0.10000000] ,loss[0.0762424096]\n",
      "[ Tue Dec  4 21:07:56 2018], validation: iter [1700], loss[0.0327878222]\n",
      "[ Tue Dec  4 21:07:56 2018], epoch [1720], lr[0.10000000] ,loss[0.0754190087]\n",
      "[ Tue Dec  4 21:07:56 2018], validation: iter [1720], loss[0.0322018303]\n",
      "[ Tue Dec  4 21:07:57 2018], epoch [1740], lr[0.10000000] ,loss[0.0754201487]\n",
      "[ Tue Dec  4 21:07:57 2018], validation: iter [1740], loss[0.0318656340]\n",
      "[ Tue Dec  4 21:07:58 2018], epoch [1760], lr[0.10000000] ,loss[0.0816749707]\n",
      "[ Tue Dec  4 21:07:58 2018], validation: iter [1760], loss[0.0372021236]\n",
      "[ Tue Dec  4 21:07:58 2018], epoch [1780], lr[0.10000000] ,loss[0.0759582520]\n",
      "[ Tue Dec  4 21:07:58 2018], validation: iter [1780], loss[0.0319553316]\n",
      "[ Tue Dec  4 21:07:59 2018], epoch [1800], lr[0.10000000] ,loss[0.0753100961]\n",
      "[ Tue Dec  4 21:07:59 2018], validation: iter [1800], loss[0.0319209993]\n",
      "[ Tue Dec  4 21:08:00 2018], epoch [1820], lr[0.10000000] ,loss[0.0754238218]\n",
      "[ Tue Dec  4 21:08:00 2018], validation: iter [1820], loss[0.0321102068]\n",
      "[ Tue Dec  4 21:08:00 2018], epoch [1840], lr[0.10000000] ,loss[0.0765726939]\n",
      "[ Tue Dec  4 21:08:00 2018], validation: iter [1840], loss[0.0341730416]\n",
      "[ Tue Dec  4 21:08:01 2018], epoch [1860], lr[0.10000000] ,loss[0.0764196813]\n",
      "[ Tue Dec  4 21:08:01 2018], validation: iter [1860], loss[0.0325824060]\n",
      "[ Tue Dec  4 21:08:02 2018], epoch [1880], lr[0.10000000] ,loss[0.0764990523]\n",
      "[ Tue Dec  4 21:08:02 2018], validation: iter [1880], loss[0.0339837223]\n",
      "[ Tue Dec  4 21:08:02 2018], epoch [1900], lr[0.10000000] ,loss[0.0768420175]\n",
      "[ Tue Dec  4 21:08:02 2018], validation: iter [1900], loss[0.0341581218]\n",
      "[ Tue Dec  4 21:08:03 2018], epoch [1920], lr[0.10000000] ,loss[0.0755851418]\n",
      "[ Tue Dec  4 21:08:03 2018], validation: iter [1920], loss[0.0321844667]\n",
      "[ Tue Dec  4 21:08:03 2018], epoch [1940], lr[0.10000000] ,loss[0.0799979046]\n",
      "[ Tue Dec  4 21:08:03 2018], validation: iter [1940], loss[0.0366903357]\n",
      "[ Tue Dec  4 21:08:04 2018], epoch [1960], lr[0.10000000] ,loss[0.0759245232]\n",
      "[ Tue Dec  4 21:08:04 2018], validation: iter [1960], loss[0.0326295123]\n",
      "[ Tue Dec  4 21:08:04 2018], epoch [1980], lr[0.10000000] ,loss[0.0752810612]\n",
      "[ Tue Dec  4 21:08:04 2018], validation: iter [1980], loss[0.0318765827]\n",
      "[ Tue Dec  4 21:08:05 2018], epoch [2000], lr[0.10000000] ,loss[0.0822670832]\n",
      "[ Tue Dec  4 21:08:05 2018], validation: iter [2000], loss[0.0384136140]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_2000']\n",
      "[ Tue Dec  4 21:08:06 2018], epoch [2020], lr[0.05000000] ,loss[0.0766089559]\n",
      "[ Tue Dec  4 21:08:06 2018], validation: iter [2020], loss[0.0320945010]\n",
      "[ Tue Dec  4 21:08:07 2018], epoch [2040], lr[0.05000000] ,loss[0.0752808526]\n",
      "[ Tue Dec  4 21:08:07 2018], validation: iter [2040], loss[0.0317352116]\n",
      "[ Tue Dec  4 21:08:07 2018], epoch [2060], lr[0.05000000] ,loss[0.0752233565]\n",
      "[ Tue Dec  4 21:08:07 2018], validation: iter [2060], loss[0.0316891372]\n",
      "[ Tue Dec  4 21:08:08 2018], epoch [2080], lr[0.05000000] ,loss[0.0752202943]\n",
      "[ Tue Dec  4 21:08:08 2018], validation: iter [2080], loss[0.0316940434]\n",
      "[ Tue Dec  4 21:08:08 2018], epoch [2100], lr[0.05000000] ,loss[0.0752084181]\n",
      "[ Tue Dec  4 21:08:08 2018], validation: iter [2100], loss[0.0316828229]\n",
      "[ Tue Dec  4 21:08:09 2018], epoch [2120], lr[0.05000000] ,loss[0.0752060860]\n",
      "[ Tue Dec  4 21:08:09 2018], validation: iter [2120], loss[0.0316795260]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 21:08:10 2018], epoch [2140], lr[0.05000000] ,loss[0.0752031803]\n",
      "[ Tue Dec  4 21:08:10 2018], validation: iter [2140], loss[0.0316767469]\n",
      "[ Tue Dec  4 21:08:10 2018], epoch [2160], lr[0.05000000] ,loss[0.0751983225]\n",
      "[ Tue Dec  4 21:08:10 2018], validation: iter [2160], loss[0.0316704251]\n",
      "[ Tue Dec  4 21:08:11 2018], epoch [2180], lr[0.05000000] ,loss[0.0751933679]\n",
      "[ Tue Dec  4 21:08:11 2018], validation: iter [2180], loss[0.0316641256]\n",
      "[ Tue Dec  4 21:08:12 2018], epoch [2200], lr[0.05000000] ,loss[0.0751885623]\n",
      "[ Tue Dec  4 21:08:12 2018], validation: iter [2200], loss[0.0316565409]\n",
      "[ Tue Dec  4 21:08:12 2018], epoch [2220], lr[0.05000000] ,loss[0.0751825422]\n",
      "[ Tue Dec  4 21:08:12 2018], validation: iter [2220], loss[0.0316493325]\n",
      "[ Tue Dec  4 21:08:13 2018], epoch [2240], lr[0.05000000] ,loss[0.0751757994]\n",
      "[ Tue Dec  4 21:08:13 2018], validation: iter [2240], loss[0.0316409618]\n",
      "[ Tue Dec  4 21:08:13 2018], epoch [2260], lr[0.05000000] ,loss[0.0751714781]\n",
      "[ Tue Dec  4 21:08:13 2018], validation: iter [2260], loss[0.0316344276]\n",
      "[ Tue Dec  4 21:08:14 2018], epoch [2280], lr[0.05000000] ,loss[0.0751662031]\n",
      "[ Tue Dec  4 21:08:14 2018], validation: iter [2280], loss[0.0316281579]\n",
      "[ Tue Dec  4 21:08:15 2018], epoch [2300], lr[0.05000000] ,loss[0.0751627311]\n",
      "[ Tue Dec  4 21:08:15 2018], validation: iter [2300], loss[0.0316214375]\n",
      "[ Tue Dec  4 21:08:15 2018], epoch [2320], lr[0.05000000] ,loss[0.0751591027]\n",
      "[ Tue Dec  4 21:08:15 2018], validation: iter [2320], loss[0.0316161998]\n",
      "[ Tue Dec  4 21:08:16 2018], epoch [2340], lr[0.05000000] ,loss[0.0751547068]\n",
      "[ Tue Dec  4 21:08:16 2018], validation: iter [2340], loss[0.0316104442]\n",
      "[ Tue Dec  4 21:08:17 2018], epoch [2360], lr[0.05000000] ,loss[0.0751517564]\n",
      "[ Tue Dec  4 21:08:17 2018], validation: iter [2360], loss[0.0316058546]\n",
      "[ Tue Dec  4 21:08:17 2018], epoch [2380], lr[0.05000000] ,loss[0.0751492009]\n",
      "[ Tue Dec  4 21:08:17 2018], validation: iter [2380], loss[0.0316006616]\n",
      "[ Tue Dec  4 21:08:18 2018], epoch [2400], lr[0.05000000] ,loss[0.0751450881]\n",
      "[ Tue Dec  4 21:08:18 2018], validation: iter [2400], loss[0.0315938704]\n",
      "[ Tue Dec  4 21:08:18 2018], epoch [2420], lr[0.05000000] ,loss[0.0751411617]\n",
      "[ Tue Dec  4 21:08:18 2018], validation: iter [2420], loss[0.0315882415]\n",
      "[ Tue Dec  4 21:08:19 2018], epoch [2440], lr[0.05000000] ,loss[0.0751385093]\n",
      "[ Tue Dec  4 21:08:19 2018], validation: iter [2440], loss[0.0315833613]\n",
      "[ Tue Dec  4 21:08:20 2018], epoch [2460], lr[0.05000000] ,loss[0.0751341283]\n",
      "[ Tue Dec  4 21:08:20 2018], validation: iter [2460], loss[0.0315773524]\n",
      "[ Tue Dec  4 21:08:21 2018], epoch [2480], lr[0.05000000] ,loss[0.0751314387]\n",
      "[ Tue Dec  4 21:08:21 2018], validation: iter [2480], loss[0.0315719172]\n",
      "[ Tue Dec  4 21:08:21 2018], epoch [2500], lr[0.05000000] ,loss[0.0751284212]\n",
      "[ Tue Dec  4 21:08:21 2018], validation: iter [2500], loss[0.0315660499]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_2500']\n",
      "[ Tue Dec  4 21:08:22 2018], epoch [2520], lr[0.05000000] ,loss[0.0751252696]\n",
      "[ Tue Dec  4 21:08:22 2018], validation: iter [2520], loss[0.0315609947]\n",
      "[ Tue Dec  4 21:08:23 2018], epoch [2540], lr[0.05000000] ,loss[0.0751216784]\n",
      "[ Tue Dec  4 21:08:23 2018], validation: iter [2540], loss[0.0315548927]\n",
      "[ Tue Dec  4 21:08:24 2018], epoch [2560], lr[0.05000000] ,loss[0.0751167983]\n",
      "[ Tue Dec  4 21:08:24 2018], validation: iter [2560], loss[0.0315473676]\n",
      "[ Tue Dec  4 21:08:24 2018], epoch [2580], lr[0.05000000] ,loss[0.0751145110]\n",
      "[ Tue Dec  4 21:08:24 2018], validation: iter [2580], loss[0.0315428302]\n",
      "[ Tue Dec  4 21:08:25 2018], epoch [2600], lr[0.05000000] ,loss[0.0751128197]\n",
      "[ Tue Dec  4 21:08:25 2018], validation: iter [2600], loss[0.0315390751]\n",
      "[ Tue Dec  4 21:08:25 2018], epoch [2620], lr[0.05000000] ,loss[0.0751107410]\n",
      "[ Tue Dec  4 21:08:25 2018], validation: iter [2620], loss[0.0315336175]\n",
      "[ Tue Dec  4 21:08:26 2018], epoch [2640], lr[0.05000000] ,loss[0.0751072392]\n",
      "[ Tue Dec  4 21:08:26 2018], validation: iter [2640], loss[0.0315282866]\n",
      "[ Tue Dec  4 21:08:26 2018], epoch [2660], lr[0.05000000] ,loss[0.0751063526]\n",
      "[ Tue Dec  4 21:08:26 2018], validation: iter [2660], loss[0.0315252207]\n",
      "[ Tue Dec  4 21:08:27 2018], epoch [2680], lr[0.05000000] ,loss[0.0751046166]\n",
      "[ Tue Dec  4 21:08:27 2018], validation: iter [2680], loss[0.0315212458]\n",
      "[ Tue Dec  4 21:08:27 2018], epoch [2700], lr[0.05000000] ,loss[0.0751020685]\n",
      "[ Tue Dec  4 21:08:27 2018], validation: iter [2700], loss[0.0315160342]\n",
      "[ Tue Dec  4 21:08:28 2018], epoch [2720], lr[0.05000000] ,loss[0.0750992894]\n",
      "[ Tue Dec  4 21:08:28 2018], validation: iter [2720], loss[0.0315106846]\n",
      "[ Tue Dec  4 21:08:29 2018], epoch [2740], lr[0.05000000] ,loss[0.0750903711]\n",
      "[ Tue Dec  4 21:08:29 2018], validation: iter [2740], loss[0.0314992219]\n",
      "[ Tue Dec  4 21:08:30 2018], epoch [2760], lr[0.05000000] ,loss[0.0750892684]\n",
      "[ Tue Dec  4 21:08:30 2018], validation: iter [2760], loss[0.0314954892]\n",
      "[ Tue Dec  4 21:08:30 2018], epoch [2780], lr[0.05000000] ,loss[0.0750878528]\n",
      "[ Tue Dec  4 21:08:30 2018], validation: iter [2780], loss[0.0314909481]\n",
      "[ Tue Dec  4 21:08:31 2018], epoch [2800], lr[0.05000000] ,loss[0.0750879198]\n",
      "[ Tue Dec  4 21:08:31 2018], validation: iter [2800], loss[0.0314896218]\n",
      "[ Tue Dec  4 21:08:32 2018], epoch [2820], lr[0.05000000] ,loss[0.0750868917]\n",
      "[ Tue Dec  4 21:08:32 2018], validation: iter [2820], loss[0.0314870998]\n",
      "[ Tue Dec  4 21:08:33 2018], epoch [2840], lr[0.05000000] ,loss[0.0750858709]\n",
      "[ Tue Dec  4 21:08:33 2018], validation: iter [2840], loss[0.0314848833]\n",
      "[ Tue Dec  4 21:08:33 2018], epoch [2860], lr[0.05000000] ,loss[0.0750852600]\n",
      "[ Tue Dec  4 21:08:33 2018], validation: iter [2860], loss[0.0314826518]\n",
      "[ Tue Dec  4 21:08:34 2018], epoch [2880], lr[0.05000000] ,loss[0.0750840306]\n",
      "[ Tue Dec  4 21:08:34 2018], validation: iter [2880], loss[0.0314802378]\n",
      "[ Tue Dec  4 21:08:35 2018], epoch [2900], lr[0.05000000] ,loss[0.0750828162]\n",
      "[ Tue Dec  4 21:08:35 2018], validation: iter [2900], loss[0.0314769372]\n",
      "[ Tue Dec  4 21:08:35 2018], epoch [2920], lr[0.05000000] ,loss[0.0750816688]\n",
      "[ Tue Dec  4 21:08:35 2018], validation: iter [2920], loss[0.0314741172]\n",
      "[ Tue Dec  4 21:08:36 2018], epoch [2940], lr[0.05000000] ,loss[0.0750795677]\n",
      "[ Tue Dec  4 21:08:36 2018], validation: iter [2940], loss[0.0314712748]\n",
      "[ Tue Dec  4 21:08:37 2018], epoch [2960], lr[0.05000000] ,loss[0.0750787780]\n",
      "[ Tue Dec  4 21:08:37 2018], validation: iter [2960], loss[0.0314681605]\n",
      "[ Tue Dec  4 21:08:37 2018], epoch [2980], lr[0.05000000] ,loss[0.0750779584]\n",
      "[ Tue Dec  4 21:08:37 2018], validation: iter [2980], loss[0.0314663537]\n",
      "[ Tue Dec  4 21:08:38 2018], epoch [3000], lr[0.05000000] ,loss[0.0750765726]\n",
      "[ Tue Dec  4 21:08:38 2018], validation: iter [3000], loss[0.0314630084]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_3000']\n",
      "[ Tue Dec  4 21:08:39 2018], epoch [3020], lr[0.05000000] ,loss[0.0750745907]\n",
      "[ Tue Dec  4 21:08:39 2018], validation: iter [3020], loss[0.0314594880]\n",
      "[ Tue Dec  4 21:08:39 2018], epoch [3040], lr[0.05000000] ,loss[0.0750736818]\n",
      "[ Tue Dec  4 21:08:39 2018], validation: iter [3040], loss[0.0314565785]\n",
      "[ Tue Dec  4 21:08:40 2018], epoch [3060], lr[0.05000000] ,loss[0.0750730708]\n",
      "[ Tue Dec  4 21:08:40 2018], validation: iter [3060], loss[0.0314537175]\n",
      "[ Tue Dec  4 21:08:41 2018], epoch [3080], lr[0.05000000] ,loss[0.0750717744]\n",
      "[ Tue Dec  4 21:08:41 2018], validation: iter [3080], loss[0.0314509682]\n",
      "[ Tue Dec  4 21:08:41 2018], epoch [3100], lr[0.05000000] ,loss[0.0750704333]\n",
      "[ Tue Dec  4 21:08:41 2018], validation: iter [3100], loss[0.0314477012]\n",
      "[ Tue Dec  4 21:08:42 2018], epoch [3120], lr[0.05000000] ,loss[0.0750700384]\n",
      "[ Tue Dec  4 21:08:42 2018], validation: iter [3120], loss[0.0314455964]\n",
      "[ Tue Dec  4 21:08:42 2018], epoch [3140], lr[0.05000000] ,loss[0.0750694275]\n",
      "[ Tue Dec  4 21:08:42 2018], validation: iter [3140], loss[0.0314424373]\n",
      "[ Tue Dec  4 21:08:43 2018], epoch [3160], lr[0.05000000] ,loss[0.0750678480]\n",
      "[ Tue Dec  4 21:08:43 2018], validation: iter [3160], loss[0.0314391814]\n",
      "[ Tue Dec  4 21:08:44 2018], epoch [3180], lr[0.05000000] ,loss[0.0750671327]\n",
      "[ Tue Dec  4 21:08:44 2018], validation: iter [3180], loss[0.0314368792]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 21:08:44 2018], epoch [3200], lr[0.05000000] ,loss[0.0750651285]\n",
      "[ Tue Dec  4 21:08:44 2018], validation: iter [3200], loss[0.0314321220]\n",
      "[ Tue Dec  4 21:08:45 2018], epoch [3220], lr[0.05000000] ,loss[0.0750646815]\n",
      "[ Tue Dec  4 21:08:45 2018], validation: iter [3220], loss[0.0314309038]\n",
      "[ Tue Dec  4 21:08:46 2018], epoch [3240], lr[0.05000000] ,loss[0.0756795332]\n",
      "[ Tue Dec  4 21:08:46 2018], validation: iter [3240], loss[0.0325889960]\n",
      "[ Tue Dec  4 21:08:46 2018], epoch [3260], lr[0.05000000] ,loss[0.0767543241]\n",
      "[ Tue Dec  4 21:08:46 2018], validation: iter [3260], loss[0.0322622992]\n",
      "[ Tue Dec  4 21:08:47 2018], epoch [3280], lr[0.05000000] ,loss[0.0752804279]\n",
      "[ Tue Dec  4 21:08:47 2018], validation: iter [3280], loss[0.0315631777]\n",
      "[ Tue Dec  4 21:08:48 2018], epoch [3300], lr[0.05000000] ,loss[0.0750895813]\n",
      "[ Tue Dec  4 21:08:48 2018], validation: iter [3300], loss[0.0314611271]\n",
      "[ Tue Dec  4 21:08:49 2018], epoch [3320], lr[0.05000000] ,loss[0.0750884265]\n",
      "[ Tue Dec  4 21:08:49 2018], validation: iter [3320], loss[0.0314532332]\n",
      "[ Tue Dec  4 21:08:49 2018], epoch [3340], lr[0.05000000] ,loss[0.0750808045]\n",
      "[ Tue Dec  4 21:08:49 2018], validation: iter [3340], loss[0.0314240158]\n",
      "[ Tue Dec  4 21:08:50 2018], epoch [3360], lr[0.05000000] ,loss[0.0797998682]\n",
      "[ Tue Dec  4 21:08:50 2018], validation: iter [3360], loss[0.0368041247]\n",
      "[ Tue Dec  4 21:08:51 2018], epoch [3380], lr[0.05000000] ,loss[0.0754764229]\n",
      "[ Tue Dec  4 21:08:51 2018], validation: iter [3380], loss[0.0319983289]\n",
      "[ Tue Dec  4 21:08:52 2018], epoch [3400], lr[0.05000000] ,loss[0.0750811249]\n",
      "[ Tue Dec  4 21:08:52 2018], validation: iter [3400], loss[0.0314805470]\n",
      "[ Tue Dec  4 21:08:52 2018], epoch [3420], lr[0.05000000] ,loss[0.0750717893]\n",
      "[ Tue Dec  4 21:08:52 2018], validation: iter [3420], loss[0.0314402990]\n",
      "[ Tue Dec  4 21:08:53 2018], epoch [3440], lr[0.05000000] ,loss[0.0750768408]\n",
      "[ Tue Dec  4 21:08:53 2018], validation: iter [3440], loss[0.0314071551]\n",
      "[ Tue Dec  4 21:08:54 2018], epoch [3460], lr[0.05000000] ,loss[0.0750794783]\n",
      "[ Tue Dec  4 21:08:54 2018], validation: iter [3460], loss[0.0314073041]\n",
      "[ Tue Dec  4 21:08:54 2018], epoch [3480], lr[0.05000000] ,loss[0.0790015087]\n",
      "[ Tue Dec  4 21:08:54 2018], validation: iter [3480], loss[0.0358685888]\n",
      "[ Tue Dec  4 21:08:55 2018], epoch [3500], lr[0.05000000] ,loss[0.0755234733]\n",
      "[ Tue Dec  4 21:08:55 2018], validation: iter [3500], loss[0.0316880718]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_3500']\n",
      "[ Tue Dec  4 21:08:56 2018], epoch [3520], lr[0.05000000] ,loss[0.0750561804]\n",
      "[ Tue Dec  4 21:08:56 2018], validation: iter [3520], loss[0.0314640626]\n",
      "[ Tue Dec  4 21:08:56 2018], epoch [3540], lr[0.05000000] ,loss[0.0750873387]\n",
      "[ Tue Dec  4 21:08:56 2018], validation: iter [3540], loss[0.0314052142]\n",
      "[ Tue Dec  4 21:08:57 2018], epoch [3560], lr[0.05000000] ,loss[0.0750642866]\n",
      "[ Tue Dec  4 21:08:57 2018], validation: iter [3560], loss[0.0314312354]\n",
      "[ Tue Dec  4 21:08:58 2018], epoch [3580], lr[0.05000000] ,loss[0.0753761083]\n",
      "[ Tue Dec  4 21:08:58 2018], validation: iter [3580], loss[0.0319982320]\n",
      "[ Tue Dec  4 21:08:59 2018], epoch [3600], lr[0.05000000] ,loss[0.0763990507]\n",
      "[ Tue Dec  4 21:08:59 2018], validation: iter [3600], loss[0.0320062004]\n",
      "[ Tue Dec  4 21:08:59 2018], epoch [3620], lr[0.05000000] ,loss[0.0751227513]\n",
      "[ Tue Dec  4 21:08:59 2018], validation: iter [3620], loss[0.0313886143]\n",
      "[ Tue Dec  4 21:09:00 2018], epoch [3640], lr[0.05000000] ,loss[0.0751106143]\n",
      "[ Tue Dec  4 21:09:00 2018], validation: iter [3640], loss[0.0314994641]\n",
      "[ Tue Dec  4 21:09:01 2018], epoch [3660], lr[0.05000000] ,loss[0.0757544786]\n",
      "[ Tue Dec  4 21:09:01 2018], validation: iter [3660], loss[0.0323002003]\n",
      "[ Tue Dec  4 21:09:01 2018], epoch [3680], lr[0.05000000] ,loss[0.0752153993]\n",
      "[ Tue Dec  4 21:09:01 2018], validation: iter [3680], loss[0.0315755941]\n",
      "[ Tue Dec  4 21:09:02 2018], epoch [3700], lr[0.05000000] ,loss[0.0768798888]\n",
      "[ Tue Dec  4 21:09:02 2018], validation: iter [3700], loss[0.0332710296]\n",
      "[ Tue Dec  4 21:09:02 2018], epoch [3720], lr[0.05000000] ,loss[0.0751766264]\n",
      "[ Tue Dec  4 21:09:02 2018], validation: iter [3720], loss[0.0315026008]\n",
      "[ Tue Dec  4 21:09:03 2018], epoch [3740], lr[0.05000000] ,loss[0.0751242861]\n",
      "[ Tue Dec  4 21:09:03 2018], validation: iter [3740], loss[0.0314979441]\n",
      "[ Tue Dec  4 21:09:03 2018], epoch [3760], lr[0.05000000] ,loss[0.0751652047]\n",
      "[ Tue Dec  4 21:09:03 2018], validation: iter [3760], loss[0.0314348675]\n",
      "[ Tue Dec  4 21:09:04 2018], epoch [3780], lr[0.05000000] ,loss[0.0761139840]\n",
      "[ Tue Dec  4 21:09:04 2018], validation: iter [3780], loss[0.0317564420]\n",
      "[ Tue Dec  4 21:09:05 2018], epoch [3800], lr[0.05000000] ,loss[0.0750823691]\n",
      "[ Tue Dec  4 21:09:05 2018], validation: iter [3800], loss[0.0314084217]\n",
      "[ Tue Dec  4 21:09:06 2018], epoch [3820], lr[0.05000000] ,loss[0.0751754418]\n",
      "[ Tue Dec  4 21:09:06 2018], validation: iter [3820], loss[0.0314492173]\n",
      "[ Tue Dec  4 21:09:07 2018], epoch [3840], lr[0.05000000] ,loss[0.0773252770]\n",
      "[ Tue Dec  4 21:09:07 2018], validation: iter [3840], loss[0.0337185189]\n",
      "[ Tue Dec  4 21:09:07 2018], epoch [3860], lr[0.05000000] ,loss[0.0752603263]\n",
      "[ Tue Dec  4 21:09:07 2018], validation: iter [3860], loss[0.0315824561]\n",
      "[ Tue Dec  4 21:09:08 2018], epoch [3880], lr[0.05000000] ,loss[0.0751211867]\n",
      "[ Tue Dec  4 21:09:08 2018], validation: iter [3880], loss[0.0313854627]\n",
      "[ Tue Dec  4 21:09:09 2018], epoch [3900], lr[0.05000000] ,loss[0.0750569701]\n",
      "[ Tue Dec  4 21:09:09 2018], validation: iter [3900], loss[0.0314007066]\n",
      "[ Tue Dec  4 21:09:09 2018], epoch [3920], lr[0.05000000] ,loss[0.0792158842]\n",
      "[ Tue Dec  4 21:09:09 2018], validation: iter [3920], loss[0.0340820812]\n",
      "[ Tue Dec  4 21:09:10 2018], epoch [3940], lr[0.05000000] ,loss[0.0758169815]\n",
      "[ Tue Dec  4 21:09:10 2018], validation: iter [3940], loss[0.0318769999]\n",
      "[ Tue Dec  4 21:09:11 2018], epoch [3960], lr[0.05000000] ,loss[0.0751686692]\n",
      "[ Tue Dec  4 21:09:11 2018], validation: iter [3960], loss[0.0314060338]\n",
      "[ Tue Dec  4 21:09:12 2018], epoch [3980], lr[0.05000000] ,loss[0.0750521347]\n",
      "[ Tue Dec  4 21:09:12 2018], validation: iter [3980], loss[0.0313668326]\n",
      "[ Tue Dec  4 21:09:12 2018], epoch [4000], lr[0.05000000] ,loss[0.0750714689]\n",
      "[ Tue Dec  4 21:09:12 2018], validation: iter [4000], loss[0.0313555263]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_4000']\n",
      "[ Tue Dec  4 21:09:13 2018], epoch [4020], lr[0.02500000] ,loss[0.0750464201]\n",
      "[ Tue Dec  4 21:09:13 2018], validation: iter [4020], loss[0.0313554257]\n",
      "[ Tue Dec  4 21:09:13 2018], epoch [4040], lr[0.02500000] ,loss[0.0750440508]\n",
      "[ Tue Dec  4 21:09:13 2018], validation: iter [4040], loss[0.0313552432]\n",
      "[ Tue Dec  4 21:09:14 2018], epoch [4060], lr[0.02500000] ,loss[0.0750412792]\n",
      "[ Tue Dec  4 21:09:14 2018], validation: iter [4060], loss[0.0313538052]\n",
      "[ Tue Dec  4 21:09:14 2018], epoch [4080], lr[0.02500000] ,loss[0.0750406832]\n",
      "[ Tue Dec  4 21:09:14 2018], validation: iter [4080], loss[0.0313510895]\n",
      "[ Tue Dec  4 21:09:15 2018], epoch [4100], lr[0.02500000] ,loss[0.0750390291]\n",
      "[ Tue Dec  4 21:09:15 2018], validation: iter [4100], loss[0.0313483328]\n",
      "[ Tue Dec  4 21:09:15 2018], epoch [4120], lr[0.02500000] ,loss[0.0750373676]\n",
      "[ Tue Dec  4 21:09:15 2018], validation: iter [4120], loss[0.0313457623]\n",
      "[ Tue Dec  4 21:09:16 2018], epoch [4140], lr[0.02500000] ,loss[0.0750357285]\n",
      "[ Tue Dec  4 21:09:16 2018], validation: iter [4140], loss[0.0313430093]\n",
      "[ Tue Dec  4 21:09:16 2018], epoch [4160], lr[0.02500000] ,loss[0.0750341639]\n",
      "[ Tue Dec  4 21:09:16 2018], validation: iter [4160], loss[0.0313403457]\n",
      "[ Tue Dec  4 21:09:17 2018], epoch [4180], lr[0.02500000] ,loss[0.0750326365]\n",
      "[ Tue Dec  4 21:09:17 2018], validation: iter [4180], loss[0.0313377790]\n",
      "[ Tue Dec  4 21:09:17 2018], epoch [4200], lr[0.02500000] ,loss[0.0750313178]\n",
      "[ Tue Dec  4 21:09:17 2018], validation: iter [4200], loss[0.0313357078]\n",
      "[ Tue Dec  4 21:09:18 2018], epoch [4220], lr[0.02500000] ,loss[0.0750298500]\n",
      "[ Tue Dec  4 21:09:18 2018], validation: iter [4220], loss[0.0313330144]\n",
      "[ Tue Dec  4 21:09:19 2018], epoch [4240], lr[0.02500000] ,loss[0.0750282481]\n",
      "[ Tue Dec  4 21:09:19 2018], validation: iter [4240], loss[0.0313307866]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 21:09:19 2018], epoch [4260], lr[0.02500000] ,loss[0.0750272125]\n",
      "[ Tue Dec  4 21:09:19 2018], validation: iter [4260], loss[0.0313287117]\n",
      "[ Tue Dec  4 21:09:20 2018], epoch [4280], lr[0.02500000] ,loss[0.0750261769]\n",
      "[ Tue Dec  4 21:09:20 2018], validation: iter [4280], loss[0.0313265473]\n",
      "[ Tue Dec  4 21:09:20 2018], epoch [4300], lr[0.02500000] ,loss[0.0750246197]\n",
      "[ Tue Dec  4 21:09:20 2018], validation: iter [4300], loss[0.0313240997]\n",
      "[ Tue Dec  4 21:09:21 2018], epoch [4320], lr[0.02500000] ,loss[0.0750238895]\n",
      "[ Tue Dec  4 21:09:21 2018], validation: iter [4320], loss[0.0313219838]\n",
      "[ Tue Dec  4 21:09:21 2018], epoch [4340], lr[0.02500000] ,loss[0.0750223249]\n",
      "[ Tue Dec  4 21:09:21 2018], validation: iter [4340], loss[0.0313195586]\n",
      "[ Tue Dec  4 21:09:22 2018], epoch [4360], lr[0.02500000] ,loss[0.0750212818]\n",
      "[ Tue Dec  4 21:09:22 2018], validation: iter [4360], loss[0.0313176438]\n",
      "[ Tue Dec  4 21:09:22 2018], epoch [4380], lr[0.02500000] ,loss[0.0750199407]\n",
      "[ Tue Dec  4 21:09:22 2018], validation: iter [4380], loss[0.0313148536]\n",
      "[ Tue Dec  4 21:09:23 2018], epoch [4400], lr[0.02500000] ,loss[0.0750187337]\n",
      "[ Tue Dec  4 21:09:23 2018], validation: iter [4400], loss[0.0313128941]\n",
      "[ Tue Dec  4 21:09:23 2018], epoch [4420], lr[0.02500000] ,loss[0.0750173256]\n",
      "[ Tue Dec  4 21:09:23 2018], validation: iter [4420], loss[0.0313106291]\n",
      "[ Tue Dec  4 21:09:24 2018], epoch [4440], lr[0.02500000] ,loss[0.0750166178]\n",
      "[ Tue Dec  4 21:09:24 2018], validation: iter [4440], loss[0.0313090421]\n",
      "[ Tue Dec  4 21:09:24 2018], epoch [4460], lr[0.02500000] ,loss[0.0750155225]\n",
      "[ Tue Dec  4 21:09:24 2018], validation: iter [4460], loss[0.0313067026]\n",
      "[ Tue Dec  4 21:09:25 2018], epoch [4480], lr[0.02500000] ,loss[0.0750150010]\n",
      "[ Tue Dec  4 21:09:25 2018], validation: iter [4480], loss[0.0313051529]\n",
      "[ Tue Dec  4 21:09:25 2018], epoch [4500], lr[0.02500000] ,loss[0.0750139728]\n",
      "[ Tue Dec  4 21:09:25 2018], validation: iter [4500], loss[0.0313027650]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_4500']\n",
      "[ Tue Dec  4 21:09:26 2018], epoch [4520], lr[0.02500000] ,loss[0.0750135779]\n",
      "[ Tue Dec  4 21:09:26 2018], validation: iter [4520], loss[0.0313016325]\n",
      "[ Tue Dec  4 21:09:26 2018], epoch [4540], lr[0.02500000] ,loss[0.0750119165]\n",
      "[ Tue Dec  4 21:09:26 2018], validation: iter [4540], loss[0.0312989950]\n",
      "[ Tue Dec  4 21:09:27 2018], epoch [4560], lr[0.02500000] ,loss[0.0750119239]\n",
      "[ Tue Dec  4 21:09:27 2018], validation: iter [4560], loss[0.0312977731]\n",
      "[ Tue Dec  4 21:09:27 2018], epoch [4580], lr[0.02500000] ,loss[0.0750103444]\n",
      "[ Tue Dec  4 21:09:27 2018], validation: iter [4580], loss[0.0312955491]\n",
      "[ Tue Dec  4 21:09:28 2018], epoch [4600], lr[0.02500000] ,loss[0.0750062838]\n",
      "[ Tue Dec  4 21:09:28 2018], validation: iter [4600], loss[0.0312910564]\n",
      "[ Tue Dec  4 21:09:29 2018], epoch [4620], lr[0.02500000] ,loss[0.0750057325]\n",
      "[ Tue Dec  4 21:09:29 2018], validation: iter [4620], loss[0.0312890783]\n",
      "[ Tue Dec  4 21:09:29 2018], epoch [4640], lr[0.02500000] ,loss[0.0750049651]\n",
      "[ Tue Dec  4 21:09:29 2018], validation: iter [4640], loss[0.0312863477]\n",
      "[ Tue Dec  4 21:09:30 2018], epoch [4660], lr[0.02500000] ,loss[0.0750044957]\n",
      "[ Tue Dec  4 21:09:30 2018], validation: iter [4660], loss[0.0312851556]\n",
      "[ Tue Dec  4 21:09:30 2018], epoch [4680], lr[0.02500000] ,loss[0.0750034526]\n",
      "[ Tue Dec  4 21:09:30 2018], validation: iter [4680], loss[0.0312839486]\n",
      "[ Tue Dec  4 21:09:31 2018], epoch [4700], lr[0.02500000] ,loss[0.0750025585]\n",
      "[ Tue Dec  4 21:09:31 2018], validation: iter [4700], loss[0.0312817059]\n",
      "[ Tue Dec  4 21:09:32 2018], epoch [4720], lr[0.02500000] ,loss[0.0750028491]\n",
      "[ Tue Dec  4 21:09:32 2018], validation: iter [4720], loss[0.0312809907]\n",
      "[ Tue Dec  4 21:09:32 2018], epoch [4740], lr[0.02500000] ,loss[0.0750012994]\n",
      "[ Tue Dec  4 21:09:32 2018], validation: iter [4740], loss[0.0312781632]\n",
      "[ Tue Dec  4 21:09:33 2018], epoch [4760], lr[0.02500000] ,loss[0.0750008970]\n",
      "[ Tue Dec  4 21:09:33 2018], validation: iter [4760], loss[0.0312762484]\n",
      "[ Tue Dec  4 21:09:33 2018], epoch [4780], lr[0.02500000] ,loss[0.0749997944]\n",
      "[ Tue Dec  4 21:09:33 2018], validation: iter [4780], loss[0.0312743858]\n",
      "[ Tue Dec  4 21:09:34 2018], epoch [4800], lr[0.02500000] ,loss[0.0749994963]\n",
      "[ Tue Dec  4 21:09:34 2018], validation: iter [4800], loss[0.0312726460]\n",
      "[ Tue Dec  4 21:09:34 2018], epoch [4820], lr[0.02500000] ,loss[0.0749981403]\n",
      "[ Tue Dec  4 21:09:34 2018], validation: iter [4820], loss[0.0312703773]\n",
      "[ Tue Dec  4 21:09:35 2018], epoch [4840], lr[0.02500000] ,loss[0.0749974474]\n",
      "[ Tue Dec  4 21:09:35 2018], validation: iter [4840], loss[0.0312685482]\n",
      "[ Tue Dec  4 21:09:35 2018], epoch [4860], lr[0.02500000] ,loss[0.0749972761]\n",
      "[ Tue Dec  4 21:09:35 2018], validation: iter [4860], loss[0.0312665589]\n",
      "[ Tue Dec  4 21:09:36 2018], epoch [4880], lr[0.02500000] ,loss[0.0749961436]\n",
      "[ Tue Dec  4 21:09:36 2018], validation: iter [4880], loss[0.0312647037]\n",
      "[ Tue Dec  4 21:09:36 2018], epoch [4900], lr[0.02500000] ,loss[0.0749957934]\n",
      "[ Tue Dec  4 21:09:36 2018], validation: iter [4900], loss[0.0312623084]\n",
      "[ Tue Dec  4 21:09:37 2018], epoch [4920], lr[0.02500000] ,loss[0.0749957487]\n",
      "[ Tue Dec  4 21:09:37 2018], validation: iter [4920], loss[0.0312606879]\n",
      "[ Tue Dec  4 21:09:37 2018], epoch [4940], lr[0.02500000] ,loss[0.0749941319]\n",
      "[ Tue Dec  4 21:09:37 2018], validation: iter [4940], loss[0.0312594660]\n",
      "[ Tue Dec  4 21:09:38 2018], epoch [4960], lr[0.02500000] ,loss[0.0749926940]\n",
      "[ Tue Dec  4 21:09:38 2018], validation: iter [4960], loss[0.0312560610]\n",
      "[ Tue Dec  4 21:09:38 2018], epoch [4980], lr[0.02500000] ,loss[0.0749922767]\n",
      "[ Tue Dec  4 21:09:38 2018], validation: iter [4980], loss[0.0312550440]\n",
      "[ Tue Dec  4 21:09:39 2018], epoch [5000], lr[0.02500000] ,loss[0.0749922767]\n",
      "[ Tue Dec  4 21:09:39 2018], validation: iter [5000], loss[0.0312528163]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_5000']\n",
      "[ Tue Dec  4 21:09:39 2018], epoch [5020], lr[0.02500000] ,loss[0.0749904364]\n",
      "[ Tue Dec  4 21:09:39 2018], validation: iter [5020], loss[0.0312505327]\n",
      "[ Tue Dec  4 21:09:40 2018], epoch [5040], lr[0.02500000] ,loss[0.0749896988]\n",
      "[ Tue Dec  4 21:09:40 2018], validation: iter [5040], loss[0.0312482957]\n",
      "[ Tue Dec  4 21:09:40 2018], epoch [5060], lr[0.02500000] ,loss[0.0749901906]\n",
      "[ Tue Dec  4 21:09:40 2018], validation: iter [5060], loss[0.0312467813]\n",
      "[ Tue Dec  4 21:09:41 2018], epoch [5080], lr[0.02500000] ,loss[0.0749892294]\n",
      "[ Tue Dec  4 21:09:41 2018], validation: iter [5080], loss[0.0312447604]\n",
      "[ Tue Dec  4 21:09:42 2018], epoch [5100], lr[0.02500000] ,loss[0.0749870464]\n",
      "[ Tue Dec  4 21:09:42 2018], validation: iter [5100], loss[0.0312414188]\n",
      "[ Tue Dec  4 21:09:42 2018], epoch [5120], lr[0.02500000] ,loss[0.0749876946]\n",
      "[ Tue Dec  4 21:09:42 2018], validation: iter [5120], loss[0.0312410165]\n",
      "[ Tue Dec  4 21:09:43 2018], epoch [5140], lr[0.02500000] ,loss[0.0749863386]\n",
      "[ Tue Dec  4 21:09:43 2018], validation: iter [5140], loss[0.0312368087]\n",
      "[ Tue Dec  4 21:09:43 2018], epoch [5160], lr[0.02500000] ,loss[0.0749859512]\n",
      "[ Tue Dec  4 21:09:43 2018], validation: iter [5160], loss[0.0312352180]\n",
      "[ Tue Dec  4 21:09:44 2018], epoch [5180], lr[0.02500000] ,loss[0.0749841854]\n",
      "[ Tue Dec  4 21:09:44 2018], validation: iter [5180], loss[0.0312323198]\n",
      "[ Tue Dec  4 21:09:44 2018], epoch [5200], lr[0.02500000] ,loss[0.0749829337]\n",
      "[ Tue Dec  4 21:09:44 2018], validation: iter [5200], loss[0.0312308501]\n",
      "[ Tue Dec  4 21:09:45 2018], epoch [5220], lr[0.02500000] ,loss[0.0749832690]\n",
      "[ Tue Dec  4 21:09:45 2018], validation: iter [5220], loss[0.0312296003]\n",
      "[ Tue Dec  4 21:09:45 2018], epoch [5240], lr[0.02500000] ,loss[0.0749813095]\n",
      "[ Tue Dec  4 21:09:45 2018], validation: iter [5240], loss[0.0312254354]\n",
      "[ Tue Dec  4 21:09:46 2018], epoch [5260], lr[0.02500000] ,loss[0.0749814957]\n",
      "[ Tue Dec  4 21:09:46 2018], validation: iter [5260], loss[0.0312211085]\n",
      "[ Tue Dec  4 21:09:46 2018], epoch [5280], lr[0.02500000] ,loss[0.0749918371]\n",
      "[ Tue Dec  4 21:09:46 2018], validation: iter [5280], loss[0.0312117096]\n",
      "[ Tue Dec  4 21:09:47 2018], epoch [5300], lr[0.02500000] ,loss[0.0764566809]\n",
      "[ Tue Dec  4 21:09:47 2018], validation: iter [5300], loss[0.0322969370]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 21:09:47 2018], epoch [5320], lr[0.02500000] ,loss[0.0750229433]\n",
      "[ Tue Dec  4 21:09:47 2018], validation: iter [5320], loss[0.0313340276]\n",
      "[ Tue Dec  4 21:09:48 2018], epoch [5340], lr[0.02500000] ,loss[0.0749694258]\n",
      "[ Tue Dec  4 21:09:48 2018], validation: iter [5340], loss[0.0312236249]\n",
      "[ Tue Dec  4 21:09:48 2018], epoch [5360], lr[0.02500000] ,loss[0.0749903321]\n",
      "[ Tue Dec  4 21:09:48 2018], validation: iter [5360], loss[0.0312067624]\n",
      "[ Tue Dec  4 21:09:49 2018], epoch [5380], lr[0.02500000] ,loss[0.0751535743]\n",
      "[ Tue Dec  4 21:09:49 2018], validation: iter [5380], loss[0.0313487127]\n",
      "[ Tue Dec  4 21:09:49 2018], epoch [5400], lr[0.02500000] ,loss[0.0752506703]\n",
      "[ Tue Dec  4 21:09:49 2018], validation: iter [5400], loss[0.0315979607]\n",
      "[ Tue Dec  4 21:09:50 2018], epoch [5420], lr[0.02500000] ,loss[0.0749894306]\n",
      "[ Tue Dec  4 21:09:50 2018], validation: iter [5420], loss[0.0312789790]\n",
      "[ Tue Dec  4 21:09:50 2018], epoch [5440], lr[0.02500000] ,loss[0.0750006214]\n",
      "[ Tue Dec  4 21:09:50 2018], validation: iter [5440], loss[0.0312026627]\n",
      "[ Tue Dec  4 21:09:51 2018], epoch [5460], lr[0.02500000] ,loss[0.0749733597]\n",
      "[ Tue Dec  4 21:09:51 2018], validation: iter [5460], loss[0.0312079862]\n",
      "[ Tue Dec  4 21:09:51 2018], epoch [5480], lr[0.02500000] ,loss[0.0751500875]\n",
      "[ Tue Dec  4 21:09:51 2018], validation: iter [5480], loss[0.0316086076]\n",
      "[ Tue Dec  4 21:09:52 2018], epoch [5500], lr[0.02500000] ,loss[0.0750632435]\n",
      "[ Tue Dec  4 21:09:52 2018], validation: iter [5500], loss[0.0312220175]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_5500']\n",
      "[ Tue Dec  4 21:09:53 2018], epoch [5520], lr[0.02500000] ,loss[0.0750026479]\n",
      "[ Tue Dec  4 21:09:53 2018], validation: iter [5520], loss[0.0312911980]\n",
      "[ Tue Dec  4 21:09:53 2018], epoch [5540], lr[0.02500000] ,loss[0.0749731734]\n",
      "[ Tue Dec  4 21:09:53 2018], validation: iter [5540], loss[0.0312183611]\n",
      "[ Tue Dec  4 21:09:54 2018], epoch [5560], lr[0.02500000] ,loss[0.0749772489]\n",
      "[ Tue Dec  4 21:09:54 2018], validation: iter [5560], loss[0.0311970655]\n",
      "[ Tue Dec  4 21:09:54 2018], epoch [5580], lr[0.02500000] ,loss[0.0753057450]\n",
      "[ Tue Dec  4 21:09:54 2018], validation: iter [5580], loss[0.0313517153]\n",
      "[ Tue Dec  4 21:09:55 2018], epoch [5600], lr[0.02500000] ,loss[0.0749979168]\n",
      "[ Tue Dec  4 21:09:55 2018], validation: iter [5600], loss[0.0312566832]\n",
      "[ Tue Dec  4 21:09:56 2018], epoch [5620], lr[0.02500000] ,loss[0.0750435516]\n",
      "[ Tue Dec  4 21:09:56 2018], validation: iter [5620], loss[0.0312330704]\n",
      "[ Tue Dec  4 21:09:56 2018], epoch [5640], lr[0.02500000] ,loss[0.0749846026]\n",
      "[ Tue Dec  4 21:09:56 2018], validation: iter [5640], loss[0.0312732123]\n",
      "[ Tue Dec  4 21:09:57 2018], epoch [5660], lr[0.02500000] ,loss[0.0749691501]\n",
      "[ Tue Dec  4 21:09:57 2018], validation: iter [5660], loss[0.0312199835]\n",
      "[ Tue Dec  4 21:09:58 2018], epoch [5680], lr[0.02500000] ,loss[0.0749955401]\n",
      "[ Tue Dec  4 21:09:58 2018], validation: iter [5680], loss[0.0311787799]\n",
      "[ Tue Dec  4 21:09:59 2018], epoch [5700], lr[0.02500000] ,loss[0.0749662519]\n",
      "[ Tue Dec  4 21:09:59 2018], validation: iter [5700], loss[0.0312021710]\n",
      "[ Tue Dec  4 21:09:59 2018], epoch [5720], lr[0.02500000] ,loss[0.0750816241]\n",
      "[ Tue Dec  4 21:09:59 2018], validation: iter [5720], loss[0.0314479545]\n",
      "[ Tue Dec  4 21:10:00 2018], epoch [5740], lr[0.02500000] ,loss[0.0753043890]\n",
      "[ Tue Dec  4 21:10:00 2018], validation: iter [5740], loss[0.0313878581]\n",
      "[ Tue Dec  4 21:10:01 2018], epoch [5760], lr[0.02500000] ,loss[0.0749920309]\n",
      "[ Tue Dec  4 21:10:01 2018], validation: iter [5760], loss[0.0311650783]\n",
      "[ Tue Dec  4 21:10:01 2018], epoch [5780], lr[0.02500000] ,loss[0.0749637708]\n",
      "[ Tue Dec  4 21:10:01 2018], validation: iter [5780], loss[0.0312065445]\n",
      "[ Tue Dec  4 21:10:02 2018], epoch [5800], lr[0.02500000] ,loss[0.0750256926]\n",
      "[ Tue Dec  4 21:10:02 2018], validation: iter [5800], loss[0.0313423276]\n",
      "[ Tue Dec  4 21:10:03 2018], epoch [5820], lr[0.02500000] ,loss[0.0755896717]\n",
      "[ Tue Dec  4 21:10:03 2018], validation: iter [5820], loss[0.0316452943]\n",
      "[ Tue Dec  4 21:10:03 2018], epoch [5840], lr[0.02500000] ,loss[0.0750668123]\n",
      "[ Tue Dec  4 21:10:03 2018], validation: iter [5840], loss[0.0313382223]\n",
      "[ Tue Dec  4 21:10:04 2018], epoch [5860], lr[0.02500000] ,loss[0.0749536604]\n",
      "[ Tue Dec  4 21:10:04 2018], validation: iter [5860], loss[0.0311705209]\n",
      "[ Tue Dec  4 21:10:05 2018], epoch [5880], lr[0.02500000] ,loss[0.0749848783]\n",
      "[ Tue Dec  4 21:10:05 2018], validation: iter [5880], loss[0.0312381443]\n",
      "[ Tue Dec  4 21:10:05 2018], epoch [5900], lr[0.02500000] ,loss[0.0754276365]\n",
      "[ Tue Dec  4 21:10:05 2018], validation: iter [5900], loss[0.0316945091]\n",
      "[ Tue Dec  4 21:10:06 2018], epoch [5920], lr[0.02500000] ,loss[0.0749695972]\n",
      "[ Tue Dec  4 21:10:06 2018], validation: iter [5920], loss[0.0311792456]\n",
      "[ Tue Dec  4 21:10:07 2018], epoch [5940], lr[0.02500000] ,loss[0.0749599040]\n",
      "[ Tue Dec  4 21:10:07 2018], validation: iter [5940], loss[0.0311844926]\n",
      "[ Tue Dec  4 21:10:08 2018], epoch [5960], lr[0.02500000] ,loss[0.0750168413]\n",
      "[ Tue Dec  4 21:10:08 2018], validation: iter [5960], loss[0.0313217565]\n",
      "[ Tue Dec  4 21:10:08 2018], epoch [5980], lr[0.02500000] ,loss[0.0753377229]\n",
      "[ Tue Dec  4 21:10:08 2018], validation: iter [5980], loss[0.0314682014]\n",
      "[ Tue Dec  4 21:10:09 2018], epoch [6000], lr[0.02500000] ,loss[0.0750485212]\n",
      "[ Tue Dec  4 21:10:09 2018], validation: iter [6000], loss[0.0311751422]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_6000']\n",
      "[ Tue Dec  4 21:10:10 2018], epoch [6020], lr[0.01250000] ,loss[0.0749614090]\n",
      "[ Tue Dec  4 21:10:10 2018], validation: iter [6020], loss[0.0311476756]\n",
      "[ Tue Dec  4 21:10:10 2018], epoch [6040], lr[0.01250000] ,loss[0.0749596879]\n",
      "[ Tue Dec  4 21:10:10 2018], validation: iter [6040], loss[0.0311490670]\n",
      "[ Tue Dec  4 21:10:11 2018], epoch [6060], lr[0.01250000] ,loss[0.0749580041]\n",
      "[ Tue Dec  4 21:10:11 2018], validation: iter [6060], loss[0.0311508160]\n",
      "[ Tue Dec  4 21:10:12 2018], epoch [6080], lr[0.01250000] ,loss[0.0749565288]\n",
      "[ Tue Dec  4 21:10:12 2018], validation: iter [6080], loss[0.0311498195]\n",
      "[ Tue Dec  4 21:10:12 2018], epoch [6100], lr[0.01250000] ,loss[0.0749563724]\n",
      "[ Tue Dec  4 21:10:12 2018], validation: iter [6100], loss[0.0311488193]\n",
      "[ Tue Dec  4 21:10:13 2018], epoch [6120], lr[0.01250000] ,loss[0.0749553144]\n",
      "[ Tue Dec  4 21:10:13 2018], validation: iter [6120], loss[0.0311471783]\n",
      "[ Tue Dec  4 21:10:14 2018], epoch [6140], lr[0.01250000] ,loss[0.0749547780]\n",
      "[ Tue Dec  4 21:10:14 2018], validation: iter [6140], loss[0.0311458427]\n",
      "[ Tue Dec  4 21:10:14 2018], epoch [6160], lr[0.01250000] ,loss[0.0749536082]\n",
      "[ Tue Dec  4 21:10:14 2018], validation: iter [6160], loss[0.0311440285]\n",
      "[ Tue Dec  4 21:10:15 2018], epoch [6180], lr[0.01250000] ,loss[0.0749529377]\n",
      "[ Tue Dec  4 21:10:15 2018], validation: iter [6180], loss[0.0311424658]\n",
      "[ Tue Dec  4 21:10:16 2018], epoch [6200], lr[0.01250000] ,loss[0.0749513879]\n",
      "[ Tue Dec  4 21:10:16 2018], validation: iter [6200], loss[0.0311404690]\n",
      "[ Tue Dec  4 21:10:16 2018], epoch [6220], lr[0.01250000] ,loss[0.0749510974]\n",
      "[ Tue Dec  4 21:10:16 2018], validation: iter [6220], loss[0.0311392471]\n",
      "[ Tue Dec  4 21:10:17 2018], epoch [6240], lr[0.01250000] ,loss[0.0749504045]\n",
      "[ Tue Dec  4 21:10:17 2018], validation: iter [6240], loss[0.0311376322]\n",
      "[ Tue Dec  4 21:10:18 2018], epoch [6260], lr[0.01250000] ,loss[0.0749463513]\n",
      "[ Tue Dec  4 21:10:18 2018], validation: iter [6260], loss[0.0311323740]\n",
      "[ Tue Dec  4 21:10:18 2018], epoch [6280], lr[0.01250000] ,loss[0.0749443844]\n",
      "[ Tue Dec  4 21:10:18 2018], validation: iter [6280], loss[0.0311305858]\n",
      "[ Tue Dec  4 21:10:19 2018], epoch [6300], lr[0.01250000] ,loss[0.0749435425]\n",
      "[ Tue Dec  4 21:10:19 2018], validation: iter [6300], loss[0.0311288666]\n",
      "[ Tue Dec  4 21:10:20 2018], epoch [6320], lr[0.01250000] ,loss[0.0749434084]\n",
      "[ Tue Dec  4 21:10:20 2018], validation: iter [6320], loss[0.0311280526]\n",
      "[ Tue Dec  4 21:10:21 2018], epoch [6340], lr[0.01250000] ,loss[0.0749418288]\n",
      "[ Tue Dec  4 21:10:21 2018], validation: iter [6340], loss[0.0311263576]\n",
      "[ Tue Dec  4 21:10:21 2018], epoch [6360], lr[0.01250000] ,loss[0.0749416500]\n",
      "[ Tue Dec  4 21:10:21 2018], validation: iter [6360], loss[0.0311252289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 21:10:22 2018], epoch [6380], lr[0.01250000] ,loss[0.0749410167]\n",
      "[ Tue Dec  4 21:10:22 2018], validation: iter [6380], loss[0.0311240647]\n",
      "[ Tue Dec  4 21:10:23 2018], epoch [6400], lr[0.01250000] ,loss[0.0749405175]\n",
      "[ Tue Dec  4 21:10:23 2018], validation: iter [6400], loss[0.0311228912]\n",
      "[ Tue Dec  4 21:10:23 2018], epoch [6420], lr[0.01250000] ,loss[0.0749398246]\n",
      "[ Tue Dec  4 21:10:23 2018], validation: iter [6420], loss[0.0311215911]\n",
      "[ Tue Dec  4 21:10:24 2018], epoch [6440], lr[0.01250000] ,loss[0.0749394000]\n",
      "[ Tue Dec  4 21:10:24 2018], validation: iter [6440], loss[0.0311205052]\n",
      "[ Tue Dec  4 21:10:25 2018], epoch [6460], lr[0.01250000] ,loss[0.0749390870]\n",
      "[ Tue Dec  4 21:10:25 2018], validation: iter [6460], loss[0.0311191063]\n",
      "[ Tue Dec  4 21:10:25 2018], epoch [6480], lr[0.01250000] ,loss[0.0749382526]\n",
      "[ Tue Dec  4 21:10:25 2018], validation: iter [6480], loss[0.0311183110]\n",
      "[ Tue Dec  4 21:10:26 2018], epoch [6500], lr[0.01250000] ,loss[0.0749380216]\n",
      "[ Tue Dec  4 21:10:26 2018], validation: iter [6500], loss[0.0311171729]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_6500']\n",
      "[ Tue Dec  4 21:10:27 2018], epoch [6520], lr[0.01250000] ,loss[0.0749376938]\n",
      "[ Tue Dec  4 21:10:27 2018], validation: iter [6520], loss[0.0311158355]\n",
      "[ Tue Dec  4 21:10:27 2018], epoch [6540], lr[0.01250000] ,loss[0.0749373287]\n",
      "[ Tue Dec  4 21:10:27 2018], validation: iter [6540], loss[0.0311147477]\n",
      "[ Tue Dec  4 21:10:28 2018], epoch [6560], lr[0.01250000] ,loss[0.0749360248]\n",
      "[ Tue Dec  4 21:10:28 2018], validation: iter [6560], loss[0.0311131105]\n",
      "[ Tue Dec  4 21:10:29 2018], epoch [6580], lr[0.01250000] ,loss[0.0749358311]\n",
      "[ Tue Dec  4 21:10:29 2018], validation: iter [6580], loss[0.0311122127]\n",
      "[ Tue Dec  4 21:10:29 2018], epoch [6600], lr[0.01250000] ,loss[0.0749360844]\n",
      "[ Tue Dec  4 21:10:29 2018], validation: iter [6600], loss[0.0311106667]\n",
      "[ Tue Dec  4 21:10:30 2018], epoch [6620], lr[0.01250000] ,loss[0.0749343559]\n",
      "[ Tue Dec  4 21:10:30 2018], validation: iter [6620], loss[0.0311092976]\n",
      "[ Tue Dec  4 21:10:30 2018], epoch [6640], lr[0.01250000] ,loss[0.0749347657]\n",
      "[ Tue Dec  4 21:10:30 2018], validation: iter [6640], loss[0.0311084222]\n",
      "[ Tue Dec  4 21:10:31 2018], epoch [6660], lr[0.01250000] ,loss[0.0749346539]\n",
      "[ Tue Dec  4 21:10:31 2018], validation: iter [6660], loss[0.0311069041]\n",
      "[ Tue Dec  4 21:10:32 2018], epoch [6680], lr[0.01250000] ,loss[0.0749337226]\n",
      "[ Tue Dec  4 21:10:32 2018], validation: iter [6680], loss[0.0311056171]\n",
      "[ Tue Dec  4 21:10:33 2018], epoch [6700], lr[0.01250000] ,loss[0.0749325380]\n",
      "[ Tue Dec  4 21:10:33 2018], validation: iter [6700], loss[0.0311038364]\n",
      "[ Tue Dec  4 21:10:33 2018], epoch [6720], lr[0.01250000] ,loss[0.0749314055]\n",
      "[ Tue Dec  4 21:10:33 2018], validation: iter [6720], loss[0.0311023612]\n",
      "[ Tue Dec  4 21:10:34 2018], epoch [6740], lr[0.01250000] ,loss[0.0749319941]\n",
      "[ Tue Dec  4 21:10:34 2018], validation: iter [6740], loss[0.0311013814]\n",
      "[ Tue Dec  4 21:10:35 2018], epoch [6760], lr[0.01250000] ,loss[0.0749314949]\n",
      "[ Tue Dec  4 21:10:35 2018], validation: iter [6760], loss[0.0311000776]\n",
      "[ Tue Dec  4 21:10:36 2018], epoch [6780], lr[0.01250000] ,loss[0.0749314204]\n",
      "[ Tue Dec  4 21:10:36 2018], validation: iter [6780], loss[0.0310991015]\n",
      "[ Tue Dec  4 21:10:37 2018], epoch [6800], lr[0.01250000] ,loss[0.0749309883]\n",
      "[ Tue Dec  4 21:10:37 2018], validation: iter [6800], loss[0.0310975872]\n",
      "[ Tue Dec  4 21:10:37 2018], epoch [6820], lr[0.01250000] ,loss[0.0749299154]\n",
      "[ Tue Dec  4 21:10:37 2018], validation: iter [6820], loss[0.0310961381]\n",
      "[ Tue Dec  4 21:10:38 2018], epoch [6840], lr[0.01250000] ,loss[0.0749297738]\n",
      "[ Tue Dec  4 21:10:38 2018], validation: iter [6840], loss[0.0310942624]\n",
      "[ Tue Dec  4 21:10:38 2018], epoch [6860], lr[0.01250000] ,loss[0.0749293715]\n",
      "[ Tue Dec  4 21:10:38 2018], validation: iter [6860], loss[0.0310933720]\n",
      "[ Tue Dec  4 21:10:39 2018], epoch [6880], lr[0.01250000] ,loss[0.0749289095]\n",
      "[ Tue Dec  4 21:10:39 2018], validation: iter [6880], loss[0.0310916789]\n",
      "[ Tue Dec  4 21:10:39 2018], epoch [6900], lr[0.01250000] ,loss[0.0749267787]\n",
      "[ Tue Dec  4 21:10:39 2018], validation: iter [6900], loss[0.0310894083]\n",
      "[ Tue Dec  4 21:10:40 2018], epoch [6920], lr[0.01250000] ,loss[0.0749278367]\n",
      "[ Tue Dec  4 21:10:40 2018], validation: iter [6920], loss[0.0310888346]\n",
      "[ Tue Dec  4 21:10:41 2018], epoch [6940], lr[0.01250000] ,loss[0.0749266744]\n",
      "[ Tue Dec  4 21:10:41 2018], validation: iter [6940], loss[0.0310869403]\n",
      "[ Tue Dec  4 21:10:41 2018], epoch [6960], lr[0.01250000] ,loss[0.0749269947]\n",
      "[ Tue Dec  4 21:10:41 2018], validation: iter [6960], loss[0.0310863275]\n",
      "[ Tue Dec  4 21:10:42 2018], epoch [6980], lr[0.01250000] ,loss[0.0749265179]\n",
      "[ Tue Dec  4 21:10:42 2018], validation: iter [6980], loss[0.0310845170]\n",
      "[ Tue Dec  4 21:10:42 2018], epoch [7000], lr[0.01250000] ,loss[0.0749251917]\n",
      "[ Tue Dec  4 21:10:42 2018], validation: iter [7000], loss[0.0310826227]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_7000']\n",
      "[ Tue Dec  4 21:10:43 2018], epoch [7020], lr[0.01250000] ,loss[0.0749244541]\n",
      "[ Tue Dec  4 21:10:43 2018], validation: iter [7020], loss[0.0310811028]\n",
      "[ Tue Dec  4 21:10:43 2018], epoch [7040], lr[0.01250000] ,loss[0.0749249980]\n",
      "[ Tue Dec  4 21:10:43 2018], validation: iter [7040], loss[0.0310795531]\n",
      "[ Tue Dec  4 21:10:44 2018], epoch [7060], lr[0.01250000] ,loss[0.0749228150]\n",
      "[ Tue Dec  4 21:10:44 2018], validation: iter [7060], loss[0.0310779959]\n",
      "[ Tue Dec  4 21:10:44 2018], epoch [7080], lr[0.01250000] ,loss[0.0749234557]\n",
      "[ Tue Dec  4 21:10:44 2018], validation: iter [7080], loss[0.0310765970]\n",
      "[ Tue Dec  4 21:10:45 2018], epoch [7100], lr[0.01250000] ,loss[0.0749237910]\n",
      "[ Tue Dec  4 21:10:45 2018], validation: iter [7100], loss[0.0310756490]\n",
      "[ Tue Dec  4 21:10:45 2018], epoch [7120], lr[0.01250000] ,loss[0.0749222934]\n",
      "[ Tue Dec  4 21:10:45 2018], validation: iter [7120], loss[0.0310735200]\n",
      "[ Tue Dec  4 21:10:46 2018], epoch [7140], lr[0.01250000] ,loss[0.0749205127]\n",
      "[ Tue Dec  4 21:10:46 2018], validation: iter [7140], loss[0.0310712457]\n",
      "[ Tue Dec  4 21:10:46 2018], epoch [7160], lr[0.01250000] ,loss[0.0749205872]\n",
      "[ Tue Dec  4 21:10:46 2018], validation: iter [7160], loss[0.0310694408]\n",
      "[ Tue Dec  4 21:10:47 2018], epoch [7180], lr[0.01250000] ,loss[0.0749207884]\n",
      "[ Tue Dec  4 21:10:47 2018], validation: iter [7180], loss[0.0310691837]\n",
      "[ Tue Dec  4 21:10:47 2018], epoch [7200], lr[0.01250000] ,loss[0.0749204829]\n",
      "[ Tue Dec  4 21:10:47 2018], validation: iter [7200], loss[0.0310670305]\n",
      "[ Tue Dec  4 21:10:48 2018], epoch [7220], lr[0.01250000] ,loss[0.0749191642]\n",
      "[ Tue Dec  4 21:10:48 2018], validation: iter [7220], loss[0.0310653783]\n",
      "[ Tue Dec  4 21:10:48 2018], epoch [7240], lr[0.01250000] ,loss[0.0749190375]\n",
      "[ Tue Dec  4 21:10:48 2018], validation: iter [7240], loss[0.0310636032]\n",
      "[ Tue Dec  4 21:10:49 2018], epoch [7260], lr[0.01250000] ,loss[0.0749176741]\n",
      "[ Tue Dec  4 21:10:49 2018], validation: iter [7260], loss[0.0310623050]\n",
      "[ Tue Dec  4 21:10:50 2018], epoch [7280], lr[0.01250000] ,loss[0.0749168321]\n",
      "[ Tue Dec  4 21:10:50 2018], validation: iter [7280], loss[0.0310600344]\n",
      "[ Tue Dec  4 21:10:50 2018], epoch [7300], lr[0.01250000] ,loss[0.0749167278]\n",
      "[ Tue Dec  4 21:10:50 2018], validation: iter [7300], loss[0.0310579594]\n",
      "[ Tue Dec  4 21:10:51 2018], epoch [7320], lr[0.01250000] ,loss[0.0749160573]\n",
      "[ Tue Dec  4 21:10:51 2018], validation: iter [7320], loss[0.0310558639]\n",
      "[ Tue Dec  4 21:10:51 2018], epoch [7340], lr[0.01250000] ,loss[0.0749161616]\n",
      "[ Tue Dec  4 21:10:51 2018], validation: iter [7340], loss[0.0310499985]\n",
      "[ Tue Dec  4 21:10:52 2018], epoch [7360], lr[0.01250000] ,loss[0.0750069246]\n",
      "[ Tue Dec  4 21:10:52 2018], validation: iter [7360], loss[0.0310836248]\n",
      "[ Tue Dec  4 21:10:52 2018], epoch [7380], lr[0.01250000] ,loss[0.0750250295]\n",
      "[ Tue Dec  4 21:10:52 2018], validation: iter [7380], loss[0.0310943238]\n",
      "[ Tue Dec  4 21:10:53 2018], epoch [7400], lr[0.01250000] ,loss[0.0749137551]\n",
      "[ Tue Dec  4 21:10:53 2018], validation: iter [7400], loss[0.0310705509]\n",
      "[ Tue Dec  4 21:10:53 2018], epoch [7420], lr[0.01250000] ,loss[0.0749296993]\n",
      "[ Tue Dec  4 21:10:53 2018], validation: iter [7420], loss[0.0311156437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 21:10:54 2018], epoch [7440], lr[0.01250000] ,loss[0.0749281794]\n",
      "[ Tue Dec  4 21:10:54 2018], validation: iter [7440], loss[0.0310977343]\n",
      "[ Tue Dec  4 21:10:54 2018], epoch [7460], lr[0.01250000] ,loss[0.0749400631]\n",
      "[ Tue Dec  4 21:10:54 2018], validation: iter [7460], loss[0.0310442876]\n",
      "[ Tue Dec  4 21:10:55 2018], epoch [7480], lr[0.01250000] ,loss[0.0750441551]\n",
      "[ Tue Dec  4 21:10:55 2018], validation: iter [7480], loss[0.0310826898]\n",
      "[ Tue Dec  4 21:10:55 2018], epoch [7500], lr[0.01250000] ,loss[0.0749148950]\n",
      "[ Tue Dec  4 21:10:55 2018], validation: iter [7500], loss[0.0310424250]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_7500']\n",
      "[ Tue Dec  4 21:10:56 2018], epoch [7520], lr[0.01250000] ,loss[0.0749181956]\n",
      "[ Tue Dec  4 21:10:56 2018], validation: iter [7520], loss[0.0310331061]\n",
      "[ Tue Dec  4 21:10:56 2018], epoch [7540], lr[0.01250000] ,loss[0.0750779137]\n",
      "[ Tue Dec  4 21:10:56 2018], validation: iter [7540], loss[0.0311345458]\n",
      "[ Tue Dec  4 21:10:57 2018], epoch [7560], lr[0.01250000] ,loss[0.0749832988]\n",
      "[ Tue Dec  4 21:10:57 2018], validation: iter [7560], loss[0.0310533941]\n",
      "[ Tue Dec  4 21:10:57 2018], epoch [7580], lr[0.01250000] ,loss[0.0749391168]\n",
      "[ Tue Dec  4 21:10:57 2018], validation: iter [7580], loss[0.0311525334]\n",
      "[ Tue Dec  4 21:10:58 2018], epoch [7600], lr[0.01250000] ,loss[0.0749104545]\n",
      "[ Tue Dec  4 21:10:58 2018], validation: iter [7600], loss[0.0310358554]\n",
      "[ Tue Dec  4 21:10:58 2018], epoch [7620], lr[0.01250000] ,loss[0.0749147013]\n",
      "[ Tue Dec  4 21:10:58 2018], validation: iter [7620], loss[0.0310292579]\n",
      "[ Tue Dec  4 21:10:59 2018], epoch [7640], lr[0.01250000] ,loss[0.0749123618]\n",
      "[ Tue Dec  4 21:10:59 2018], validation: iter [7640], loss[0.0310242716]\n",
      "[ Tue Dec  4 21:10:59 2018], epoch [7660], lr[0.01250000] ,loss[0.0751625746]\n",
      "[ Tue Dec  4 21:10:59 2018], validation: iter [7660], loss[0.0312046390]\n",
      "[ Tue Dec  4 21:11:00 2018], epoch [7680], lr[0.01250000] ,loss[0.0749105066]\n",
      "[ Tue Dec  4 21:11:00 2018], validation: iter [7680], loss[0.0310362838]\n",
      "[ Tue Dec  4 21:11:00 2018], epoch [7700], lr[0.01250000] ,loss[0.0748974159]\n",
      "[ Tue Dec  4 21:11:00 2018], validation: iter [7700], loss[0.0310408939]\n",
      "[ Tue Dec  4 21:11:01 2018], epoch [7720], lr[0.01250000] ,loss[0.0749072656]\n",
      "[ Tue Dec  4 21:11:01 2018], validation: iter [7720], loss[0.0310162939]\n",
      "[ Tue Dec  4 21:11:01 2018], epoch [7740], lr[0.01250000] ,loss[0.0749569386]\n",
      "[ Tue Dec  4 21:11:01 2018], validation: iter [7740], loss[0.0310375057]\n",
      "[ Tue Dec  4 21:11:02 2018], epoch [7760], lr[0.01250000] ,loss[0.0749028474]\n",
      "[ Tue Dec  4 21:11:02 2018], validation: iter [7760], loss[0.0310809966]\n",
      "[ Tue Dec  4 21:11:02 2018], epoch [7780], lr[0.01250000] ,loss[0.0749208108]\n",
      "[ Tue Dec  4 21:11:02 2018], validation: iter [7780], loss[0.0310138669]\n",
      "[ Tue Dec  4 21:11:03 2018], epoch [7800], lr[0.01250000] ,loss[0.0749021173]\n",
      "[ Tue Dec  4 21:11:03 2018], validation: iter [7800], loss[0.0310232136]\n",
      "[ Tue Dec  4 21:11:03 2018], epoch [7820], lr[0.01250000] ,loss[0.0749024078]\n",
      "[ Tue Dec  4 21:11:03 2018], validation: iter [7820], loss[0.0310520977]\n",
      "[ Tue Dec  4 21:11:04 2018], epoch [7840], lr[0.01250000] ,loss[0.0749018639]\n",
      "[ Tue Dec  4 21:11:04 2018], validation: iter [7840], loss[0.0310357623]\n",
      "[ Tue Dec  4 21:11:04 2018], epoch [7860], lr[0.01250000] ,loss[0.0748989955]\n",
      "[ Tue Dec  4 21:11:04 2018], validation: iter [7860], loss[0.0310221165]\n",
      "[ Tue Dec  4 21:11:05 2018], epoch [7880], lr[0.01250000] ,loss[0.0759592354]\n",
      "[ Tue Dec  4 21:11:05 2018], validation: iter [7880], loss[0.0324803814]\n",
      "[ Tue Dec  4 21:11:05 2018], epoch [7900], lr[0.01250000] ,loss[0.0749766082]\n",
      "[ Tue Dec  4 21:11:05 2018], validation: iter [7900], loss[0.0310569443]\n",
      "[ Tue Dec  4 21:11:06 2018], epoch [7920], lr[0.01250000] ,loss[0.0749195144]\n",
      "[ Tue Dec  4 21:11:06 2018], validation: iter [7920], loss[0.0310085155]\n",
      "[ Tue Dec  4 21:11:06 2018], epoch [7940], lr[0.01250000] ,loss[0.0749047920]\n",
      "[ Tue Dec  4 21:11:06 2018], validation: iter [7940], loss[0.0310095549]\n",
      "[ Tue Dec  4 21:11:07 2018], epoch [7960], lr[0.01250000] ,loss[0.0748981908]\n",
      "[ Tue Dec  4 21:11:07 2018], validation: iter [7960], loss[0.0310143679]\n",
      "[ Tue Dec  4 21:11:07 2018], epoch [7980], lr[0.01250000] ,loss[0.0748976246]\n",
      "[ Tue Dec  4 21:11:07 2018], validation: iter [7980], loss[0.0310124699]\n",
      "[ Tue Dec  4 21:11:08 2018], epoch [8000], lr[0.01250000] ,loss[0.0748964772]\n",
      "[ Tue Dec  4 21:11:08 2018], validation: iter [8000], loss[0.0310111549]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_8000']\n",
      "[ Tue Dec  4 21:11:08 2018], epoch [8020], lr[0.00625000] ,loss[0.0748959184]\n",
      "[ Tue Dec  4 21:11:08 2018], validation: iter [8020], loss[0.0310109481]\n",
      "[ Tue Dec  4 21:11:09 2018], epoch [8040], lr[0.00625000] ,loss[0.0748956054]\n",
      "[ Tue Dec  4 21:11:09 2018], validation: iter [8040], loss[0.0310101733]\n",
      "[ Tue Dec  4 21:11:09 2018], epoch [8060], lr[0.00625000] ,loss[0.0748953819]\n",
      "[ Tue Dec  4 21:11:09 2018], validation: iter [8060], loss[0.0310100000]\n",
      "[ Tue Dec  4 21:11:10 2018], epoch [8080], lr[0.00625000] ,loss[0.0748950168]\n",
      "[ Tue Dec  4 21:11:10 2018], validation: iter [8080], loss[0.0310092550]\n",
      "[ Tue Dec  4 21:11:10 2018], epoch [8100], lr[0.00625000] ,loss[0.0748948082]\n",
      "[ Tue Dec  4 21:11:10 2018], validation: iter [8100], loss[0.0310091190]\n",
      "[ Tue Dec  4 21:11:11 2018], epoch [8120], lr[0.00625000] ,loss[0.0748942345]\n",
      "[ Tue Dec  4 21:11:11 2018], validation: iter [8120], loss[0.0310083795]\n",
      "[ Tue Dec  4 21:11:11 2018], epoch [8140], lr[0.00625000] ,loss[0.0748942047]\n",
      "[ Tue Dec  4 21:11:11 2018], validation: iter [8140], loss[0.0310082659]\n",
      "[ Tue Dec  4 21:11:12 2018], epoch [8160], lr[0.00625000] ,loss[0.0748937353]\n",
      "[ Tue Dec  4 21:11:12 2018], validation: iter [8160], loss[0.0310074519]\n",
      "[ Tue Dec  4 21:11:12 2018], epoch [8180], lr[0.00625000] ,loss[0.0748931095]\n",
      "[ Tue Dec  4 21:11:12 2018], validation: iter [8180], loss[0.0310070217]\n",
      "[ Tue Dec  4 21:11:13 2018], epoch [8200], lr[0.00625000] ,loss[0.0748929158]\n",
      "[ Tue Dec  4 21:11:13 2018], validation: iter [8200], loss[0.0310062598]\n",
      "[ Tue Dec  4 21:11:13 2018], epoch [8220], lr[0.00625000] ,loss[0.0748928934]\n",
      "[ Tue Dec  4 21:11:13 2018], validation: iter [8220], loss[0.0310061947]\n",
      "[ Tue Dec  4 21:11:14 2018], epoch [8240], lr[0.00625000] ,loss[0.0748923123]\n",
      "[ Tue Dec  4 21:11:14 2018], validation: iter [8240], loss[0.0310054738]\n",
      "[ Tue Dec  4 21:11:14 2018], epoch [8260], lr[0.00625000] ,loss[0.0748923272]\n",
      "[ Tue Dec  4 21:11:14 2018], validation: iter [8260], loss[0.0310053956]\n",
      "[ Tue Dec  4 21:11:15 2018], epoch [8280], lr[0.00625000] ,loss[0.0748917684]\n",
      "[ Tue Dec  4 21:11:15 2018], validation: iter [8280], loss[0.0310046282]\n",
      "[ Tue Dec  4 21:11:15 2018], epoch [8300], lr[0.00625000] ,loss[0.0748919025]\n",
      "[ Tue Dec  4 21:11:15 2018], validation: iter [8300], loss[0.0310046095]\n",
      "[ Tue Dec  4 21:11:16 2018], epoch [8320], lr[0.00625000] ,loss[0.0748916566]\n",
      "[ Tue Dec  4 21:11:16 2018], validation: iter [8320], loss[0.0310040675]\n",
      "[ Tue Dec  4 21:11:16 2018], epoch [8340], lr[0.00625000] ,loss[0.0748915449]\n",
      "[ Tue Dec  4 21:11:16 2018], validation: iter [8340], loss[0.0310035888]\n",
      "[ Tue Dec  4 21:11:17 2018], epoch [8360], lr[0.00625000] ,loss[0.0748910755]\n",
      "[ Tue Dec  4 21:11:17 2018], validation: iter [8360], loss[0.0310033206]\n",
      "[ Tue Dec  4 21:11:17 2018], epoch [8380], lr[0.00625000] ,loss[0.0748908743]\n",
      "[ Tue Dec  4 21:11:17 2018], validation: iter [8380], loss[0.0310029536]\n",
      "[ Tue Dec  4 21:11:18 2018], epoch [8400], lr[0.00625000] ,loss[0.0748906359]\n",
      "[ Tue Dec  4 21:11:18 2018], validation: iter [8400], loss[0.0310025439]\n",
      "[ Tue Dec  4 21:11:18 2018], epoch [8420], lr[0.00625000] ,loss[0.0748903453]\n",
      "[ Tue Dec  4 21:11:18 2018], validation: iter [8420], loss[0.0310021602]\n",
      "[ Tue Dec  4 21:11:19 2018], epoch [8440], lr[0.00625000] ,loss[0.0748901367]\n",
      "[ Tue Dec  4 21:11:19 2018], validation: iter [8440], loss[0.0310017411]\n",
      "[ Tue Dec  4 21:11:19 2018], epoch [8460], lr[0.00625000] ,loss[0.0748898759]\n",
      "[ Tue Dec  4 21:11:19 2018], validation: iter [8460], loss[0.0310013629]\n",
      "[ Tue Dec  4 21:11:20 2018], epoch [8480], lr[0.00625000] ,loss[0.0748896003]\n",
      "[ Tue Dec  4 21:11:20 2018], validation: iter [8480], loss[0.0310009271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 21:11:20 2018], epoch [8500], lr[0.00625000] ,loss[0.0748894438]\n",
      "[ Tue Dec  4 21:11:20 2018], validation: iter [8500], loss[0.0310004298]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_8500']\n",
      "[ Tue Dec  4 21:11:21 2018], epoch [8520], lr[0.00625000] ,loss[0.0748891905]\n",
      "[ Tue Dec  4 21:11:21 2018], validation: iter [8520], loss[0.0310001709]\n",
      "[ Tue Dec  4 21:11:21 2018], epoch [8540], lr[0.00625000] ,loss[0.0748889223]\n",
      "[ Tue Dec  4 21:11:21 2018], validation: iter [8540], loss[0.0309998151]\n",
      "[ Tue Dec  4 21:11:22 2018], epoch [8560], lr[0.00625000] ,loss[0.0748886988]\n",
      "[ Tue Dec  4 21:11:22 2018], validation: iter [8560], loss[0.0309996232]\n",
      "[ Tue Dec  4 21:11:22 2018], epoch [8580], lr[0.00625000] ,loss[0.0748883486]\n",
      "[ Tue Dec  4 21:11:22 2018], validation: iter [8580], loss[0.0309987031]\n",
      "[ Tue Dec  4 21:11:23 2018], epoch [8600], lr[0.00625000] ,loss[0.0748881102]\n",
      "[ Tue Dec  4 21:11:23 2018], validation: iter [8600], loss[0.0309982132]\n",
      "[ Tue Dec  4 21:11:23 2018], epoch [8620], lr[0.00625000] ,loss[0.0748881102]\n",
      "[ Tue Dec  4 21:11:23 2018], validation: iter [8620], loss[0.0309982877]\n",
      "[ Tue Dec  4 21:11:24 2018], epoch [8640], lr[0.00625000] ,loss[0.0748876706]\n",
      "[ Tue Dec  4 21:11:24 2018], validation: iter [8640], loss[0.0309977680]\n",
      "[ Tue Dec  4 21:11:24 2018], epoch [8660], lr[0.00625000] ,loss[0.0748876706]\n",
      "[ Tue Dec  4 21:11:24 2018], validation: iter [8660], loss[0.0309971776]\n",
      "[ Tue Dec  4 21:11:25 2018], epoch [8680], lr[0.00625000] ,loss[0.0748871863]\n",
      "[ Tue Dec  4 21:11:25 2018], validation: iter [8680], loss[0.0309969094]\n",
      "[ Tue Dec  4 21:11:25 2018], epoch [8700], lr[0.00625000] ,loss[0.0748868957]\n",
      "[ Tue Dec  4 21:11:25 2018], validation: iter [8700], loss[0.0309962947]\n",
      "[ Tue Dec  4 21:11:26 2018], epoch [8720], lr[0.00625000] ,loss[0.0748869255]\n",
      "[ Tue Dec  4 21:11:26 2018], validation: iter [8720], loss[0.0309959799]\n",
      "[ Tue Dec  4 21:11:26 2018], epoch [8740], lr[0.00625000] ,loss[0.0748865157]\n",
      "[ Tue Dec  4 21:11:26 2018], validation: iter [8740], loss[0.0309957918]\n",
      "[ Tue Dec  4 21:11:27 2018], epoch [8760], lr[0.00625000] ,loss[0.0748863369]\n",
      "[ Tue Dec  4 21:11:27 2018], validation: iter [8760], loss[0.0309951752]\n",
      "[ Tue Dec  4 21:11:27 2018], epoch [8780], lr[0.00625000] ,loss[0.0748860911]\n",
      "[ Tue Dec  4 21:11:27 2018], validation: iter [8780], loss[0.0309947710]\n",
      "[ Tue Dec  4 21:11:28 2018], epoch [8800], lr[0.00625000] ,loss[0.0748857111]\n",
      "[ Tue Dec  4 21:11:28 2018], validation: iter [8800], loss[0.0309943147]\n",
      "[ Tue Dec  4 21:11:28 2018], epoch [8820], lr[0.00625000] ,loss[0.0748854876]\n",
      "[ Tue Dec  4 21:11:28 2018], validation: iter [8820], loss[0.0309938043]\n",
      "[ Tue Dec  4 21:11:29 2018], epoch [8840], lr[0.00625000] ,loss[0.0748850778]\n",
      "[ Tue Dec  4 21:11:29 2018], validation: iter [8840], loss[0.0309932865]\n",
      "[ Tue Dec  4 21:11:29 2018], epoch [8860], lr[0.00625000] ,loss[0.0748847947]\n",
      "[ Tue Dec  4 21:11:29 2018], validation: iter [8860], loss[0.0309927985]\n",
      "[ Tue Dec  4 21:11:30 2018], epoch [8880], lr[0.00625000] ,loss[0.0748842806]\n",
      "[ Tue Dec  4 21:11:30 2018], validation: iter [8880], loss[0.0309922025]\n",
      "[ Tue Dec  4 21:11:30 2018], epoch [8900], lr[0.00625000] ,loss[0.0748836994]\n",
      "[ Tue Dec  4 21:11:30 2018], validation: iter [8900], loss[0.0309915282]\n",
      "[ Tue Dec  4 21:11:31 2018], epoch [8920], lr[0.00625000] ,loss[0.0748836771]\n",
      "[ Tue Dec  4 21:11:31 2018], validation: iter [8920], loss[0.0309912227]\n",
      "[ Tue Dec  4 21:11:31 2018], epoch [8940], lr[0.00625000] ,loss[0.0748833716]\n",
      "[ Tue Dec  4 21:11:31 2018], validation: iter [8940], loss[0.0309907328]\n",
      "[ Tue Dec  4 21:11:32 2018], epoch [8960], lr[0.00625000] ,loss[0.0748831406]\n",
      "[ Tue Dec  4 21:11:32 2018], validation: iter [8960], loss[0.0309900213]\n",
      "[ Tue Dec  4 21:11:32 2018], epoch [8980], lr[0.00625000] ,loss[0.0748834237]\n",
      "[ Tue Dec  4 21:11:32 2018], validation: iter [8980], loss[0.0309899505]\n",
      "[ Tue Dec  4 21:11:33 2018], epoch [9000], lr[0.00625000] ,loss[0.0748822838]\n",
      "[ Tue Dec  4 21:11:33 2018], validation: iter [9000], loss[0.0309890360]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_9000']\n",
      "[ Tue Dec  4 21:11:33 2018], epoch [9020], lr[0.00625000] ,loss[0.0748828128]\n",
      "[ Tue Dec  4 21:11:33 2018], validation: iter [9020], loss[0.0309889372]\n",
      "[ Tue Dec  4 21:11:34 2018], epoch [9040], lr[0.00625000] ,loss[0.0748825297]\n",
      "[ Tue Dec  4 21:11:34 2018], validation: iter [9040], loss[0.0309888776]\n",
      "[ Tue Dec  4 21:11:34 2018], epoch [9060], lr[0.00625000] ,loss[0.0748820975]\n",
      "[ Tue Dec  4 21:11:34 2018], validation: iter [9060], loss[0.0309880134]\n",
      "[ Tue Dec  4 21:11:35 2018], epoch [9080], lr[0.00625000] ,loss[0.0748815313]\n",
      "[ Tue Dec  4 21:11:35 2018], validation: iter [9080], loss[0.0309878513]\n",
      "[ Tue Dec  4 21:11:35 2018], epoch [9100], lr[0.00625000] ,loss[0.0748807043]\n",
      "[ Tue Dec  4 21:11:35 2018], validation: iter [9100], loss[0.0309869535]\n",
      "[ Tue Dec  4 21:11:36 2018], epoch [9120], lr[0.00625000] ,loss[0.0748802796]\n",
      "[ Tue Dec  4 21:11:36 2018], validation: iter [9120], loss[0.0309859961]\n",
      "[ Tue Dec  4 21:11:36 2018], epoch [9140], lr[0.00625000] ,loss[0.0748800114]\n",
      "[ Tue Dec  4 21:11:36 2018], validation: iter [9140], loss[0.0309852883]\n",
      "[ Tue Dec  4 21:11:37 2018], epoch [9160], lr[0.00625000] ,loss[0.0748802349]\n",
      "[ Tue Dec  4 21:11:37 2018], validation: iter [9160], loss[0.0309849326]\n",
      "[ Tue Dec  4 21:11:37 2018], epoch [9180], lr[0.00625000] ,loss[0.0748801008]\n",
      "[ Tue Dec  4 21:11:37 2018], validation: iter [9180], loss[0.0309847705]\n",
      "[ Tue Dec  4 21:11:38 2018], epoch [9200], lr[0.00625000] ,loss[0.0748798251]\n",
      "[ Tue Dec  4 21:11:38 2018], validation: iter [9200], loss[0.0309846345]\n",
      "[ Tue Dec  4 21:11:38 2018], epoch [9220], lr[0.00625000] ,loss[0.0748794079]\n",
      "[ Tue Dec  4 21:11:38 2018], validation: iter [9220], loss[0.0309841800]\n",
      "[ Tue Dec  4 21:11:39 2018], epoch [9240], lr[0.00625000] ,loss[0.0748786256]\n",
      "[ Tue Dec  4 21:11:39 2018], validation: iter [9240], loss[0.0309832450]\n",
      "[ Tue Dec  4 21:11:39 2018], epoch [9260], lr[0.00625000] ,loss[0.0748779550]\n",
      "[ Tue Dec  4 21:11:39 2018], validation: iter [9260], loss[0.0309820808]\n",
      "[ Tue Dec  4 21:11:40 2018], epoch [9280], lr[0.00625000] ,loss[0.0748775005]\n",
      "[ Tue Dec  4 21:11:40 2018], validation: iter [9280], loss[0.0309813377]\n",
      "[ Tue Dec  4 21:11:40 2018], epoch [9300], lr[0.00625000] ,loss[0.0748774037]\n",
      "[ Tue Dec  4 21:11:40 2018], validation: iter [9300], loss[0.0309806056]\n",
      "[ Tue Dec  4 21:11:41 2018], epoch [9320], lr[0.00625000] ,loss[0.0748775899]\n",
      "[ Tue Dec  4 21:11:41 2018], validation: iter [9320], loss[0.0309809521]\n",
      "[ Tue Dec  4 21:11:41 2018], epoch [9340], lr[0.00625000] ,loss[0.0748768598]\n",
      "[ Tue Dec  4 21:11:41 2018], validation: iter [9340], loss[0.0309803616]\n",
      "[ Tue Dec  4 21:11:42 2018], epoch [9360], lr[0.00625000] ,loss[0.0748766139]\n",
      "[ Tue Dec  4 21:11:42 2018], validation: iter [9360], loss[0.0309797861]\n",
      "[ Tue Dec  4 21:11:42 2018], epoch [9380], lr[0.00625000] ,loss[0.0748762861]\n",
      "[ Tue Dec  4 21:11:42 2018], validation: iter [9380], loss[0.0309791267]\n",
      "[ Tue Dec  4 21:11:43 2018], epoch [9400], lr[0.00625000] ,loss[0.0748748109]\n",
      "[ Tue Dec  4 21:11:43 2018], validation: iter [9400], loss[0.0309792571]\n",
      "[ Tue Dec  4 21:11:43 2018], epoch [9420], lr[0.00625000] ,loss[0.0749136060]\n",
      "[ Tue Dec  4 21:11:43 2018], validation: iter [9420], loss[0.0310478657]\n",
      "[ Tue Dec  4 21:11:44 2018], epoch [9440], lr[0.00625000] ,loss[0.0748723298]\n",
      "[ Tue Dec  4 21:11:44 2018], validation: iter [9440], loss[0.0309804305]\n",
      "[ Tue Dec  4 21:11:44 2018], epoch [9460], lr[0.00625000] ,loss[0.0748756751]\n",
      "[ Tue Dec  4 21:11:44 2018], validation: iter [9460], loss[0.0309778769]\n",
      "[ Tue Dec  4 21:11:45 2018], epoch [9480], lr[0.00625000] ,loss[0.0749122575]\n",
      "[ Tue Dec  4 21:11:45 2018], validation: iter [9480], loss[0.0310910605]\n",
      "[ Tue Dec  4 21:11:45 2018], epoch [9500], lr[0.00625000] ,loss[0.0748709366]\n",
      "[ Tue Dec  4 21:11:45 2018], validation: iter [9500], loss[0.0309972651]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_9500']\n",
      "[ Tue Dec  4 21:11:46 2018], epoch [9520], lr[0.00625000] ,loss[0.0748696551]\n",
      "[ Tue Dec  4 21:11:46 2018], validation: iter [9520], loss[0.0309821293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 21:11:46 2018], epoch [9540], lr[0.00625000] ,loss[0.0748742893]\n",
      "[ Tue Dec  4 21:11:46 2018], validation: iter [9540], loss[0.0309749711]\n",
      "[ Tue Dec  4 21:11:47 2018], epoch [9560], lr[0.00625000] ,loss[0.0748731419]\n",
      "[ Tue Dec  4 21:11:47 2018], validation: iter [9560], loss[0.0309743844]\n",
      "[ Tue Dec  4 21:11:47 2018], epoch [9580], lr[0.00625000] ,loss[0.0748731792]\n",
      "[ Tue Dec  4 21:11:47 2018], validation: iter [9580], loss[0.0309715718]\n",
      "[ Tue Dec  4 21:11:48 2018], epoch [9600], lr[0.00625000] ,loss[0.0749974325]\n",
      "[ Tue Dec  4 21:11:48 2018], validation: iter [9600], loss[0.0310410745]\n",
      "[ Tue Dec  4 21:11:49 2018], epoch [9620], lr[0.00625000] ,loss[0.0749037564]\n",
      "[ Tue Dec  4 21:11:49 2018], validation: iter [9620], loss[0.0309751797]\n",
      "[ Tue Dec  4 21:11:49 2018], epoch [9640], lr[0.00625000] ,loss[0.0748765618]\n",
      "[ Tue Dec  4 21:11:49 2018], validation: iter [9640], loss[0.0309687052]\n",
      "[ Tue Dec  4 21:11:50 2018], epoch [9660], lr[0.00625000] ,loss[0.0748730376]\n",
      "[ Tue Dec  4 21:11:50 2018], validation: iter [9660], loss[0.0309695993]\n",
      "[ Tue Dec  4 21:11:50 2018], epoch [9680], lr[0.00625000] ,loss[0.0748706833]\n",
      "[ Tue Dec  4 21:11:50 2018], validation: iter [9680], loss[0.0309697017]\n",
      "[ Tue Dec  4 21:11:51 2018], epoch [9700], lr[0.00625000] ,loss[0.0749251768]\n",
      "[ Tue Dec  4 21:11:51 2018], validation: iter [9700], loss[0.0309739169]\n",
      "[ Tue Dec  4 21:11:51 2018], epoch [9720], lr[0.00625000] ,loss[0.0748717338]\n",
      "[ Tue Dec  4 21:11:51 2018], validation: iter [9720], loss[0.0309860501]\n",
      "[ Tue Dec  4 21:11:52 2018], epoch [9740], lr[0.00625000] ,loss[0.0748699456]\n",
      "[ Tue Dec  4 21:11:52 2018], validation: iter [9740], loss[0.0309699457]\n",
      "[ Tue Dec  4 21:11:52 2018], epoch [9760], lr[0.00625000] ,loss[0.0749731213]\n",
      "[ Tue Dec  4 21:11:52 2018], validation: iter [9760], loss[0.0311543699]\n",
      "[ Tue Dec  4 21:11:53 2018], epoch [9780], lr[0.00625000] ,loss[0.0748700947]\n",
      "[ Tue Dec  4 21:11:53 2018], validation: iter [9780], loss[0.0309712458]\n",
      "[ Tue Dec  4 21:11:53 2018], epoch [9800], lr[0.00625000] ,loss[0.0748737678]\n",
      "[ Tue Dec  4 21:11:53 2018], validation: iter [9800], loss[0.0309636369]\n",
      "[ Tue Dec  4 21:11:54 2018], epoch [9820], lr[0.00625000] ,loss[0.0748697966]\n",
      "[ Tue Dec  4 21:11:54 2018], validation: iter [9820], loss[0.0309652835]\n",
      "[ Tue Dec  4 21:11:54 2018], epoch [9840], lr[0.00625000] ,loss[0.0748684257]\n",
      "[ Tue Dec  4 21:11:54 2018], validation: iter [9840], loss[0.0309653953]\n",
      "[ Tue Dec  4 21:11:55 2018], epoch [9860], lr[0.00625000] ,loss[0.0748673230]\n",
      "[ Tue Dec  4 21:11:55 2018], validation: iter [9860], loss[0.0309665184]\n",
      "[ Tue Dec  4 21:11:56 2018], epoch [9880], lr[0.00625000] ,loss[0.0748671889]\n",
      "[ Tue Dec  4 21:11:56 2018], validation: iter [9880], loss[0.0309656784]\n",
      "[ Tue Dec  4 21:11:56 2018], epoch [9900], lr[0.00625000] ,loss[0.0748685300]\n",
      "[ Tue Dec  4 21:11:56 2018], validation: iter [9900], loss[0.0310015325]\n",
      "[ Tue Dec  4 21:11:57 2018], epoch [9920], lr[0.00625000] ,loss[0.0748916641]\n",
      "[ Tue Dec  4 21:11:57 2018], validation: iter [9920], loss[0.0309595168]\n",
      "[ Tue Dec  4 21:11:57 2018], epoch [9940], lr[0.00625000] ,loss[0.0748628825]\n",
      "[ Tue Dec  4 21:11:57 2018], validation: iter [9940], loss[0.0309744235]\n",
      "[ Tue Dec  4 21:11:58 2018], epoch [9960], lr[0.00625000] ,loss[0.0748665631]\n",
      "[ Tue Dec  4 21:11:58 2018], validation: iter [9960], loss[0.0309618041]\n",
      "[ Tue Dec  4 21:11:58 2018], epoch [9980], lr[0.00625000] ,loss[0.0748669133]\n",
      "[ Tue Dec  4 21:11:58 2018], validation: iter [9980], loss[0.0309618302]\n",
      "[ Tue Dec  4 21:11:59 2018], epoch [10000], lr[0.00625000] ,loss[0.0748648793]\n",
      "[ Tue Dec  4 21:11:59 2018], validation: iter [10000], loss[0.0309608709]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_10000']\n",
      "[ Tue Dec  4 21:11:59 2018], epoch [10020], lr[0.00312500] ,loss[0.0748649463]\n",
      "[ Tue Dec  4 21:11:59 2018], validation: iter [10020], loss[0.0309612602]\n",
      "[ Tue Dec  4 21:12:00 2018], epoch [10040], lr[0.00312500] ,loss[0.0748649985]\n",
      "[ Tue Dec  4 21:12:00 2018], validation: iter [10040], loss[0.0309614725]\n",
      "[ Tue Dec  4 21:12:00 2018], epoch [10060], lr[0.00312500] ,loss[0.0748640820]\n",
      "[ Tue Dec  4 21:12:00 2018], validation: iter [10060], loss[0.0309615862]\n",
      "[ Tue Dec  4 21:12:01 2018], epoch [10080], lr[0.00312500] ,loss[0.0748640746]\n",
      "[ Tue Dec  4 21:12:01 2018], validation: iter [10080], loss[0.0309620257]\n",
      "[ Tue Dec  4 21:12:01 2018], epoch [10100], lr[0.00312500] ,loss[0.0748640075]\n",
      "[ Tue Dec  4 21:12:01 2018], validation: iter [10100], loss[0.0309619159]\n",
      "[ Tue Dec  4 21:12:02 2018], epoch [10120], lr[0.00312500] ,loss[0.0748635903]\n",
      "[ Tue Dec  4 21:12:02 2018], validation: iter [10120], loss[0.0309615731]\n",
      "[ Tue Dec  4 21:12:02 2018], epoch [10140], lr[0.00312500] ,loss[0.0748630017]\n",
      "[ Tue Dec  4 21:12:02 2018], validation: iter [10140], loss[0.0309614409]\n",
      "[ Tue Dec  4 21:12:03 2018], epoch [10160], lr[0.00312500] ,loss[0.0748630613]\n",
      "[ Tue Dec  4 21:12:03 2018], validation: iter [10160], loss[0.0309616607]\n",
      "[ Tue Dec  4 21:12:03 2018], epoch [10180], lr[0.00312500] ,loss[0.0748632997]\n",
      "[ Tue Dec  4 21:12:03 2018], validation: iter [10180], loss[0.0309620760]\n",
      "[ Tue Dec  4 21:12:04 2018], epoch [10200], lr[0.00312500] ,loss[0.0748627782]\n",
      "[ Tue Dec  4 21:12:04 2018], validation: iter [10200], loss[0.0309617035]\n",
      "[ Tue Dec  4 21:12:04 2018], epoch [10220], lr[0.00312500] ,loss[0.0748622194]\n",
      "[ Tue Dec  4 21:12:04 2018], validation: iter [10220], loss[0.0309613384]\n",
      "[ Tue Dec  4 21:12:05 2018], epoch [10240], lr[0.00312500] ,loss[0.0748620555]\n",
      "[ Tue Dec  4 21:12:05 2018], validation: iter [10240], loss[0.0309614036]\n",
      "[ Tue Dec  4 21:12:05 2018], epoch [10260], lr[0.00312500] ,loss[0.0748621449]\n",
      "[ Tue Dec  4 21:12:05 2018], validation: iter [10260], loss[0.0309619922]\n",
      "[ Tue Dec  4 21:12:06 2018], epoch [10280], lr[0.00312500] ,loss[0.0748620853]\n",
      "[ Tue Dec  4 21:12:06 2018], validation: iter [10280], loss[0.0309618451]\n",
      "[ Tue Dec  4 21:12:06 2018], epoch [10300], lr[0.00312500] ,loss[0.0748613924]\n",
      "[ Tue Dec  4 21:12:06 2018], validation: iter [10300], loss[0.0309612323]\n",
      "[ Tue Dec  4 21:12:07 2018], epoch [10320], lr[0.00312500] ,loss[0.0748609453]\n",
      "[ Tue Dec  4 21:12:07 2018], validation: iter [10320], loss[0.0309609771]\n",
      "[ Tue Dec  4 21:12:07 2018], epoch [10340], lr[0.00312500] ,loss[0.0748605058]\n",
      "[ Tue Dec  4 21:12:07 2018], validation: iter [10340], loss[0.0309608448]\n",
      "[ Tue Dec  4 21:12:08 2018], epoch [10360], lr[0.00312500] ,loss[0.0748604015]\n",
      "[ Tue Dec  4 21:12:08 2018], validation: iter [10360], loss[0.0309611615]\n",
      "[ Tue Dec  4 21:12:08 2018], epoch [10380], lr[0.00312500] ,loss[0.0748602599]\n",
      "[ Tue Dec  4 21:12:08 2018], validation: iter [10380], loss[0.0309610888]\n",
      "[ Tue Dec  4 21:12:09 2018], epoch [10400], lr[0.00312500] ,loss[0.0748597533]\n",
      "[ Tue Dec  4 21:12:09 2018], validation: iter [10400], loss[0.0309610646]\n",
      "[ Tue Dec  4 21:12:09 2018], epoch [10420], lr[0.00312500] ,loss[0.0748596191]\n",
      "[ Tue Dec  4 21:12:09 2018], validation: iter [10420], loss[0.0309610739]\n",
      "[ Tue Dec  4 21:12:10 2018], epoch [10440], lr[0.00312500] ,loss[0.0748595074]\n",
      "[ Tue Dec  4 21:12:10 2018], validation: iter [10440], loss[0.0309610106]\n",
      "[ Tue Dec  4 21:12:10 2018], epoch [10460], lr[0.00312500] ,loss[0.0748592988]\n",
      "[ Tue Dec  4 21:12:10 2018], validation: iter [10460], loss[0.0309610050]\n",
      "[ Tue Dec  4 21:12:11 2018], epoch [10480], lr[0.00312500] ,loss[0.0748591870]\n",
      "[ Tue Dec  4 21:12:11 2018], validation: iter [10480], loss[0.0309612006]\n",
      "[ Tue Dec  4 21:12:11 2018], epoch [10500], lr[0.00312500] ,loss[0.0748588443]\n",
      "[ Tue Dec  4 21:12:11 2018], validation: iter [10500], loss[0.0309612919]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_10500']\n",
      "[ Tue Dec  4 21:12:12 2018], epoch [10520], lr[0.00312500] ,loss[0.0748585388]\n",
      "[ Tue Dec  4 21:12:12 2018], validation: iter [10520], loss[0.0309611037]\n",
      "[ Tue Dec  4 21:12:12 2018], epoch [10540], lr[0.00312500] ,loss[0.0748582408]\n",
      "[ Tue Dec  4 21:12:12 2018], validation: iter [10540], loss[0.0309610348]\n",
      "[ Tue Dec  4 21:12:13 2018], epoch [10560], lr[0.00312500] ,loss[0.0748580098]\n",
      "[ Tue Dec  4 21:12:13 2018], validation: iter [10560], loss[0.0309610832]\n",
      "[ Tue Dec  4 21:12:13 2018], epoch [10580], lr[0.00312500] ,loss[0.0748577788]\n",
      "[ Tue Dec  4 21:12:13 2018], validation: iter [10580], loss[0.0309610832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 21:12:14 2018], epoch [10600], lr[0.00312500] ,loss[0.0748576745]\n",
      "[ Tue Dec  4 21:12:14 2018], validation: iter [10600], loss[0.0309610665]\n",
      "[ Tue Dec  4 21:12:14 2018], epoch [10620], lr[0.00312500] ,loss[0.0748574734]\n",
      "[ Tue Dec  4 21:12:14 2018], validation: iter [10620], loss[0.0309612062]\n",
      "[ Tue Dec  4 21:12:15 2018], epoch [10640], lr[0.00312500] ,loss[0.0748571232]\n",
      "[ Tue Dec  4 21:12:15 2018], validation: iter [10640], loss[0.0309612881]\n",
      "[ Tue Dec  4 21:12:15 2018], epoch [10660], lr[0.00312500] ,loss[0.0748567507]\n",
      "[ Tue Dec  4 21:12:15 2018], validation: iter [10660], loss[0.0309611429]\n",
      "[ Tue Dec  4 21:12:16 2018], epoch [10680], lr[0.00312500] ,loss[0.0748564303]\n",
      "[ Tue Dec  4 21:12:16 2018], validation: iter [10680], loss[0.0309610646]\n",
      "[ Tue Dec  4 21:12:16 2018], epoch [10700], lr[0.00312500] ,loss[0.0748563185]\n",
      "[ Tue Dec  4 21:12:16 2018], validation: iter [10700], loss[0.0309611037]\n",
      "[ Tue Dec  4 21:12:17 2018], epoch [10720], lr[0.00312500] ,loss[0.0748556927]\n",
      "[ Tue Dec  4 21:12:17 2018], validation: iter [10720], loss[0.0309614316]\n",
      "[ Tue Dec  4 21:12:17 2018], epoch [10740], lr[0.00312500] ,loss[0.0748555064]\n",
      "[ Tue Dec  4 21:12:17 2018], validation: iter [10740], loss[0.0309609864]\n",
      "[ Tue Dec  4 21:12:18 2018], epoch [10760], lr[0.00312500] ,loss[0.0748556107]\n",
      "[ Tue Dec  4 21:12:18 2018], validation: iter [10760], loss[0.0309612844]\n",
      "[ Tue Dec  4 21:12:18 2018], epoch [10780], lr[0.00312500] ,loss[0.0748550296]\n",
      "[ Tue Dec  4 21:12:18 2018], validation: iter [10780], loss[0.0309610646]\n",
      "[ Tue Dec  4 21:12:19 2018], epoch [10800], lr[0.00312500] ,loss[0.0748550370]\n",
      "[ Tue Dec  4 21:12:19 2018], validation: iter [10800], loss[0.0309613086]\n",
      "[ Tue Dec  4 21:12:19 2018], epoch [10820], lr[0.00312500] ,loss[0.0748548061]\n",
      "[ Tue Dec  4 21:12:19 2018], validation: iter [10820], loss[0.0309610311]\n",
      "[ Tue Dec  4 21:12:20 2018], epoch [10840], lr[0.00312500] ,loss[0.0748541653]\n",
      "[ Tue Dec  4 21:12:20 2018], validation: iter [10840], loss[0.0309613850]\n",
      "[ Tue Dec  4 21:12:20 2018], epoch [10860], lr[0.00312500] ,loss[0.0748543814]\n",
      "[ Tue Dec  4 21:12:20 2018], validation: iter [10860], loss[0.0309610516]\n",
      "[ Tue Dec  4 21:12:21 2018], epoch [10880], lr[0.00312500] ,loss[0.0748539045]\n",
      "[ Tue Dec  4 21:12:21 2018], validation: iter [10880], loss[0.0309613775]\n",
      "[ Tue Dec  4 21:12:21 2018], epoch [10900], lr[0.00312500] ,loss[0.0748537481]\n",
      "[ Tue Dec  4 21:12:21 2018], validation: iter [10900], loss[0.0309609938]\n",
      "[ Tue Dec  4 21:12:22 2018], epoch [10920], lr[0.00312500] ,loss[0.0748532116]\n",
      "[ Tue Dec  4 21:12:22 2018], validation: iter [10920], loss[0.0309613943]\n",
      "[ Tue Dec  4 21:12:22 2018], epoch [10940], lr[0.00312500] ,loss[0.0748530403]\n",
      "[ Tue Dec  4 21:12:22 2018], validation: iter [10940], loss[0.0309612304]\n",
      "[ Tue Dec  4 21:12:23 2018], epoch [10960], lr[0.00312500] ,loss[0.0748524666]\n",
      "[ Tue Dec  4 21:12:23 2018], validation: iter [10960], loss[0.0309609566]\n",
      "[ Tue Dec  4 21:12:23 2018], epoch [10980], lr[0.00312500] ,loss[0.0748519972]\n",
      "[ Tue Dec  4 21:12:23 2018], validation: iter [10980], loss[0.0309610497]\n",
      "[ Tue Dec  4 21:12:24 2018], epoch [11000], lr[0.00312500] ,loss[0.0748523548]\n",
      "[ Tue Dec  4 21:12:24 2018], validation: iter [11000], loss[0.0309613571]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_11000']\n",
      "[ Tue Dec  4 21:12:24 2018], epoch [11020], lr[0.00312500] ,loss[0.0748516917]\n",
      "[ Tue Dec  4 21:12:24 2018], validation: iter [11020], loss[0.0309616365]\n",
      "[ Tue Dec  4 21:12:25 2018], epoch [11040], lr[0.00312500] ,loss[0.0748516172]\n",
      "[ Tue Dec  4 21:12:25 2018], validation: iter [11040], loss[0.0309612229]\n",
      "[ Tue Dec  4 21:12:25 2018], epoch [11060], lr[0.00312500] ,loss[0.0748515651]\n",
      "[ Tue Dec  4 21:12:25 2018], validation: iter [11060], loss[0.0309609938]\n",
      "[ Tue Dec  4 21:12:26 2018], epoch [11080], lr[0.00312500] ,loss[0.0748504698]\n",
      "[ Tue Dec  4 21:12:26 2018], validation: iter [11080], loss[0.0309607591]\n",
      "[ Tue Dec  4 21:12:26 2018], epoch [11100], lr[0.00312500] ,loss[0.0748495087]\n",
      "[ Tue Dec  4 21:12:26 2018], validation: iter [11100], loss[0.0309602935]\n",
      "[ Tue Dec  4 21:12:27 2018], epoch [11120], lr[0.00312500] ,loss[0.0748489872]\n",
      "[ Tue Dec  4 21:12:27 2018], validation: iter [11120], loss[0.0309603661]\n",
      "[ Tue Dec  4 21:12:27 2018], epoch [11140], lr[0.00312500] ,loss[0.0748497322]\n",
      "[ Tue Dec  4 21:12:27 2018], validation: iter [11140], loss[0.0309601948]\n",
      "[ Tue Dec  4 21:12:28 2018], epoch [11160], lr[0.00312500] ,loss[0.0748483688]\n",
      "[ Tue Dec  4 21:12:28 2018], validation: iter [11160], loss[0.0309602506]\n",
      "[ Tue Dec  4 21:12:28 2018], epoch [11180], lr[0.00312500] ,loss[0.0748474672]\n",
      "[ Tue Dec  4 21:12:28 2018], validation: iter [11180], loss[0.0309604667]\n",
      "[ Tue Dec  4 21:12:29 2018], epoch [11200], lr[0.00312500] ,loss[0.0748476461]\n",
      "[ Tue Dec  4 21:12:29 2018], validation: iter [11200], loss[0.0309607182]\n",
      "[ Tue Dec  4 21:12:29 2018], epoch [11220], lr[0.00312500] ,loss[0.0748473629]\n",
      "[ Tue Dec  4 21:12:29 2018], validation: iter [11220], loss[0.0309607908]\n",
      "[ Tue Dec  4 21:12:30 2018], epoch [11240], lr[0.00312500] ,loss[0.0748478621]\n",
      "[ Tue Dec  4 21:12:30 2018], validation: iter [11240], loss[0.0309607964]\n",
      "[ Tue Dec  4 21:12:30 2018], epoch [11260], lr[0.00312500] ,loss[0.0748466849]\n",
      "[ Tue Dec  4 21:12:30 2018], validation: iter [11260], loss[0.0309609082]\n",
      "[ Tue Dec  4 21:12:31 2018], epoch [11280], lr[0.00312500] ,loss[0.0748464093]\n",
      "[ Tue Dec  4 21:12:31 2018], validation: iter [11280], loss[0.0309610888]\n",
      "[ Tue Dec  4 21:12:31 2018], epoch [11300], lr[0.00312500] ,loss[0.0748463869]\n",
      "[ Tue Dec  4 21:12:31 2018], validation: iter [11300], loss[0.0309610888]\n",
      "[ Tue Dec  4 21:12:32 2018], epoch [11320], lr[0.00312500] ,loss[0.0748456046]\n",
      "[ Tue Dec  4 21:12:32 2018], validation: iter [11320], loss[0.0309610162]\n",
      "[ Tue Dec  4 21:12:32 2018], epoch [11340], lr[0.00312500] ,loss[0.0748455450]\n",
      "[ Tue Dec  4 21:12:32 2018], validation: iter [11340], loss[0.0309592653]\n",
      "[ Tue Dec  4 21:12:33 2018], epoch [11360], lr[0.00312500] ,loss[0.0748541877]\n",
      "[ Tue Dec  4 21:12:33 2018], validation: iter [11360], loss[0.0309547260]\n",
      "[ Tue Dec  4 21:12:33 2018], epoch [11380], lr[0.00312500] ,loss[0.0748439431]\n",
      "[ Tue Dec  4 21:12:33 2018], validation: iter [11380], loss[0.0309615470]\n",
      "[ Tue Dec  4 21:12:34 2018], epoch [11400], lr[0.00312500] ,loss[0.0748404711]\n",
      "[ Tue Dec  4 21:12:34 2018], validation: iter [11400], loss[0.0309683550]\n",
      "[ Tue Dec  4 21:12:34 2018], epoch [11420], lr[0.00312500] ,loss[0.0748469979]\n",
      "[ Tue Dec  4 21:12:34 2018], validation: iter [11420], loss[0.0309577584]\n",
      "[ Tue Dec  4 21:12:35 2018], epoch [11440], lr[0.00312500] ,loss[0.0748444274]\n",
      "[ Tue Dec  4 21:12:35 2018], validation: iter [11440], loss[0.0309611131]\n",
      "[ Tue Dec  4 21:12:35 2018], epoch [11460], lr[0.00312500] ,loss[0.0748433992]\n",
      "[ Tue Dec  4 21:12:35 2018], validation: iter [11460], loss[0.0309637710]\n",
      "[ Tue Dec  4 21:12:36 2018], epoch [11480], lr[0.00312500] ,loss[0.0748439580]\n",
      "[ Tue Dec  4 21:12:36 2018], validation: iter [11480], loss[0.0309603978]\n",
      "[ Tue Dec  4 21:12:36 2018], epoch [11500], lr[0.00312500] ,loss[0.0748468563]\n",
      "[ Tue Dec  4 21:12:36 2018], validation: iter [11500], loss[0.0309581719]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_11500']\n",
      "[ Tue Dec  4 21:12:37 2018], epoch [11520], lr[0.00312500] ,loss[0.0748432949]\n",
      "[ Tue Dec  4 21:12:37 2018], validation: iter [11520], loss[0.0309660695]\n",
      "[ Tue Dec  4 21:12:37 2018], epoch [11540], lr[0.00312500] ,loss[0.0748432726]\n",
      "[ Tue Dec  4 21:12:37 2018], validation: iter [11540], loss[0.0309620257]\n",
      "[ Tue Dec  4 21:12:38 2018], epoch [11560], lr[0.00312500] ,loss[0.0748425499]\n",
      "[ Tue Dec  4 21:12:38 2018], validation: iter [11560], loss[0.0309598092]\n",
      "[ Tue Dec  4 21:12:38 2018], epoch [11580], lr[0.00312500] ,loss[0.0748410970]\n",
      "[ Tue Dec  4 21:12:38 2018], validation: iter [11580], loss[0.0309666060]\n",
      "[ Tue Dec  4 21:12:39 2018], epoch [11600], lr[0.00312500] ,loss[0.0748485625]\n",
      "[ Tue Dec  4 21:12:39 2018], validation: iter [11600], loss[0.0309560765]\n",
      "[ Tue Dec  4 21:12:39 2018], epoch [11620], lr[0.00312500] ,loss[0.0748386532]\n",
      "[ Tue Dec  4 21:12:39 2018], validation: iter [11620], loss[0.0309674554]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 21:12:40 2018], epoch [11640], lr[0.00312500] ,loss[0.0748400539]\n",
      "[ Tue Dec  4 21:12:40 2018], validation: iter [11640], loss[0.0309862029]\n",
      "[ Tue Dec  4 21:12:40 2018], epoch [11660], lr[0.00312500] ,loss[0.0748477876]\n",
      "[ Tue Dec  4 21:12:40 2018], validation: iter [11660], loss[0.0309576858]\n",
      "[ Tue Dec  4 21:12:41 2018], epoch [11680], lr[0.00312500] ,loss[0.0748399273]\n",
      "[ Tue Dec  4 21:12:41 2018], validation: iter [11680], loss[0.0309616756]\n",
      "[ Tue Dec  4 21:12:41 2018], epoch [11700], lr[0.00312500] ,loss[0.0748406127]\n",
      "[ Tue Dec  4 21:12:41 2018], validation: iter [11700], loss[0.0309600048]\n",
      "[ Tue Dec  4 21:12:42 2018], epoch [11720], lr[0.00312500] ,loss[0.0748525262]\n",
      "[ Tue Dec  4 21:12:42 2018], validation: iter [11720], loss[0.0309583247]\n",
      "[ Tue Dec  4 21:12:42 2018], epoch [11740], lr[0.00312500] ,loss[0.0748352781]\n",
      "[ Tue Dec  4 21:12:42 2018], validation: iter [11740], loss[0.0309737604]\n",
      "[ Tue Dec  4 21:12:43 2018], epoch [11760], lr[0.00312500] ,loss[0.0748386085]\n",
      "[ Tue Dec  4 21:12:43 2018], validation: iter [11760], loss[0.0309634320]\n",
      "[ Tue Dec  4 21:12:43 2018], epoch [11780], lr[0.00312500] ,loss[0.0748376250]\n",
      "[ Tue Dec  4 21:12:43 2018], validation: iter [11780], loss[0.0309607051]\n",
      "[ Tue Dec  4 21:12:44 2018], epoch [11800], lr[0.00312500] ,loss[0.0748410076]\n",
      "[ Tue Dec  4 21:12:44 2018], validation: iter [11800], loss[0.0309585482]\n",
      "[ Tue Dec  4 21:12:44 2018], epoch [11820], lr[0.00312500] ,loss[0.0748494938]\n",
      "[ Tue Dec  4 21:12:44 2018], validation: iter [11820], loss[0.0309583675]\n",
      "[ Tue Dec  4 21:12:45 2018], epoch [11840], lr[0.00312500] ,loss[0.0748411641]\n",
      "[ Tue Dec  4 21:12:45 2018], validation: iter [11840], loss[0.0309586599]\n",
      "[ Tue Dec  4 21:12:45 2018], epoch [11860], lr[0.00312500] ,loss[0.0748363659]\n",
      "[ Tue Dec  4 21:12:45 2018], validation: iter [11860], loss[0.0309617426]\n",
      "[ Tue Dec  4 21:12:46 2018], epoch [11880], lr[0.00312500] ,loss[0.0748382136]\n",
      "[ Tue Dec  4 21:12:46 2018], validation: iter [11880], loss[0.0309671294]\n",
      "[ Tue Dec  4 21:12:46 2018], epoch [11900], lr[0.00312500] ,loss[0.0748342723]\n",
      "[ Tue Dec  4 21:12:46 2018], validation: iter [11900], loss[0.0309647918]\n",
      "[ Tue Dec  4 21:12:47 2018], epoch [11920], lr[0.00312500] ,loss[0.0748314932]\n",
      "[ Tue Dec  4 21:12:47 2018], validation: iter [11920], loss[0.0309744589]\n",
      "[ Tue Dec  4 21:12:47 2018], epoch [11940], lr[0.00312500] ,loss[0.0748392567]\n",
      "[ Tue Dec  4 21:12:47 2018], validation: iter [11940], loss[0.0309573244]\n",
      "[ Tue Dec  4 21:12:48 2018], epoch [11960], lr[0.00312500] ,loss[0.0748312175]\n",
      "[ Tue Dec  4 21:12:48 2018], validation: iter [11960], loss[0.0309665184]\n",
      "[ Tue Dec  4 21:12:48 2018], epoch [11980], lr[0.00312500] ,loss[0.0748349503]\n",
      "[ Tue Dec  4 21:12:48 2018], validation: iter [11980], loss[0.0309594870]\n",
      "[ Tue Dec  4 21:12:49 2018], epoch [12000], lr[0.00312500] ,loss[0.0748479366]\n",
      "[ Tue Dec  4 21:12:49 2018], validation: iter [12000], loss[0.0309577491]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_12000']\n",
      "[ Tue Dec  4 21:12:49 2018], epoch [12020], lr[0.00156250] ,loss[0.0748341456]\n",
      "[ Tue Dec  4 21:12:49 2018], validation: iter [12020], loss[0.0309585761]\n",
      "[ Tue Dec  4 21:12:50 2018], epoch [12040], lr[0.00156250] ,loss[0.0748339221]\n",
      "[ Tue Dec  4 21:12:50 2018], validation: iter [12040], loss[0.0309603643]\n",
      "[ Tue Dec  4 21:12:50 2018], epoch [12060], lr[0.00156250] ,loss[0.0748337060]\n",
      "[ Tue Dec  4 21:12:50 2018], validation: iter [12060], loss[0.0309612434]\n",
      "[ Tue Dec  4 21:12:51 2018], epoch [12080], lr[0.00156250] ,loss[0.0748326033]\n",
      "[ Tue Dec  4 21:12:51 2018], validation: iter [12080], loss[0.0309615973]\n",
      "[ Tue Dec  4 21:12:51 2018], epoch [12100], lr[0.00156250] ,loss[0.0748330057]\n",
      "[ Tue Dec  4 21:12:51 2018], validation: iter [12100], loss[0.0309616402]\n",
      "[ Tue Dec  4 21:12:52 2018], epoch [12120], lr[0.00156250] ,loss[0.0748326853]\n",
      "[ Tue Dec  4 21:12:52 2018], validation: iter [12120], loss[0.0309616067]\n",
      "[ Tue Dec  4 21:12:52 2018], epoch [12140], lr[0.00156250] ,loss[0.0748324841]\n",
      "[ Tue Dec  4 21:12:52 2018], validation: iter [12140], loss[0.0309615918]\n",
      "[ Tue Dec  4 21:12:53 2018], epoch [12160], lr[0.00156250] ,loss[0.0748323426]\n",
      "[ Tue Dec  4 21:12:53 2018], validation: iter [12160], loss[0.0309615899]\n",
      "[ Tue Dec  4 21:12:53 2018], epoch [12180], lr[0.00156250] ,loss[0.0748321563]\n",
      "[ Tue Dec  4 21:12:53 2018], validation: iter [12180], loss[0.0309615824]\n",
      "[ Tue Dec  4 21:12:54 2018], epoch [12200], lr[0.00156250] ,loss[0.0748319477]\n",
      "[ Tue Dec  4 21:12:54 2018], validation: iter [12200], loss[0.0309615787]\n",
      "[ Tue Dec  4 21:12:54 2018], epoch [12220], lr[0.00156250] ,loss[0.0748317167]\n",
      "[ Tue Dec  4 21:12:54 2018], validation: iter [12220], loss[0.0309615824]\n",
      "[ Tue Dec  4 21:12:55 2018], epoch [12240], lr[0.00156250] ,loss[0.0748314857]\n",
      "[ Tue Dec  4 21:12:55 2018], validation: iter [12240], loss[0.0309615750]\n",
      "[ Tue Dec  4 21:12:55 2018], epoch [12260], lr[0.00156250] ,loss[0.0748312920]\n",
      "[ Tue Dec  4 21:12:55 2018], validation: iter [12260], loss[0.0309615824]\n",
      "[ Tue Dec  4 21:12:56 2018], epoch [12280], lr[0.00156250] ,loss[0.0748310536]\n",
      "[ Tue Dec  4 21:12:56 2018], validation: iter [12280], loss[0.0309615936]\n",
      "[ Tue Dec  4 21:12:56 2018], epoch [12300], lr[0.00156250] ,loss[0.0748308748]\n",
      "[ Tue Dec  4 21:12:56 2018], validation: iter [12300], loss[0.0309615824]\n",
      "[ Tue Dec  4 21:12:57 2018], epoch [12320], lr[0.00156250] ,loss[0.0748307630]\n",
      "[ Tue Dec  4 21:12:57 2018], validation: iter [12320], loss[0.0309615843]\n",
      "[ Tue Dec  4 21:12:57 2018], epoch [12340], lr[0.00156250] ,loss[0.0748304725]\n",
      "[ Tue Dec  4 21:12:57 2018], validation: iter [12340], loss[0.0309615936]\n",
      "[ Tue Dec  4 21:12:58 2018], epoch [12360], lr[0.00156250] ,loss[0.0748302415]\n",
      "[ Tue Dec  4 21:12:58 2018], validation: iter [12360], loss[0.0309615824]\n",
      "[ Tue Dec  4 21:12:58 2018], epoch [12380], lr[0.00156250] ,loss[0.0748300031]\n",
      "[ Tue Dec  4 21:12:58 2018], validation: iter [12380], loss[0.0309615545]\n",
      "[ Tue Dec  4 21:12:59 2018], epoch [12400], lr[0.00156250] ,loss[0.0748297721]\n",
      "[ Tue Dec  4 21:12:59 2018], validation: iter [12400], loss[0.0309615918]\n",
      "[ Tue Dec  4 21:12:59 2018], epoch [12420], lr[0.00156250] ,loss[0.0748295933]\n",
      "[ Tue Dec  4 21:12:59 2018], validation: iter [12420], loss[0.0309616067]\n",
      "[ Tue Dec  4 21:13:00 2018], epoch [12440], lr[0.00156250] ,loss[0.0748293549]\n",
      "[ Tue Dec  4 21:13:00 2018], validation: iter [12440], loss[0.0309615340]\n",
      "[ Tue Dec  4 21:13:00 2018], epoch [12460], lr[0.00156250] ,loss[0.0748291463]\n",
      "[ Tue Dec  4 21:13:00 2018], validation: iter [12460], loss[0.0309615675]\n",
      "[ Tue Dec  4 21:13:01 2018], epoch [12480], lr[0.00156250] ,loss[0.0748289153]\n",
      "[ Tue Dec  4 21:13:01 2018], validation: iter [12480], loss[0.0309615470]\n",
      "[ Tue Dec  4 21:13:01 2018], epoch [12500], lr[0.00156250] ,loss[0.0748286620]\n",
      "[ Tue Dec  4 21:13:01 2018], validation: iter [12500], loss[0.0309614725]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_12500']\n",
      "[ Tue Dec  4 21:13:02 2018], epoch [12520], lr[0.00156250] ,loss[0.0748282820]\n",
      "[ Tue Dec  4 21:13:02 2018], validation: iter [12520], loss[0.0309613161]\n",
      "[ Tue Dec  4 21:13:02 2018], epoch [12540], lr[0.00156250] ,loss[0.0748277530]\n",
      "[ Tue Dec  4 21:13:02 2018], validation: iter [12540], loss[0.0309608690]\n",
      "[ Tue Dec  4 21:13:03 2018], epoch [12560], lr[0.00156250] ,loss[0.0748275518]\n",
      "[ Tue Dec  4 21:13:03 2018], validation: iter [12560], loss[0.0309609473]\n",
      "[ Tue Dec  4 21:13:03 2018], epoch [12580], lr[0.00156250] ,loss[0.0748273358]\n",
      "[ Tue Dec  4 21:13:03 2018], validation: iter [12580], loss[0.0309609864]\n",
      "[ Tue Dec  4 21:13:04 2018], epoch [12600], lr[0.00156250] ,loss[0.0748268217]\n",
      "[ Tue Dec  4 21:13:04 2018], validation: iter [12600], loss[0.0309606660]\n",
      "[ Tue Dec  4 21:13:04 2018], epoch [12620], lr[0.00156250] ,loss[0.0748267397]\n",
      "[ Tue Dec  4 21:13:04 2018], validation: iter [12620], loss[0.0309609137]\n",
      "[ Tue Dec  4 21:13:05 2018], epoch [12640], lr[0.00156250] ,loss[0.0748266503]\n",
      "[ Tue Dec  4 21:13:05 2018], validation: iter [12640], loss[0.0309609286]\n",
      "[ Tue Dec  4 21:13:05 2018], epoch [12660], lr[0.00156250] ,loss[0.0748264790]\n",
      "[ Tue Dec  4 21:13:05 2018], validation: iter [12660], loss[0.0309608001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 21:13:06 2018], epoch [12680], lr[0.00156250] ,loss[0.0748261660]\n",
      "[ Tue Dec  4 21:13:06 2018], validation: iter [12680], loss[0.0309609156]\n",
      "[ Tue Dec  4 21:13:06 2018], epoch [12700], lr[0.00156250] ,loss[0.0748259202]\n",
      "[ Tue Dec  4 21:13:06 2018], validation: iter [12700], loss[0.0309609864]\n",
      "[ Tue Dec  4 21:13:07 2018], epoch [12720], lr[0.00156250] ,loss[0.0748257041]\n",
      "[ Tue Dec  4 21:13:07 2018], validation: iter [12720], loss[0.0309608951]\n",
      "[ Tue Dec  4 21:13:07 2018], epoch [12740], lr[0.00156250] ,loss[0.0748253390]\n",
      "[ Tue Dec  4 21:13:07 2018], validation: iter [12740], loss[0.0309610050]\n",
      "[ Tue Dec  4 21:13:08 2018], epoch [12760], lr[0.00156250] ,loss[0.0748252794]\n",
      "[ Tue Dec  4 21:13:08 2018], validation: iter [12760], loss[0.0309610330]\n",
      "[ Tue Dec  4 21:13:08 2018], epoch [12780], lr[0.00156250] ,loss[0.0748249143]\n",
      "[ Tue Dec  4 21:13:08 2018], validation: iter [12780], loss[0.0309610106]\n",
      "[ Tue Dec  4 21:13:09 2018], epoch [12800], lr[0.00156250] ,loss[0.0748246610]\n",
      "[ Tue Dec  4 21:13:09 2018], validation: iter [12800], loss[0.0309610832]\n",
      "[ Tue Dec  4 21:13:09 2018], epoch [12820], lr[0.00156250] ,loss[0.0748243853]\n",
      "[ Tue Dec  4 21:13:09 2018], validation: iter [12820], loss[0.0309610404]\n",
      "[ Tue Dec  4 21:13:10 2018], epoch [12840], lr[0.00156250] ,loss[0.0748241171]\n",
      "[ Tue Dec  4 21:13:10 2018], validation: iter [12840], loss[0.0309610162]\n",
      "[ Tue Dec  4 21:13:10 2018], epoch [12860], lr[0.00156250] ,loss[0.0748240128]\n",
      "[ Tue Dec  4 21:13:10 2018], validation: iter [12860], loss[0.0309612211]\n",
      "[ Tue Dec  4 21:13:11 2018], epoch [12880], lr[0.00156250] ,loss[0.0748235881]\n",
      "[ Tue Dec  4 21:13:11 2018], validation: iter [12880], loss[0.0309611037]\n",
      "[ Tue Dec  4 21:13:11 2018], epoch [12900], lr[0.00156250] ,loss[0.0748232603]\n",
      "[ Tue Dec  4 21:13:11 2018], validation: iter [12900], loss[0.0309610255]\n",
      "[ Tue Dec  4 21:13:12 2018], epoch [12920], lr[0.00156250] ,loss[0.0748231709]\n",
      "[ Tue Dec  4 21:13:12 2018], validation: iter [12920], loss[0.0309613235]\n",
      "[ Tue Dec  4 21:13:12 2018], epoch [12940], lr[0.00156250] ,loss[0.0748227611]\n",
      "[ Tue Dec  4 21:13:12 2018], validation: iter [12940], loss[0.0309610944]\n",
      "[ Tue Dec  4 21:13:12 2018], epoch [12960], lr[0.00156250] ,loss[0.0748224482]\n",
      "[ Tue Dec  4 21:13:12 2018], validation: iter [12960], loss[0.0309610553]\n",
      "[ Tue Dec  4 21:13:13 2018], epoch [12980], lr[0.00156250] ,loss[0.0748225972]\n",
      "[ Tue Dec  4 21:13:13 2018], validation: iter [12980], loss[0.0309614595]\n",
      "[ Tue Dec  4 21:13:13 2018], epoch [13000], lr[0.00156250] ,loss[0.0748220831]\n",
      "[ Tue Dec  4 21:13:13 2018], validation: iter [13000], loss[0.0309614111]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_13000']\n",
      "[ Tue Dec  4 21:13:14 2018], epoch [13020], lr[0.00156250] ,loss[0.0748219118]\n",
      "[ Tue Dec  4 21:13:14 2018], validation: iter [13020], loss[0.0309613477]\n",
      "[ Tue Dec  4 21:13:15 2018], epoch [13040], lr[0.00156250] ,loss[0.0748215765]\n",
      "[ Tue Dec  4 21:13:15 2018], validation: iter [13040], loss[0.0309614260]\n",
      "[ Tue Dec  4 21:13:15 2018], epoch [13060], lr[0.00156250] ,loss[0.0748213455]\n",
      "[ Tue Dec  4 21:13:15 2018], validation: iter [13060], loss[0.0309614278]\n",
      "[ Tue Dec  4 21:13:16 2018], epoch [13080], lr[0.00156250] ,loss[0.0748211667]\n",
      "[ Tue Dec  4 21:13:16 2018], validation: iter [13080], loss[0.0309613869]\n",
      "[ Tue Dec  4 21:13:16 2018], epoch [13100], lr[0.00156250] ,loss[0.0748203844]\n",
      "[ Tue Dec  4 21:13:16 2018], validation: iter [13100], loss[0.0309609920]\n",
      "[ Tue Dec  4 21:13:17 2018], epoch [13120], lr[0.00156250] ,loss[0.0748204514]\n",
      "[ Tue Dec  4 21:13:17 2018], validation: iter [13120], loss[0.0309614372]\n",
      "[ Tue Dec  4 21:13:17 2018], epoch [13140], lr[0.00156250] ,loss[0.0748198628]\n",
      "[ Tue Dec  4 21:13:17 2018], validation: iter [13140], loss[0.0309610348]\n",
      "[ Tue Dec  4 21:13:18 2018], epoch [13160], lr[0.00156250] ,loss[0.0748197883]\n",
      "[ Tue Dec  4 21:13:18 2018], validation: iter [13160], loss[0.0309611578]\n",
      "[ Tue Dec  4 21:13:18 2018], epoch [13180], lr[0.00156250] ,loss[0.0748193339]\n",
      "[ Tue Dec  4 21:13:18 2018], validation: iter [13180], loss[0.0309612006]\n",
      "[ Tue Dec  4 21:13:19 2018], epoch [13200], lr[0.00156250] ,loss[0.0748194084]\n",
      "[ Tue Dec  4 21:13:19 2018], validation: iter [13200], loss[0.0309616327]\n",
      "[ Tue Dec  4 21:13:19 2018], epoch [13220], lr[0.00156250] ,loss[0.0748188198]\n",
      "[ Tue Dec  4 21:13:19 2018], validation: iter [13220], loss[0.0309616160]\n",
      "[ Tue Dec  4 21:13:20 2018], epoch [13240], lr[0.00156250] ,loss[0.0748185068]\n",
      "[ Tue Dec  4 21:13:20 2018], validation: iter [13240], loss[0.0309612285]\n",
      "[ Tue Dec  4 21:13:20 2018], epoch [13260], lr[0.00156250] ,loss[0.0748168379]\n",
      "[ Tue Dec  4 21:13:20 2018], validation: iter [13260], loss[0.0309607368]\n",
      "[ Tue Dec  4 21:13:21 2018], epoch [13280], lr[0.00156250] ,loss[0.0748171285]\n",
      "[ Tue Dec  4 21:13:21 2018], validation: iter [13280], loss[0.0309606157]\n",
      "[ Tue Dec  4 21:13:21 2018], epoch [13300], lr[0.00156250] ,loss[0.0748168752]\n",
      "[ Tue Dec  4 21:13:21 2018], validation: iter [13300], loss[0.0309606735]\n",
      "[ Tue Dec  4 21:13:22 2018], epoch [13320], lr[0.00156250] ,loss[0.0748158023]\n",
      "[ Tue Dec  4 21:13:22 2018], validation: iter [13320], loss[0.0309606194]\n",
      "[ Tue Dec  4 21:13:22 2018], epoch [13340], lr[0.00156250] ,loss[0.0748155713]\n",
      "[ Tue Dec  4 21:13:22 2018], validation: iter [13340], loss[0.0309605766]\n",
      "[ Tue Dec  4 21:13:23 2018], epoch [13360], lr[0.00156250] ,loss[0.0748159513]\n",
      "[ Tue Dec  4 21:13:23 2018], validation: iter [13360], loss[0.0309606474]\n",
      "[ Tue Dec  4 21:13:23 2018], epoch [13380], lr[0.00156250] ,loss[0.0748158693]\n",
      "[ Tue Dec  4 21:13:23 2018], validation: iter [13380], loss[0.0309611913]\n",
      "[ Tue Dec  4 21:13:24 2018], epoch [13400], lr[0.00156250] ,loss[0.0748142600]\n",
      "[ Tue Dec  4 21:13:24 2018], validation: iter [13400], loss[0.0309716202]\n",
      "[ Tue Dec  4 21:13:24 2018], epoch [13420], lr[0.00156250] ,loss[0.0748179331]\n",
      "[ Tue Dec  4 21:13:24 2018], validation: iter [13420], loss[0.0309605803]\n",
      "[ Tue Dec  4 21:13:25 2018], epoch [13440], lr[0.00156250] ,loss[0.0748147070]\n",
      "[ Tue Dec  4 21:13:25 2018], validation: iter [13440], loss[0.0309595224]\n",
      "[ Tue Dec  4 21:13:25 2018], epoch [13460], lr[0.00156250] ,loss[0.0748139694]\n",
      "[ Tue Dec  4 21:13:25 2018], validation: iter [13460], loss[0.0309605766]\n",
      "[ Tue Dec  4 21:13:26 2018], epoch [13480], lr[0.00156250] ,loss[0.0748141333]\n",
      "[ Tue Dec  4 21:13:26 2018], validation: iter [13480], loss[0.0309606697]\n",
      "[ Tue Dec  4 21:13:26 2018], epoch [13500], lr[0.00156250] ,loss[0.0748134181]\n",
      "[ Tue Dec  4 21:13:26 2018], validation: iter [13500], loss[0.0309603531]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_13500']\n",
      "[ Tue Dec  4 21:13:27 2018], epoch [13520], lr[0.00156250] ,loss[0.0748129189]\n",
      "[ Tue Dec  4 21:13:27 2018], validation: iter [13520], loss[0.0309603531]\n",
      "[ Tue Dec  4 21:13:27 2018], epoch [13540], lr[0.00156250] ,loss[0.0748128146]\n",
      "[ Tue Dec  4 21:13:27 2018], validation: iter [13540], loss[0.0309603605]\n",
      "[ Tue Dec  4 21:13:28 2018], epoch [13560], lr[0.00156250] ,loss[0.0748136640]\n",
      "[ Tue Dec  4 21:13:28 2018], validation: iter [13560], loss[0.0309649091]\n",
      "[ Tue Dec  4 21:13:28 2018], epoch [13580], lr[0.00156250] ,loss[0.0748137012]\n",
      "[ Tue Dec  4 21:13:28 2018], validation: iter [13580], loss[0.0309604909]\n",
      "[ Tue Dec  4 21:13:29 2018], epoch [13600], lr[0.00156250] ,loss[0.0748154372]\n",
      "[ Tue Dec  4 21:13:29 2018], validation: iter [13600], loss[0.0309574958]\n",
      "[ Tue Dec  4 21:13:29 2018], epoch [13620], lr[0.00156250] ,loss[0.0748111457]\n",
      "[ Tue Dec  4 21:13:29 2018], validation: iter [13620], loss[0.0309640765]\n",
      "[ Tue Dec  4 21:13:30 2018], epoch [13640], lr[0.00156250] ,loss[0.0748128667]\n",
      "[ Tue Dec  4 21:13:30 2018], validation: iter [13640], loss[0.0309592243]\n",
      "[ Tue Dec  4 21:13:30 2018], epoch [13660], lr[0.00156250] ,loss[0.0748121887]\n",
      "[ Tue Dec  4 21:13:30 2018], validation: iter [13660], loss[0.0309594050]\n",
      "[ Tue Dec  4 21:13:31 2018], epoch [13680], lr[0.00156250] ,loss[0.0748221725]\n",
      "[ Tue Dec  4 21:13:31 2018], validation: iter [13680], loss[0.0309569780]\n",
      "[ Tue Dec  4 21:13:31 2018], epoch [13700], lr[0.00156250] ,loss[0.0748105496]\n",
      "[ Tue Dec  4 21:13:31 2018], validation: iter [13700], loss[0.0309602488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 21:13:32 2018], epoch [13720], lr[0.00156250] ,loss[0.0748089477]\n",
      "[ Tue Dec  4 21:13:32 2018], validation: iter [13720], loss[0.0309621394]\n",
      "[ Tue Dec  4 21:13:32 2018], epoch [13740], lr[0.00156250] ,loss[0.0748098344]\n",
      "[ Tue Dec  4 21:13:32 2018], validation: iter [13740], loss[0.0309606157]\n",
      "[ Tue Dec  4 21:13:33 2018], epoch [13760], lr[0.00156250] ,loss[0.0748124197]\n",
      "[ Tue Dec  4 21:13:33 2018], validation: iter [13760], loss[0.0309661273]\n",
      "[ Tue Dec  4 21:13:33 2018], epoch [13780], lr[0.00156250] ,loss[0.0748077929]\n",
      "[ Tue Dec  4 21:13:33 2018], validation: iter [13780], loss[0.0309596919]\n",
      "[ Tue Dec  4 21:13:34 2018], epoch [13800], lr[0.00156250] ,loss[0.0748047233]\n",
      "[ Tue Dec  4 21:13:34 2018], validation: iter [13800], loss[0.0309775677]\n",
      "[ Tue Dec  4 21:13:34 2018], epoch [13820], lr[0.00156250] ,loss[0.0748059377]\n",
      "[ Tue Dec  4 21:13:34 2018], validation: iter [13820], loss[0.0309657473]\n",
      "[ Tue Dec  4 21:13:35 2018], epoch [13840], lr[0.00156250] ,loss[0.0748071522]\n",
      "[ Tue Dec  4 21:13:35 2018], validation: iter [13840], loss[0.0309627298]\n",
      "[ Tue Dec  4 21:13:35 2018], epoch [13860], lr[0.00156250] ,loss[0.0748083517]\n",
      "[ Tue Dec  4 21:13:35 2018], validation: iter [13860], loss[0.0309614949]\n",
      "[ Tue Dec  4 21:13:36 2018], epoch [13880], lr[0.00156250] ,loss[0.0748075172]\n",
      "[ Tue Dec  4 21:13:36 2018], validation: iter [13880], loss[0.0309609734]\n",
      "[ Tue Dec  4 21:13:36 2018], epoch [13900], lr[0.00156250] ,loss[0.0748070478]\n",
      "[ Tue Dec  4 21:13:36 2018], validation: iter [13900], loss[0.0309607759]\n",
      "[ Tue Dec  4 21:13:37 2018], epoch [13920], lr[0.00156250] ,loss[0.0748076066]\n",
      "[ Tue Dec  4 21:13:37 2018], validation: iter [13920], loss[0.0309598502]\n",
      "[ Tue Dec  4 21:13:37 2018], epoch [13940], lr[0.00156250] ,loss[0.0748238117]\n",
      "[ Tue Dec  4 21:13:37 2018], validation: iter [13940], loss[0.0309576634]\n",
      "[ Tue Dec  4 21:13:38 2018], epoch [13960], lr[0.00156250] ,loss[0.0748061016]\n",
      "[ Tue Dec  4 21:13:38 2018], validation: iter [13960], loss[0.0309625082]\n",
      "[ Tue Dec  4 21:13:38 2018], epoch [13980], lr[0.00156250] ,loss[0.0748054311]\n",
      "[ Tue Dec  4 21:13:38 2018], validation: iter [13980], loss[0.0309627075]\n",
      "[ Tue Dec  4 21:13:39 2018], epoch [14000], lr[0.00156250] ,loss[0.0748063400]\n",
      "[ Tue Dec  4 21:13:39 2018], validation: iter [14000], loss[0.0309615470]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_14000']\n",
      "[ Tue Dec  4 21:13:39 2018], epoch [14020], lr[0.00078125] ,loss[0.0748051107]\n",
      "[ Tue Dec  4 21:13:39 2018], validation: iter [14020], loss[0.0309607908]\n",
      "[ Tue Dec  4 21:13:40 2018], epoch [14040], lr[0.00078125] ,loss[0.0748040080]\n",
      "[ Tue Dec  4 21:13:40 2018], validation: iter [14040], loss[0.0309606567]\n",
      "[ Tue Dec  4 21:13:40 2018], epoch [14060], lr[0.00078125] ,loss[0.0748042241]\n",
      "[ Tue Dec  4 21:13:40 2018], validation: iter [14060], loss[0.0309606325]\n",
      "[ Tue Dec  4 21:13:41 2018], epoch [14080], lr[0.00078125] ,loss[0.0748039931]\n",
      "[ Tue Dec  4 21:13:41 2018], validation: iter [14080], loss[0.0309605170]\n",
      "[ Tue Dec  4 21:13:41 2018], epoch [14100], lr[0.00078125] ,loss[0.0748038888]\n",
      "[ Tue Dec  4 21:13:41 2018], validation: iter [14100], loss[0.0309605841]\n",
      "[ Tue Dec  4 21:13:42 2018], epoch [14120], lr[0.00078125] ,loss[0.0748039410]\n",
      "[ Tue Dec  4 21:13:42 2018], validation: iter [14120], loss[0.0309604928]\n",
      "[ Tue Dec  4 21:13:42 2018], epoch [14140], lr[0.00078125] ,loss[0.0748035386]\n",
      "[ Tue Dec  4 21:13:42 2018], validation: iter [14140], loss[0.0309605915]\n",
      "[ Tue Dec  4 21:13:43 2018], epoch [14160], lr[0.00078125] ,loss[0.0748032779]\n",
      "[ Tue Dec  4 21:13:43 2018], validation: iter [14160], loss[0.0309604518]\n",
      "[ Tue Dec  4 21:13:43 2018], epoch [14180], lr[0.00078125] ,loss[0.0748030543]\n",
      "[ Tue Dec  4 21:13:43 2018], validation: iter [14180], loss[0.0309605487]\n",
      "[ Tue Dec  4 21:13:44 2018], epoch [14200], lr[0.00078125] ,loss[0.0748026893]\n",
      "[ Tue Dec  4 21:13:44 2018], validation: iter [14200], loss[0.0309604313]\n",
      "[ Tue Dec  4 21:13:44 2018], epoch [14220], lr[0.00078125] ,loss[0.0748031214]\n",
      "[ Tue Dec  4 21:13:44 2018], validation: iter [14220], loss[0.0309606306]\n",
      "[ Tue Dec  4 21:13:45 2018], epoch [14240], lr[0.00078125] ,loss[0.0748025030]\n",
      "[ Tue Dec  4 21:13:45 2018], validation: iter [14240], loss[0.0309604984]\n",
      "[ Tue Dec  4 21:13:46 2018], epoch [14260], lr[0.00078125] ,loss[0.0748023614]\n",
      "[ Tue Dec  4 21:13:46 2018], validation: iter [14260], loss[0.0309605412]\n",
      "[ Tue Dec  4 21:13:47 2018], epoch [14280], lr[0.00078125] ,loss[0.0748024806]\n",
      "[ Tue Dec  4 21:13:47 2018], validation: iter [14280], loss[0.0309606642]\n",
      "[ Tue Dec  4 21:13:47 2018], epoch [14300], lr[0.00078125] ,loss[0.0748018473]\n",
      "[ Tue Dec  4 21:13:47 2018], validation: iter [14300], loss[0.0309604630]\n",
      "[ Tue Dec  4 21:13:48 2018], epoch [14320], lr[0.00078125] ,loss[0.0748016685]\n",
      "[ Tue Dec  4 21:13:48 2018], validation: iter [14320], loss[0.0309604108]\n",
      "[ Tue Dec  4 21:13:48 2018], epoch [14340], lr[0.00078125] ,loss[0.0748015642]\n",
      "[ Tue Dec  4 21:13:48 2018], validation: iter [14340], loss[0.0309604667]\n",
      "[ Tue Dec  4 21:13:49 2018], epoch [14360], lr[0.00078125] ,loss[0.0748016164]\n",
      "[ Tue Dec  4 21:13:49 2018], validation: iter [14360], loss[0.0309606045]\n",
      "[ Tue Dec  4 21:13:49 2018], epoch [14380], lr[0.00078125] ,loss[0.0748012587]\n",
      "[ Tue Dec  4 21:13:49 2018], validation: iter [14380], loss[0.0309605226]\n",
      "[ Tue Dec  4 21:13:50 2018], epoch [14400], lr[0.00078125] ,loss[0.0748011470]\n",
      "[ Tue Dec  4 21:13:50 2018], validation: iter [14400], loss[0.0309606101]\n",
      "[ Tue Dec  4 21:13:50 2018], epoch [14420], lr[0.00078125] ,loss[0.0748007745]\n",
      "[ Tue Dec  4 21:13:50 2018], validation: iter [14420], loss[0.0309606101]\n",
      "[ Tue Dec  4 21:13:51 2018], epoch [14440], lr[0.00078125] ,loss[0.0748006105]\n",
      "[ Tue Dec  4 21:13:51 2018], validation: iter [14440], loss[0.0309604295]\n",
      "[ Tue Dec  4 21:13:51 2018], epoch [14460], lr[0.00078125] ,loss[0.0748004317]\n",
      "[ Tue Dec  4 21:13:51 2018], validation: iter [14460], loss[0.0309604704]\n",
      "[ Tue Dec  4 21:13:52 2018], epoch [14480], lr[0.00078125] ,loss[0.0748010874]\n",
      "[ Tue Dec  4 21:13:52 2018], validation: iter [14480], loss[0.0309606828]\n",
      "[ Tue Dec  4 21:13:52 2018], epoch [14500], lr[0.00078125] ,loss[0.0747999400]\n",
      "[ Tue Dec  4 21:13:52 2018], validation: iter [14500], loss[0.0309604388]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_14500']\n",
      "[ Tue Dec  4 21:13:53 2018], epoch [14520], lr[0.00078125] ,loss[0.0747997239]\n",
      "[ Tue Dec  4 21:13:53 2018], validation: iter [14520], loss[0.0309605524]\n",
      "[ Tue Dec  4 21:13:54 2018], epoch [14540], lr[0.00078125] ,loss[0.0747995302]\n",
      "[ Tue Dec  4 21:13:54 2018], validation: iter [14540], loss[0.0309604257]\n",
      "[ Tue Dec  4 21:13:54 2018], epoch [14560], lr[0.00078125] ,loss[0.0747994706]\n",
      "[ Tue Dec  4 21:13:54 2018], validation: iter [14560], loss[0.0309604928]\n",
      "[ Tue Dec  4 21:13:55 2018], epoch [14580], lr[0.00078125] ,loss[0.0747996122]\n",
      "[ Tue Dec  4 21:13:55 2018], validation: iter [14580], loss[0.0309604742]\n",
      "[ Tue Dec  4 21:13:55 2018], epoch [14600], lr[0.00078125] ,loss[0.0747994557]\n",
      "[ Tue Dec  4 21:13:55 2018], validation: iter [14600], loss[0.0309603810]\n",
      "[ Tue Dec  4 21:13:56 2018], epoch [14620], lr[0.00078125] ,loss[0.0747985169]\n",
      "[ Tue Dec  4 21:13:56 2018], validation: iter [14620], loss[0.0309604462]\n",
      "[ Tue Dec  4 21:13:56 2018], epoch [14640], lr[0.00078125] ,loss[0.0747991130]\n",
      "[ Tue Dec  4 21:13:56 2018], validation: iter [14640], loss[0.0309605226]\n",
      "[ Tue Dec  4 21:13:57 2018], epoch [14660], lr[0.00078125] ,loss[0.0747983083]\n",
      "[ Tue Dec  4 21:13:57 2018], validation: iter [14660], loss[0.0309602115]\n",
      "[ Tue Dec  4 21:13:57 2018], epoch [14680], lr[0.00078125] ,loss[0.0747986883]\n",
      "[ Tue Dec  4 21:13:57 2018], validation: iter [14680], loss[0.0309606697]\n",
      "[ Tue Dec  4 21:13:58 2018], epoch [14700], lr[0.00078125] ,loss[0.0747984797]\n",
      "[ Tue Dec  4 21:13:58 2018], validation: iter [14700], loss[0.0309604295]\n",
      "[ Tue Dec  4 21:13:58 2018], epoch [14720], lr[0.00078125] ,loss[0.0747977942]\n",
      "[ Tue Dec  4 21:13:58 2018], validation: iter [14720], loss[0.0309604369]\n",
      "[ Tue Dec  4 21:13:58 2018], epoch [14740], lr[0.00078125] ,loss[0.0747978836]\n",
      "[ Tue Dec  4 21:13:58 2018], validation: iter [14740], loss[0.0309603717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 21:13:59 2018], epoch [14760], lr[0.00078125] ,loss[0.0747974515]\n",
      "[ Tue Dec  4 21:13:59 2018], validation: iter [14760], loss[0.0309607275]\n",
      "[ Tue Dec  4 21:13:59 2018], epoch [14780], lr[0.00078125] ,loss[0.0747971535]\n",
      "[ Tue Dec  4 21:13:59 2018], validation: iter [14780], loss[0.0309603736]\n",
      "[ Tue Dec  4 21:14:00 2018], epoch [14800], lr[0.00078125] ,loss[0.0747972056]\n",
      "[ Tue Dec  4 21:14:00 2018], validation: iter [14800], loss[0.0309605710]\n",
      "[ Tue Dec  4 21:14:00 2018], epoch [14820], lr[0.00078125] ,loss[0.0747973546]\n",
      "[ Tue Dec  4 21:14:00 2018], validation: iter [14820], loss[0.0309603643]\n",
      "[ Tue Dec  4 21:14:01 2018], epoch [14840], lr[0.00078125] ,loss[0.0747968256]\n",
      "[ Tue Dec  4 21:14:01 2018], validation: iter [14840], loss[0.0309605319]\n",
      "[ Tue Dec  4 21:14:01 2018], epoch [14860], lr[0.00078125] ,loss[0.0747964606]\n",
      "[ Tue Dec  4 21:14:01 2018], validation: iter [14860], loss[0.0309604742]\n",
      "[ Tue Dec  4 21:14:02 2018], epoch [14880], lr[0.00078125] ,loss[0.0747957230]\n",
      "[ Tue Dec  4 21:14:02 2018], validation: iter [14880], loss[0.0309600532]\n",
      "[ Tue Dec  4 21:14:02 2018], epoch [14900], lr[0.00078125] ,loss[0.0747963488]\n",
      "[ Tue Dec  4 21:14:02 2018], validation: iter [14900], loss[0.0309603959]\n",
      "[ Tue Dec  4 21:14:03 2018], epoch [14920], lr[0.00078125] ,loss[0.0747957975]\n",
      "[ Tue Dec  4 21:14:03 2018], validation: iter [14920], loss[0.0309604462]\n",
      "[ Tue Dec  4 21:14:03 2018], epoch [14940], lr[0.00078125] ,loss[0.0747954696]\n",
      "[ Tue Dec  4 21:14:03 2018], validation: iter [14940], loss[0.0309604350]\n",
      "[ Tue Dec  4 21:14:04 2018], epoch [14960], lr[0.00078125] ,loss[0.0747943819]\n",
      "[ Tue Dec  4 21:14:04 2018], validation: iter [14960], loss[0.0309590772]\n",
      "[ Tue Dec  4 21:14:04 2018], epoch [14980], lr[0.00078125] ,loss[0.0747933537]\n",
      "[ Tue Dec  4 21:14:04 2018], validation: iter [14980], loss[0.0309586469]\n",
      "[ Tue Dec  4 21:14:05 2018], epoch [15000], lr[0.00078125] ,loss[0.0747926012]\n",
      "[ Tue Dec  4 21:14:05 2018], validation: iter [15000], loss[0.0309583135]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_15000']\n",
      "[ Tue Dec  4 21:14:06 2018], epoch [15020], lr[0.00078125] ,loss[0.0747916996]\n",
      "[ Tue Dec  4 21:14:06 2018], validation: iter [15020], loss[0.0309574138]\n",
      "[ Tue Dec  4 21:14:06 2018], epoch [15040], lr[0.00078125] ,loss[0.0747909173]\n",
      "[ Tue Dec  4 21:14:06 2018], validation: iter [15040], loss[0.0309572760]\n",
      "[ Tue Dec  4 21:14:06 2018], epoch [15060], lr[0.00078125] ,loss[0.0747906566]\n",
      "[ Tue Dec  4 21:14:06 2018], validation: iter [15060], loss[0.0309573784]\n",
      "[ Tue Dec  4 21:14:07 2018], epoch [15080], lr[0.00078125] ,loss[0.0747898445]\n",
      "[ Tue Dec  4 21:14:07 2018], validation: iter [15080], loss[0.0309571140]\n",
      "[ Tue Dec  4 21:14:07 2018], epoch [15100], lr[0.00078125] ,loss[0.0747894123]\n",
      "[ Tue Dec  4 21:14:07 2018], validation: iter [15100], loss[0.0309571587]\n",
      "[ Tue Dec  4 21:14:08 2018], epoch [15120], lr[0.00078125] ,loss[0.0747897774]\n",
      "[ Tue Dec  4 21:14:08 2018], validation: iter [15120], loss[0.0309575908]\n",
      "[ Tue Dec  4 21:14:09 2018], epoch [15140], lr[0.00078125] ,loss[0.0747897103]\n",
      "[ Tue Dec  4 21:14:09 2018], validation: iter [15140], loss[0.0309578031]\n",
      "[ Tue Dec  4 21:14:09 2018], epoch [15160], lr[0.00078125] ,loss[0.0747894943]\n",
      "[ Tue Dec  4 21:14:09 2018], validation: iter [15160], loss[0.0309574716]\n",
      "[ Tue Dec  4 21:14:10 2018], epoch [15180], lr[0.00078125] ,loss[0.0747894645]\n",
      "[ Tue Dec  4 21:14:10 2018], validation: iter [15180], loss[0.0309573393]\n",
      "[ Tue Dec  4 21:14:10 2018], epoch [15200], lr[0.00078125] ,loss[0.0747895166]\n",
      "[ Tue Dec  4 21:14:10 2018], validation: iter [15200], loss[0.0309573486]\n",
      "[ Tue Dec  4 21:14:11 2018], epoch [15220], lr[0.00078125] ,loss[0.0747893006]\n",
      "[ Tue Dec  4 21:14:11 2018], validation: iter [15220], loss[0.0309573002]\n",
      "[ Tue Dec  4 21:14:11 2018], epoch [15240], lr[0.00078125] ,loss[0.0747878477]\n",
      "[ Tue Dec  4 21:14:11 2018], validation: iter [15240], loss[0.0309573729]\n",
      "[ Tue Dec  4 21:14:12 2018], epoch [15260], lr[0.00078125] ,loss[0.0747884512]\n",
      "[ Tue Dec  4 21:14:12 2018], validation: iter [15260], loss[0.0309576485]\n",
      "[ Tue Dec  4 21:14:12 2018], epoch [15280], lr[0.00078125] ,loss[0.0747875348]\n",
      "[ Tue Dec  4 21:14:12 2018], validation: iter [15280], loss[0.0309575107]\n",
      "[ Tue Dec  4 21:14:13 2018], epoch [15300], lr[0.00078125] ,loss[0.0747874826]\n",
      "[ Tue Dec  4 21:14:13 2018], validation: iter [15300], loss[0.0309576187]\n",
      "[ Tue Dec  4 21:14:13 2018], epoch [15320], lr[0.00078125] ,loss[0.0747884214]\n",
      "[ Tue Dec  4 21:14:13 2018], validation: iter [15320], loss[0.0309579950]\n",
      "[ Tue Dec  4 21:14:14 2018], epoch [15340], lr[0.00078125] ,loss[0.0747877657]\n",
      "[ Tue Dec  4 21:14:14 2018], validation: iter [15340], loss[0.0309576970]\n",
      "[ Tue Dec  4 21:14:14 2018], epoch [15360], lr[0.00078125] ,loss[0.0747862607]\n",
      "[ Tue Dec  4 21:14:14 2018], validation: iter [15360], loss[0.0309576374]\n",
      "[ Tue Dec  4 21:14:15 2018], epoch [15380], lr[0.00078125] ,loss[0.0747862309]\n",
      "[ Tue Dec  4 21:14:15 2018], validation: iter [15380], loss[0.0309576262]\n",
      "[ Tue Dec  4 21:14:15 2018], epoch [15400], lr[0.00078125] ,loss[0.0747844949]\n",
      "[ Tue Dec  4 21:14:15 2018], validation: iter [15400], loss[0.0309570413]\n",
      "[ Tue Dec  4 21:14:16 2018], epoch [15420], lr[0.00078125] ,loss[0.0747842044]\n",
      "[ Tue Dec  4 21:14:16 2018], validation: iter [15420], loss[0.0309590138]\n",
      "[ Tue Dec  4 21:14:16 2018], epoch [15440], lr[0.00078125] ,loss[0.0747848079]\n",
      "[ Tue Dec  4 21:14:16 2018], validation: iter [15440], loss[0.0309570115]\n",
      "[ Tue Dec  4 21:14:17 2018], epoch [15460], lr[0.00078125] ,loss[0.0747860223]\n",
      "[ Tue Dec  4 21:14:17 2018], validation: iter [15460], loss[0.0309579838]\n",
      "[ Tue Dec  4 21:14:17 2018], epoch [15480], lr[0.00078125] ,loss[0.0747861564]\n",
      "[ Tue Dec  4 21:14:17 2018], validation: iter [15480], loss[0.0309587531]\n",
      "[ Tue Dec  4 21:14:18 2018], epoch [15500], lr[0.00078125] ,loss[0.0747848004]\n",
      "[ Tue Dec  4 21:14:18 2018], validation: iter [15500], loss[0.0309576802]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_15500']\n",
      "[ Tue Dec  4 21:14:19 2018], epoch [15520], lr[0.00078125] ,loss[0.0747845173]\n",
      "[ Tue Dec  4 21:14:19 2018], validation: iter [15520], loss[0.0309579149]\n",
      "[ Tue Dec  4 21:14:19 2018], epoch [15540], lr[0.00078125] ,loss[0.0747838393]\n",
      "[ Tue Dec  4 21:14:19 2018], validation: iter [15540], loss[0.0309610311]\n",
      "[ Tue Dec  4 21:14:20 2018], epoch [15560], lr[0.00078125] ,loss[0.0747862533]\n",
      "[ Tue Dec  4 21:14:20 2018], validation: iter [15560], loss[0.0309590772]\n",
      "[ Tue Dec  4 21:14:20 2018], epoch [15580], lr[0.00078125] ,loss[0.0747826025]\n",
      "[ Tue Dec  4 21:14:20 2018], validation: iter [15580], loss[0.0309575871]\n",
      "[ Tue Dec  4 21:14:21 2018], epoch [15600], lr[0.00078125] ,loss[0.0747841150]\n",
      "[ Tue Dec  4 21:14:21 2018], validation: iter [15600], loss[0.0309581365]\n",
      "[ Tue Dec  4 21:14:21 2018], epoch [15620], lr[0.00078125] ,loss[0.0747830346]\n",
      "[ Tue Dec  4 21:14:21 2018], validation: iter [15620], loss[0.0309579130]\n",
      "[ Tue Dec  4 21:14:22 2018], epoch [15640], lr[0.00078125] ,loss[0.0747829825]\n",
      "[ Tue Dec  4 21:14:22 2018], validation: iter [15640], loss[0.0309577826]\n",
      "[ Tue Dec  4 21:14:22 2018], epoch [15660], lr[0.00078125] ,loss[0.0747825578]\n",
      "[ Tue Dec  4 21:14:22 2018], validation: iter [15660], loss[0.0309578218]\n",
      "[ Tue Dec  4 21:14:23 2018], epoch [15680], lr[0.00078125] ,loss[0.0747828409]\n",
      "[ Tue Dec  4 21:14:23 2018], validation: iter [15680], loss[0.0309581906]\n",
      "[ Tue Dec  4 21:14:23 2018], epoch [15700], lr[0.00078125] ,loss[0.0747817531]\n",
      "[ Tue Dec  4 21:14:23 2018], validation: iter [15700], loss[0.0309578590]\n",
      "[ Tue Dec  4 21:14:24 2018], epoch [15720], lr[0.00078125] ,loss[0.0747790113]\n",
      "[ Tue Dec  4 21:14:24 2018], validation: iter [15720], loss[0.0309637375]\n",
      "[ Tue Dec  4 21:14:24 2018], epoch [15740], lr[0.00078125] ,loss[0.0747809932]\n",
      "[ Tue Dec  4 21:14:24 2018], validation: iter [15740], loss[0.0309586711]\n",
      "[ Tue Dec  4 21:14:25 2018], epoch [15760], lr[0.00078125] ,loss[0.0747816116]\n",
      "[ Tue Dec  4 21:14:25 2018], validation: iter [15760], loss[0.0309588090]\n",
      "[ Tue Dec  4 21:14:25 2018], epoch [15780], lr[0.00078125] ,loss[0.0747807473]\n",
      "[ Tue Dec  4 21:14:25 2018], validation: iter [15780], loss[0.0309576895]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 21:14:26 2018], epoch [15800], lr[0.00078125] ,loss[0.0747763216]\n",
      "[ Tue Dec  4 21:14:26 2018], validation: iter [15800], loss[0.0309538767]\n",
      "[ Tue Dec  4 21:14:26 2018], epoch [15820], lr[0.00078125] ,loss[0.0747744888]\n",
      "[ Tue Dec  4 21:14:26 2018], validation: iter [15820], loss[0.0309515912]\n",
      "[ Tue Dec  4 21:14:27 2018], epoch [15840], lr[0.00078125] ,loss[0.0747725517]\n",
      "[ Tue Dec  4 21:14:27 2018], validation: iter [15840], loss[0.0309491511]\n",
      "[ Tue Dec  4 21:14:27 2018], epoch [15860], lr[0.00078125] ,loss[0.0747685730]\n",
      "[ Tue Dec  4 21:14:27 2018], validation: iter [15860], loss[0.0309443660]\n",
      "[ Tue Dec  4 21:14:28 2018], epoch [15880], lr[0.00078125] ,loss[0.0747673810]\n",
      "[ Tue Dec  4 21:14:28 2018], validation: iter [15880], loss[0.0309433602]\n",
      "[ Tue Dec  4 21:14:29 2018], epoch [15900], lr[0.00078125] ,loss[0.0747641027]\n",
      "[ Tue Dec  4 21:14:29 2018], validation: iter [15900], loss[0.0309401359]\n",
      "[ Tue Dec  4 21:14:29 2018], epoch [15920], lr[0.00078125] ,loss[0.0747632608]\n",
      "[ Tue Dec  4 21:14:29 2018], validation: iter [15920], loss[0.0309397951]\n",
      "[ Tue Dec  4 21:14:30 2018], epoch [15940], lr[0.00078125] ,loss[0.0747638345]\n",
      "[ Tue Dec  4 21:14:30 2018], validation: iter [15940], loss[0.0309390314]\n",
      "[ Tue Dec  4 21:14:31 2018], epoch [15960], lr[0.00078125] ,loss[0.0747656077]\n",
      "[ Tue Dec  4 21:14:31 2018], validation: iter [15960], loss[0.0309449024]\n",
      "[ Tue Dec  4 21:14:31 2018], epoch [15980], lr[0.00078125] ,loss[0.0747625232]\n",
      "[ Tue Dec  4 21:14:31 2018], validation: iter [15980], loss[0.0309417527]\n",
      "[ Tue Dec  4 21:14:32 2018], epoch [16000], lr[0.00078125] ,loss[0.0747614205]\n",
      "[ Tue Dec  4 21:14:32 2018], validation: iter [16000], loss[0.0309391171]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_16000']\n",
      "[ Tue Dec  4 21:14:33 2018], epoch [16020], lr[0.00039063] ,loss[0.0747621730]\n",
      "[ Tue Dec  4 21:14:33 2018], validation: iter [16020], loss[0.0309398025]\n",
      "[ Tue Dec  4 21:14:33 2018], epoch [16040], lr[0.00039063] ,loss[0.0747625157]\n",
      "[ Tue Dec  4 21:14:33 2018], validation: iter [16040], loss[0.0309396833]\n",
      "[ Tue Dec  4 21:14:34 2018], epoch [16060], lr[0.00039063] ,loss[0.0747623295]\n",
      "[ Tue Dec  4 21:14:34 2018], validation: iter [16060], loss[0.0309395734]\n",
      "[ Tue Dec  4 21:14:34 2018], epoch [16080], lr[0.00039063] ,loss[0.0747620985]\n",
      "[ Tue Dec  4 21:14:34 2018], validation: iter [16080], loss[0.0309394207]\n",
      "[ Tue Dec  4 21:14:35 2018], epoch [16100], lr[0.00039063] ,loss[0.0747621208]\n",
      "[ Tue Dec  4 21:14:35 2018], validation: iter [16100], loss[0.0309395213]\n",
      "[ Tue Dec  4 21:14:35 2018], epoch [16120], lr[0.00039063] ,loss[0.0747620836]\n",
      "[ Tue Dec  4 21:14:35 2018], validation: iter [16120], loss[0.0309395734]\n",
      "[ Tue Dec  4 21:14:36 2018], epoch [16140], lr[0.00039063] ,loss[0.0747618750]\n",
      "[ Tue Dec  4 21:14:36 2018], validation: iter [16140], loss[0.0309394784]\n",
      "[ Tue Dec  4 21:14:37 2018], epoch [16160], lr[0.00039063] ,loss[0.0747617781]\n",
      "[ Tue Dec  4 21:14:37 2018], validation: iter [16160], loss[0.0309394114]\n",
      "[ Tue Dec  4 21:14:37 2018], epoch [16180], lr[0.00039063] ,loss[0.0747614354]\n",
      "[ Tue Dec  4 21:14:37 2018], validation: iter [16180], loss[0.0309393071]\n",
      "[ Tue Dec  4 21:14:38 2018], epoch [16200], lr[0.00039063] ,loss[0.0747615471]\n",
      "[ Tue Dec  4 21:14:38 2018], validation: iter [16200], loss[0.0309392828]\n",
      "[ Tue Dec  4 21:14:38 2018], epoch [16220], lr[0.00039063] ,loss[0.0747614056]\n",
      "[ Tue Dec  4 21:14:38 2018], validation: iter [16220], loss[0.0309392326]\n",
      "[ Tue Dec  4 21:14:39 2018], epoch [16240], lr[0.00039063] ,loss[0.0747611597]\n",
      "[ Tue Dec  4 21:14:39 2018], validation: iter [16240], loss[0.0309391990]\n",
      "[ Tue Dec  4 21:14:39 2018], epoch [16260], lr[0.00039063] ,loss[0.0747609809]\n",
      "[ Tue Dec  4 21:14:39 2018], validation: iter [16260], loss[0.0309391413]\n",
      "[ Tue Dec  4 21:14:40 2018], epoch [16280], lr[0.00039063] ,loss[0.0747608021]\n",
      "[ Tue Dec  4 21:14:40 2018], validation: iter [16280], loss[0.0309390519]\n",
      "[ Tue Dec  4 21:14:40 2018], epoch [16300], lr[0.00039063] ,loss[0.0747607127]\n",
      "[ Tue Dec  4 21:14:40 2018], validation: iter [16300], loss[0.0309390016]\n",
      "[ Tue Dec  4 21:14:41 2018], epoch [16320], lr[0.00039063] ,loss[0.0747608319]\n",
      "[ Tue Dec  4 21:14:41 2018], validation: iter [16320], loss[0.0309389699]\n",
      "[ Tue Dec  4 21:14:42 2018], epoch [16340], lr[0.00039063] ,loss[0.0747606978]\n",
      "[ Tue Dec  4 21:14:42 2018], validation: iter [16340], loss[0.0309388768]\n",
      "[ Tue Dec  4 21:14:42 2018], epoch [16360], lr[0.00039063] ,loss[0.0747605488]\n",
      "[ Tue Dec  4 21:14:42 2018], validation: iter [16360], loss[0.0309388712]\n",
      "[ Tue Dec  4 21:14:43 2018], epoch [16380], lr[0.00039063] ,loss[0.0747600719]\n",
      "[ Tue Dec  4 21:14:43 2018], validation: iter [16380], loss[0.0309388433]\n",
      "[ Tue Dec  4 21:14:43 2018], epoch [16400], lr[0.00039063] ,loss[0.0747598633]\n",
      "[ Tue Dec  4 21:14:43 2018], validation: iter [16400], loss[0.0309386142]\n",
      "[ Tue Dec  4 21:14:44 2018], epoch [16420], lr[0.00039063] ,loss[0.0747601539]\n",
      "[ Tue Dec  4 21:14:44 2018], validation: iter [16420], loss[0.0309387557]\n",
      "[ Tue Dec  4 21:14:44 2018], epoch [16440], lr[0.00039063] ,loss[0.0747600347]\n",
      "[ Tue Dec  4 21:14:44 2018], validation: iter [16440], loss[0.0309387818]\n",
      "[ Tue Dec  4 21:14:45 2018], epoch [16460], lr[0.00039063] ,loss[0.0747595653]\n",
      "[ Tue Dec  4 21:14:45 2018], validation: iter [16460], loss[0.0309386030]\n",
      "[ Tue Dec  4 21:14:45 2018], epoch [16480], lr[0.00039063] ,loss[0.0747598037]\n",
      "[ Tue Dec  4 21:14:45 2018], validation: iter [16480], loss[0.0309387110]\n",
      "[ Tue Dec  4 21:14:46 2018], epoch [16500], lr[0.00039063] ,loss[0.0747594684]\n",
      "[ Tue Dec  4 21:14:46 2018], validation: iter [16500], loss[0.0309384391]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_16500']\n",
      "[ Tue Dec  4 21:14:46 2018], epoch [16520], lr[0.00039063] ,loss[0.0747593939]\n",
      "[ Tue Dec  4 21:14:46 2018], validation: iter [16520], loss[0.0309385471]\n",
      "[ Tue Dec  4 21:14:47 2018], epoch [16540], lr[0.00039063] ,loss[0.0747594014]\n",
      "[ Tue Dec  4 21:14:47 2018], validation: iter [16540], loss[0.0309385695]\n",
      "[ Tue Dec  4 21:14:47 2018], epoch [16560], lr[0.00039063] ,loss[0.0747592598]\n",
      "[ Tue Dec  4 21:14:47 2018], validation: iter [16560], loss[0.0309385248]\n",
      "[ Tue Dec  4 21:14:48 2018], epoch [16580], lr[0.00039063] ,loss[0.0747589618]\n",
      "[ Tue Dec  4 21:14:48 2018], validation: iter [16580], loss[0.0309382863]\n",
      "[ Tue Dec  4 21:14:49 2018], epoch [16600], lr[0.00039063] ,loss[0.0747588426]\n",
      "[ Tue Dec  4 21:14:49 2018], validation: iter [16600], loss[0.0309382621]\n",
      "[ Tue Dec  4 21:14:49 2018], epoch [16620], lr[0.00039063] ,loss[0.0747587159]\n",
      "[ Tue Dec  4 21:14:49 2018], validation: iter [16620], loss[0.0309382956]\n",
      "[ Tue Dec  4 21:14:49 2018], epoch [16640], lr[0.00039063] ,loss[0.0747583061]\n",
      "[ Tue Dec  4 21:14:49 2018], validation: iter [16640], loss[0.0309382621]\n",
      "[ Tue Dec  4 21:14:50 2018], epoch [16660], lr[0.00039063] ,loss[0.0747584403]\n",
      "[ Tue Dec  4 21:14:50 2018], validation: iter [16660], loss[0.0309381913]\n",
      "[ Tue Dec  4 21:14:51 2018], epoch [16680], lr[0.00039063] ,loss[0.0747583732]\n",
      "[ Tue Dec  4 21:14:51 2018], validation: iter [16680], loss[0.0309381858]\n",
      "[ Tue Dec  4 21:14:51 2018], epoch [16700], lr[0.00039063] ,loss[0.0747582316]\n",
      "[ Tue Dec  4 21:14:51 2018], validation: iter [16700], loss[0.0309381615]\n",
      "[ Tue Dec  4 21:14:52 2018], epoch [16720], lr[0.00039063] ,loss[0.0747582540]\n",
      "[ Tue Dec  4 21:14:52 2018], validation: iter [16720], loss[0.0309381839]\n",
      "[ Tue Dec  4 21:14:52 2018], epoch [16740], lr[0.00039063] ,loss[0.0747580826]\n",
      "[ Tue Dec  4 21:14:52 2018], validation: iter [16740], loss[0.0309382249]\n",
      "[ Tue Dec  4 21:14:52 2018], epoch [16760], lr[0.00039063] ,loss[0.0747576579]\n",
      "[ Tue Dec  4 21:14:52 2018], validation: iter [16760], loss[0.0309383348]\n",
      "[ Tue Dec  4 21:14:53 2018], epoch [16780], lr[0.00039063] ,loss[0.0747577921]\n",
      "[ Tue Dec  4 21:14:53 2018], validation: iter [16780], loss[0.0309382938]\n",
      "[ Tue Dec  4 21:14:54 2018], epoch [16800], lr[0.00039063] ,loss[0.0747575238]\n",
      "[ Tue Dec  4 21:14:54 2018], validation: iter [16800], loss[0.0309378952]\n",
      "[ Tue Dec  4 21:14:54 2018], epoch [16820], lr[0.00039063] ,loss[0.0747573450]\n",
      "[ Tue Dec  4 21:14:54 2018], validation: iter [16820], loss[0.0309379641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 21:14:55 2018], epoch [16840], lr[0.00039063] ,loss[0.0747571886]\n",
      "[ Tue Dec  4 21:14:55 2018], validation: iter [16840], loss[0.0309379008]\n",
      "[ Tue Dec  4 21:14:55 2018], epoch [16860], lr[0.00039063] ,loss[0.0747572407]\n",
      "[ Tue Dec  4 21:14:55 2018], validation: iter [16860], loss[0.0309380181]\n",
      "[ Tue Dec  4 21:14:56 2018], epoch [16880], lr[0.00039063] ,loss[0.0747575685]\n",
      "[ Tue Dec  4 21:14:56 2018], validation: iter [16880], loss[0.0309382007]\n",
      "[ Tue Dec  4 21:14:56 2018], epoch [16900], lr[0.00039063] ,loss[0.0747569427]\n",
      "[ Tue Dec  4 21:14:56 2018], validation: iter [16900], loss[0.0309381746]\n",
      "[ Tue Dec  4 21:14:57 2018], epoch [16920], lr[0.00039063] ,loss[0.0747568086]\n",
      "[ Tue Dec  4 21:14:57 2018], validation: iter [16920], loss[0.0309380647]\n",
      "[ Tue Dec  4 21:14:57 2018], epoch [16940], lr[0.00039063] ,loss[0.0747566149]\n",
      "[ Tue Dec  4 21:14:57 2018], validation: iter [16940], loss[0.0309378952]\n",
      "[ Tue Dec  4 21:14:57 2018], epoch [16960], lr[0.00039063] ,loss[0.0747567117]\n",
      "[ Tue Dec  4 21:14:57 2018], validation: iter [16960], loss[0.0309379157]\n",
      "[ Tue Dec  4 21:14:58 2018], epoch [16980], lr[0.00039063] ,loss[0.0747567192]\n",
      "[ Tue Dec  4 21:14:58 2018], validation: iter [16980], loss[0.0309381820]\n",
      "[ Tue Dec  4 21:14:58 2018], epoch [17000], lr[0.00039063] ,loss[0.0747566298]\n",
      "[ Tue Dec  4 21:14:58 2018], validation: iter [17000], loss[0.0309384391]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_17000']\n",
      "[ Tue Dec  4 21:14:59 2018], epoch [17020], lr[0.00039063] ,loss[0.0747564733]\n",
      "[ Tue Dec  4 21:14:59 2018], validation: iter [17020], loss[0.0309384111]\n",
      "[ Tue Dec  4 21:15:00 2018], epoch [17040], lr[0.00039063] ,loss[0.0747566149]\n",
      "[ Tue Dec  4 21:15:00 2018], validation: iter [17040], loss[0.0309383199]\n",
      "[ Tue Dec  4 21:15:00 2018], epoch [17060], lr[0.00039063] ,loss[0.0747563168]\n",
      "[ Tue Dec  4 21:15:00 2018], validation: iter [17060], loss[0.0309382621]\n",
      "[ Tue Dec  4 21:15:01 2018], epoch [17080], lr[0.00039063] ,loss[0.0747561976]\n",
      "[ Tue Dec  4 21:15:01 2018], validation: iter [17080], loss[0.0309382733]\n",
      "[ Tue Dec  4 21:15:01 2018], epoch [17100], lr[0.00039063] ,loss[0.0747559220]\n",
      "[ Tue Dec  4 21:15:01 2018], validation: iter [17100], loss[0.0309382882]\n",
      "[ Tue Dec  4 21:15:02 2018], epoch [17120], lr[0.00039063] ,loss[0.0747559220]\n",
      "[ Tue Dec  4 21:15:02 2018], validation: iter [17120], loss[0.0309383105]\n",
      "[ Tue Dec  4 21:15:02 2018], epoch [17140], lr[0.00039063] ,loss[0.0747558102]\n",
      "[ Tue Dec  4 21:15:02 2018], validation: iter [17140], loss[0.0309382137]\n",
      "[ Tue Dec  4 21:15:03 2018], epoch [17160], lr[0.00039063] ,loss[0.0747555569]\n",
      "[ Tue Dec  4 21:15:03 2018], validation: iter [17160], loss[0.0309382956]\n",
      "[ Tue Dec  4 21:15:03 2018], epoch [17180], lr[0.00039063] ,loss[0.0747555271]\n",
      "[ Tue Dec  4 21:15:03 2018], validation: iter [17180], loss[0.0309382919]\n",
      "[ Tue Dec  4 21:15:04 2018], epoch [17200], lr[0.00039063] ,loss[0.0747553930]\n",
      "[ Tue Dec  4 21:15:04 2018], validation: iter [17200], loss[0.0309382956]\n",
      "[ Tue Dec  4 21:15:04 2018], epoch [17220], lr[0.00039063] ,loss[0.0747554004]\n",
      "[ Tue Dec  4 21:15:04 2018], validation: iter [17220], loss[0.0309384055]\n",
      "[ Tue Dec  4 21:15:05 2018], epoch [17240], lr[0.00039063] ,loss[0.0747551546]\n",
      "[ Tue Dec  4 21:15:05 2018], validation: iter [17240], loss[0.0309383050]\n",
      "[ Tue Dec  4 21:15:05 2018], epoch [17260], lr[0.00039063] ,loss[0.0747549459]\n",
      "[ Tue Dec  4 21:15:05 2018], validation: iter [17260], loss[0.0309382696]\n",
      "[ Tue Dec  4 21:15:06 2018], epoch [17280], lr[0.00039063] ,loss[0.0747548267]\n",
      "[ Tue Dec  4 21:15:06 2018], validation: iter [17280], loss[0.0309382714]\n",
      "[ Tue Dec  4 21:15:06 2018], epoch [17300], lr[0.00039063] ,loss[0.0747550577]\n",
      "[ Tue Dec  4 21:15:06 2018], validation: iter [17300], loss[0.0309382770]\n",
      "[ Tue Dec  4 21:15:07 2018], epoch [17320], lr[0.00039063] ,loss[0.0747545138]\n",
      "[ Tue Dec  4 21:15:07 2018], validation: iter [17320], loss[0.0309382528]\n",
      "[ Tue Dec  4 21:15:07 2018], epoch [17340], lr[0.00039063] ,loss[0.0747543722]\n",
      "[ Tue Dec  4 21:15:07 2018], validation: iter [17340], loss[0.0309382081]\n",
      "[ Tue Dec  4 21:15:08 2018], epoch [17360], lr[0.00039063] ,loss[0.0747542530]\n",
      "[ Tue Dec  4 21:15:08 2018], validation: iter [17360], loss[0.0309381597]\n",
      "[ Tue Dec  4 21:15:08 2018], epoch [17380], lr[0.00039063] ,loss[0.0747534484]\n",
      "[ Tue Dec  4 21:15:08 2018], validation: iter [17380], loss[0.0309376903]\n",
      "[ Tue Dec  4 21:15:09 2018], epoch [17400], lr[0.00039063] ,loss[0.0747538134]\n",
      "[ Tue Dec  4 21:15:09 2018], validation: iter [17400], loss[0.0309380516]\n",
      "[ Tue Dec  4 21:15:09 2018], epoch [17420], lr[0.00039063] ,loss[0.0747536868]\n",
      "[ Tue Dec  4 21:15:09 2018], validation: iter [17420], loss[0.0309380442]\n",
      "[ Tue Dec  4 21:15:10 2018], epoch [17440], lr[0.00039063] ,loss[0.0747529790]\n",
      "[ Tue Dec  4 21:15:10 2018], validation: iter [17440], loss[0.0309381597]\n",
      "[ Tue Dec  4 21:15:10 2018], epoch [17460], lr[0.00039063] ,loss[0.0747516602]\n",
      "[ Tue Dec  4 21:15:10 2018], validation: iter [17460], loss[0.0309409052]\n",
      "[ Tue Dec  4 21:15:11 2018], epoch [17480], lr[0.00039063] ,loss[0.0747542977]\n",
      "[ Tue Dec  4 21:15:11 2018], validation: iter [17480], loss[0.0309367850]\n",
      "[ Tue Dec  4 21:15:11 2018], epoch [17500], lr[0.00039063] ,loss[0.0747528896]\n",
      "[ Tue Dec  4 21:15:11 2018], validation: iter [17500], loss[0.0309380963]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_17500']\n",
      "[ Tue Dec  4 21:15:12 2018], epoch [17520], lr[0.00039063] ,loss[0.0747524276]\n",
      "[ Tue Dec  4 21:15:12 2018], validation: iter [17520], loss[0.0309381243]\n",
      "[ Tue Dec  4 21:15:13 2018], epoch [17540], lr[0.00039063] ,loss[0.0747532174]\n",
      "[ Tue Dec  4 21:15:13 2018], validation: iter [17540], loss[0.0309378766]\n",
      "[ Tue Dec  4 21:15:13 2018], epoch [17560], lr[0.00039063] ,loss[0.0747526884]\n",
      "[ Tue Dec  4 21:15:13 2018], validation: iter [17560], loss[0.0309379566]\n",
      "[ Tue Dec  4 21:15:14 2018], epoch [17580], lr[0.00039063] ,loss[0.0747522041]\n",
      "[ Tue Dec  4 21:15:14 2018], validation: iter [17580], loss[0.0309378318]\n",
      "[ Tue Dec  4 21:15:14 2018], epoch [17600], lr[0.00039063] ,loss[0.0747521147]\n",
      "[ Tue Dec  4 21:15:14 2018], validation: iter [17600], loss[0.0309378318]\n",
      "[ Tue Dec  4 21:15:15 2018], epoch [17620], lr[0.00039063] ,loss[0.0747542456]\n",
      "[ Tue Dec  4 21:15:15 2018], validation: iter [17620], loss[0.0309363045]\n",
      "[ Tue Dec  4 21:15:15 2018], epoch [17640], lr[0.00039063] ,loss[0.0747534409]\n",
      "[ Tue Dec  4 21:15:15 2018], validation: iter [17640], loss[0.0309371762]\n",
      "[ Tue Dec  4 21:15:16 2018], epoch [17660], lr[0.00039063] ,loss[0.0747516900]\n",
      "[ Tue Dec  4 21:15:16 2018], validation: iter [17660], loss[0.0309379939]\n",
      "[ Tue Dec  4 21:15:16 2018], epoch [17680], lr[0.00039063] ,loss[0.0747507140]\n",
      "[ Tue Dec  4 21:15:16 2018], validation: iter [17680], loss[0.0309377778]\n",
      "[ Tue Dec  4 21:15:17 2018], epoch [17700], lr[0.00039063] ,loss[0.0747514144]\n",
      "[ Tue Dec  4 21:15:17 2018], validation: iter [17700], loss[0.0309377760]\n",
      "[ Tue Dec  4 21:15:17 2018], epoch [17720], lr[0.00039063] ,loss[0.0747516751]\n",
      "[ Tue Dec  4 21:15:17 2018], validation: iter [17720], loss[0.0309395343]\n",
      "[ Tue Dec  4 21:15:18 2018], epoch [17740], lr[0.00039063] ,loss[0.0747516155]\n",
      "[ Tue Dec  4 21:15:18 2018], validation: iter [17740], loss[0.0309379492]\n",
      "[ Tue Dec  4 21:15:18 2018], epoch [17760], lr[0.00039063] ,loss[0.0747510046]\n",
      "[ Tue Dec  4 21:15:18 2018], validation: iter [17760], loss[0.0309377518]\n",
      "[ Tue Dec  4 21:15:19 2018], epoch [17780], lr[0.00039063] ,loss[0.0747516528]\n",
      "[ Tue Dec  4 21:15:19 2018], validation: iter [17780], loss[0.0309373438]\n",
      "[ Tue Dec  4 21:15:20 2018], epoch [17800], lr[0.00039063] ,loss[0.0747540519]\n",
      "[ Tue Dec  4 21:15:20 2018], validation: iter [17800], loss[0.0309352092]\n",
      "[ Tue Dec  4 21:15:20 2018], epoch [17820], lr[0.00039063] ,loss[0.0747504979]\n",
      "[ Tue Dec  4 21:15:20 2018], validation: iter [17820], loss[0.0309374165]\n",
      "[ Tue Dec  4 21:15:21 2018], epoch [17840], lr[0.00039063] ,loss[0.0747496113]\n",
      "[ Tue Dec  4 21:15:21 2018], validation: iter [17840], loss[0.0309381858]\n",
      "[ Tue Dec  4 21:15:21 2018], epoch [17860], lr[0.00039063] ,loss[0.0747505203]\n",
      "[ Tue Dec  4 21:15:21 2018], validation: iter [17860], loss[0.0309378617]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 21:15:22 2018], epoch [17880], lr[0.00039063] ,loss[0.0747519732]\n",
      "[ Tue Dec  4 21:15:22 2018], validation: iter [17880], loss[0.0309371427]\n",
      "[ Tue Dec  4 21:15:22 2018], epoch [17900], lr[0.00039063] ,loss[0.0747491121]\n",
      "[ Tue Dec  4 21:15:22 2018], validation: iter [17900], loss[0.0309395120]\n",
      "[ Tue Dec  4 21:15:23 2018], epoch [17920], lr[0.00039063] ,loss[0.0747503713]\n",
      "[ Tue Dec  4 21:15:23 2018], validation: iter [17920], loss[0.0309385527]\n",
      "[ Tue Dec  4 21:15:23 2018], epoch [17940], lr[0.00039063] ,loss[0.0747491568]\n",
      "[ Tue Dec  4 21:15:23 2018], validation: iter [17940], loss[0.0309379101]\n",
      "[ Tue Dec  4 21:15:24 2018], epoch [17960], lr[0.00039063] ,loss[0.0747501180]\n",
      "[ Tue Dec  4 21:15:24 2018], validation: iter [17960], loss[0.0309377145]\n",
      "[ Tue Dec  4 21:15:24 2018], epoch [17980], lr[0.00039063] ,loss[0.0747492760]\n",
      "[ Tue Dec  4 21:15:24 2018], validation: iter [17980], loss[0.0309378449]\n",
      "[ Tue Dec  4 21:15:25 2018], epoch [18000], lr[0.00039063] ,loss[0.0747498125]\n",
      "[ Tue Dec  4 21:15:25 2018], validation: iter [18000], loss[0.0309376642]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_18000']\n",
      "[ Tue Dec  4 21:15:26 2018], epoch [18020], lr[0.00019531] ,loss[0.0747488365]\n",
      "[ Tue Dec  4 21:15:26 2018], validation: iter [18020], loss[0.0309378263]\n",
      "[ Tue Dec  4 21:15:26 2018], epoch [18040], lr[0.00019531] ,loss[0.0747487620]\n",
      "[ Tue Dec  4 21:15:26 2018], validation: iter [18040], loss[0.0309377778]\n",
      "[ Tue Dec  4 21:15:27 2018], epoch [18060], lr[0.00019531] ,loss[0.0747488812]\n",
      "[ Tue Dec  4 21:15:27 2018], validation: iter [18060], loss[0.0309378617]\n",
      "[ Tue Dec  4 21:15:28 2018], epoch [18080], lr[0.00019531] ,loss[0.0747487992]\n",
      "[ Tue Dec  4 21:15:28 2018], validation: iter [18080], loss[0.0309378654]\n",
      "[ Tue Dec  4 21:15:28 2018], epoch [18100], lr[0.00019531] ,loss[0.0747486278]\n",
      "[ Tue Dec  4 21:15:28 2018], validation: iter [18100], loss[0.0309378412]\n",
      "[ Tue Dec  4 21:15:29 2018], epoch [18120], lr[0.00019531] ,loss[0.0747486651]\n",
      "[ Tue Dec  4 21:15:29 2018], validation: iter [18120], loss[0.0309378654]\n",
      "[ Tue Dec  4 21:15:29 2018], epoch [18140], lr[0.00019531] ,loss[0.0747485533]\n",
      "[ Tue Dec  4 21:15:29 2018], validation: iter [18140], loss[0.0309378207]\n",
      "[ Tue Dec  4 21:15:30 2018], epoch [18160], lr[0.00019531] ,loss[0.0747484714]\n",
      "[ Tue Dec  4 21:15:30 2018], validation: iter [18160], loss[0.0309378542]\n",
      "[ Tue Dec  4 21:15:30 2018], epoch [18180], lr[0.00019531] ,loss[0.0747482777]\n",
      "[ Tue Dec  4 21:15:30 2018], validation: iter [18180], loss[0.0309378803]\n",
      "[ Tue Dec  4 21:15:31 2018], epoch [18200], lr[0.00019531] ,loss[0.0747483149]\n",
      "[ Tue Dec  4 21:15:31 2018], validation: iter [18200], loss[0.0309378915]\n",
      "[ Tue Dec  4 21:15:31 2018], epoch [18220], lr[0.00019531] ,loss[0.0747479498]\n",
      "[ Tue Dec  4 21:15:31 2018], validation: iter [18220], loss[0.0309378877]\n",
      "[ Tue Dec  4 21:15:32 2018], epoch [18240], lr[0.00019531] ,loss[0.0747481063]\n",
      "[ Tue Dec  4 21:15:32 2018], validation: iter [18240], loss[0.0309378263]\n",
      "[ Tue Dec  4 21:15:32 2018], epoch [18260], lr[0.00019531] ,loss[0.0747480541]\n",
      "[ Tue Dec  4 21:15:32 2018], validation: iter [18260], loss[0.0309378803]\n",
      "[ Tue Dec  4 21:15:33 2018], epoch [18280], lr[0.00019531] ,loss[0.0747477412]\n",
      "[ Tue Dec  4 21:15:33 2018], validation: iter [18280], loss[0.0309378877]\n",
      "[ Tue Dec  4 21:15:33 2018], epoch [18300], lr[0.00019531] ,loss[0.0747478828]\n",
      "[ Tue Dec  4 21:15:33 2018], validation: iter [18300], loss[0.0309378933]\n",
      "[ Tue Dec  4 21:15:34 2018], epoch [18320], lr[0.00019531] ,loss[0.0747475773]\n",
      "[ Tue Dec  4 21:15:34 2018], validation: iter [18320], loss[0.0309376437]\n",
      "[ Tue Dec  4 21:15:34 2018], epoch [18340], lr[0.00019531] ,loss[0.0747476444]\n",
      "[ Tue Dec  4 21:15:34 2018], validation: iter [18340], loss[0.0309378766]\n",
      "[ Tue Dec  4 21:15:35 2018], epoch [18360], lr[0.00019531] ,loss[0.0747476220]\n",
      "[ Tue Dec  4 21:15:35 2018], validation: iter [18360], loss[0.0309379119]\n",
      "[ Tue Dec  4 21:15:35 2018], epoch [18380], lr[0.00019531] ,loss[0.0747472569]\n",
      "[ Tue Dec  4 21:15:35 2018], validation: iter [18380], loss[0.0309379101]\n",
      "[ Tue Dec  4 21:15:36 2018], epoch [18400], lr[0.00019531] ,loss[0.0747474134]\n",
      "[ Tue Dec  4 21:15:36 2018], validation: iter [18400], loss[0.0309379157]\n",
      "[ Tue Dec  4 21:15:36 2018], epoch [18420], lr[0.00019531] ,loss[0.0747470930]\n",
      "[ Tue Dec  4 21:15:36 2018], validation: iter [18420], loss[0.0309379417]\n",
      "[ Tue Dec  4 21:15:37 2018], epoch [18440], lr[0.00019531] ,loss[0.0747473463]\n",
      "[ Tue Dec  4 21:15:37 2018], validation: iter [18440], loss[0.0309379268]\n",
      "[ Tue Dec  4 21:15:37 2018], epoch [18460], lr[0.00019531] ,loss[0.0747471303]\n",
      "[ Tue Dec  4 21:15:37 2018], validation: iter [18460], loss[0.0309379119]\n",
      "[ Tue Dec  4 21:15:38 2018], epoch [18480], lr[0.00019531] ,loss[0.0747467726]\n",
      "[ Tue Dec  4 21:15:38 2018], validation: iter [18480], loss[0.0309379026]\n",
      "[ Tue Dec  4 21:15:38 2018], epoch [18500], lr[0.00019531] ,loss[0.0747466758]\n",
      "[ Tue Dec  4 21:15:38 2018], validation: iter [18500], loss[0.0309379101]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_18500']\n",
      "[ Tue Dec  4 21:15:39 2018], epoch [18520], lr[0.00019531] ,loss[0.0747465640]\n",
      "[ Tue Dec  4 21:15:39 2018], validation: iter [18520], loss[0.0309379082]\n",
      "[ Tue Dec  4 21:15:40 2018], epoch [18540], lr[0.00019531] ,loss[0.0747468695]\n",
      "[ Tue Dec  4 21:15:40 2018], validation: iter [18540], loss[0.0309378225]\n",
      "[ Tue Dec  4 21:15:40 2018], epoch [18560], lr[0.00019531] ,loss[0.0747466087]\n",
      "[ Tue Dec  4 21:15:40 2018], validation: iter [18560], loss[0.0309377983]\n",
      "[ Tue Dec  4 21:15:41 2018], epoch [18580], lr[0.00019531] ,loss[0.0747464299]\n",
      "[ Tue Dec  4 21:15:41 2018], validation: iter [18580], loss[0.0309378151]\n",
      "[ Tue Dec  4 21:15:41 2018], epoch [18600], lr[0.00019531] ,loss[0.0747463256]\n",
      "[ Tue Dec  4 21:15:41 2018], validation: iter [18600], loss[0.0309378374]\n",
      "[ Tue Dec  4 21:15:42 2018], epoch [18620], lr[0.00019531] ,loss[0.0747459531]\n",
      "[ Tue Dec  4 21:15:42 2018], validation: iter [18620], loss[0.0309378151]\n",
      "[ Tue Dec  4 21:15:42 2018], epoch [18640], lr[0.00019531] ,loss[0.0747456774]\n",
      "[ Tue Dec  4 21:15:42 2018], validation: iter [18640], loss[0.0309375729]\n",
      "[ Tue Dec  4 21:15:43 2018], epoch [18660], lr[0.00019531] ,loss[0.0747456998]\n",
      "[ Tue Dec  4 21:15:43 2018], validation: iter [18660], loss[0.0309377816]\n",
      "[ Tue Dec  4 21:15:43 2018], epoch [18680], lr[0.00019531] ,loss[0.0747459903]\n",
      "[ Tue Dec  4 21:15:43 2018], validation: iter [18680], loss[0.0309378300]\n",
      "[ Tue Dec  4 21:15:44 2018], epoch [18700], lr[0.00019531] ,loss[0.0747454688]\n",
      "[ Tue Dec  4 21:15:44 2018], validation: iter [18700], loss[0.0309378225]\n",
      "[ Tue Dec  4 21:15:44 2018], epoch [18720], lr[0.00019531] ,loss[0.0747453272]\n",
      "[ Tue Dec  4 21:15:44 2018], validation: iter [18720], loss[0.0309378263]\n",
      "[ Tue Dec  4 21:15:45 2018], epoch [18740], lr[0.00019531] ,loss[0.0747453421]\n",
      "[ Tue Dec  4 21:15:45 2018], validation: iter [18740], loss[0.0309378468]\n",
      "[ Tue Dec  4 21:15:45 2018], epoch [18760], lr[0.00019531] ,loss[0.0747451410]\n",
      "[ Tue Dec  4 21:15:45 2018], validation: iter [18760], loss[0.0309377685]\n",
      "[ Tue Dec  4 21:15:46 2018], epoch [18780], lr[0.00019531] ,loss[0.0747449920]\n",
      "[ Tue Dec  4 21:15:46 2018], validation: iter [18780], loss[0.0309378915]\n",
      "[ Tue Dec  4 21:15:46 2018], epoch [18800], lr[0.00019531] ,loss[0.0747452751]\n",
      "[ Tue Dec  4 21:15:46 2018], validation: iter [18800], loss[0.0309378486]\n",
      "[ Tue Dec  4 21:15:47 2018], epoch [18820], lr[0.00019531] ,loss[0.0747448877]\n",
      "[ Tue Dec  4 21:15:47 2018], validation: iter [18820], loss[0.0309378374]\n",
      "[ Tue Dec  4 21:15:48 2018], epoch [18840], lr[0.00019531] ,loss[0.0747447833]\n",
      "[ Tue Dec  4 21:15:48 2018], validation: iter [18840], loss[0.0309378393]\n",
      "[ Tue Dec  4 21:15:48 2018], epoch [18860], lr[0.00019531] ,loss[0.0747446716]\n",
      "[ Tue Dec  4 21:15:48 2018], validation: iter [18860], loss[0.0309378523]\n",
      "[ Tue Dec  4 21:15:48 2018], epoch [18880], lr[0.00019531] ,loss[0.0747449994]\n",
      "[ Tue Dec  4 21:15:48 2018], validation: iter [18880], loss[0.0309380367]\n",
      "[ Tue Dec  4 21:15:49 2018], epoch [18900], lr[0.00019531] ,loss[0.0747448057]\n",
      "[ Tue Dec  4 21:15:49 2018], validation: iter [18900], loss[0.0309378561]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 21:15:50 2018], epoch [18920], lr[0.00019531] ,loss[0.0747442991]\n",
      "[ Tue Dec  4 21:15:50 2018], validation: iter [18920], loss[0.0309378393]\n",
      "[ Tue Dec  4 21:15:50 2018], epoch [18940], lr[0.00019531] ,loss[0.0747441947]\n",
      "[ Tue Dec  4 21:15:50 2018], validation: iter [18940], loss[0.0309378784]\n",
      "[ Tue Dec  4 21:15:51 2018], epoch [18960], lr[0.00019531] ,loss[0.0747440606]\n",
      "[ Tue Dec  4 21:15:51 2018], validation: iter [18960], loss[0.0309378654]\n",
      "[ Tue Dec  4 21:15:51 2018], epoch [18980], lr[0.00019531] ,loss[0.0747439489]\n",
      "[ Tue Dec  4 21:15:51 2018], validation: iter [18980], loss[0.0309378523]\n",
      "[ Tue Dec  4 21:15:52 2018], epoch [19000], lr[0.00019531] ,loss[0.0747442394]\n",
      "[ Tue Dec  4 21:15:52 2018], validation: iter [19000], loss[0.0309380759]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_19000']\n",
      "[ Tue Dec  4 21:15:52 2018], epoch [19020], lr[0.00019531] ,loss[0.0747441053]\n",
      "[ Tue Dec  4 21:15:52 2018], validation: iter [19020], loss[0.0309378952]\n",
      "[ Tue Dec  4 21:15:53 2018], epoch [19040], lr[0.00019531] ,loss[0.0747435763]\n",
      "[ Tue Dec  4 21:15:53 2018], validation: iter [19040], loss[0.0309378523]\n",
      "[ Tue Dec  4 21:15:53 2018], epoch [19060], lr[0.00019531] ,loss[0.0747434646]\n",
      "[ Tue Dec  4 21:15:53 2018], validation: iter [19060], loss[0.0309378803]\n",
      "[ Tue Dec  4 21:15:54 2018], epoch [19080], lr[0.00019531] ,loss[0.0747433007]\n",
      "[ Tue Dec  4 21:15:54 2018], validation: iter [19080], loss[0.0309378617]\n",
      "[ Tue Dec  4 21:15:54 2018], epoch [19100], lr[0.00019531] ,loss[0.0747431666]\n",
      "[ Tue Dec  4 21:15:54 2018], validation: iter [19100], loss[0.0309378318]\n",
      "[ Tue Dec  4 21:15:55 2018], epoch [19120], lr[0.00019531] ,loss[0.0747430921]\n",
      "[ Tue Dec  4 21:15:55 2018], validation: iter [19120], loss[0.0309376959]\n",
      "[ Tue Dec  4 21:15:55 2018], epoch [19140], lr[0.00019531] ,loss[0.0747430176]\n",
      "[ Tue Dec  4 21:15:55 2018], validation: iter [19140], loss[0.0309378076]\n",
      "[ Tue Dec  4 21:15:56 2018], epoch [19160], lr[0.00019531] ,loss[0.0747431517]\n",
      "[ Tue Dec  4 21:15:56 2018], validation: iter [19160], loss[0.0309378617]\n",
      "[ Tue Dec  4 21:15:56 2018], epoch [19180], lr[0.00019531] ,loss[0.0747426599]\n",
      "[ Tue Dec  4 21:15:56 2018], validation: iter [19180], loss[0.0309378933]\n",
      "[ Tue Dec  4 21:15:57 2018], epoch [19200], lr[0.00019531] ,loss[0.0747426748]\n",
      "[ Tue Dec  4 21:15:57 2018], validation: iter [19200], loss[0.0309378970]\n",
      "[ Tue Dec  4 21:15:57 2018], epoch [19220], lr[0.00019531] ,loss[0.0747423992]\n",
      "[ Tue Dec  4 21:15:57 2018], validation: iter [19220], loss[0.0309377424]\n",
      "[ Tue Dec  4 21:15:58 2018], epoch [19240], lr[0.00019531] ,loss[0.0747421160]\n",
      "[ Tue Dec  4 21:15:58 2018], validation: iter [19240], loss[0.0309377424]\n",
      "[ Tue Dec  4 21:15:58 2018], epoch [19260], lr[0.00019531] ,loss[0.0747423470]\n",
      "[ Tue Dec  4 21:15:58 2018], validation: iter [19260], loss[0.0309379045]\n",
      "[ Tue Dec  4 21:15:59 2018], epoch [19280], lr[0.00019531] ,loss[0.0747424737]\n",
      "[ Tue Dec  4 21:15:59 2018], validation: iter [19280], loss[0.0309378803]\n",
      "[ Tue Dec  4 21:15:59 2018], epoch [19300], lr[0.00019531] ,loss[0.0747416988]\n",
      "[ Tue Dec  4 21:15:59 2018], validation: iter [19300], loss[0.0309377518]\n",
      "[ Tue Dec  4 21:16:00 2018], epoch [19320], lr[0.00019531] ,loss[0.0747415647]\n",
      "[ Tue Dec  4 21:16:00 2018], validation: iter [19320], loss[0.0309377499]\n",
      "[ Tue Dec  4 21:16:00 2018], epoch [19340], lr[0.00019531] ,loss[0.0747413710]\n",
      "[ Tue Dec  4 21:16:00 2018], validation: iter [19340], loss[0.0309377685]\n",
      "[ Tue Dec  4 21:16:01 2018], epoch [19360], lr[0.00019531] ,loss[0.0747410059]\n",
      "[ Tue Dec  4 21:16:01 2018], validation: iter [19360], loss[0.0309377890]\n",
      "[ Tue Dec  4 21:16:01 2018], epoch [19380], lr[0.00019531] ,loss[0.0747441128]\n",
      "[ Tue Dec  4 21:16:01 2018], validation: iter [19380], loss[0.0309363771]\n",
      "[ Tue Dec  4 21:16:02 2018], epoch [19400], lr[0.00019531] ,loss[0.0747399852]\n",
      "[ Tue Dec  4 21:16:02 2018], validation: iter [19400], loss[0.0309381373]\n",
      "[ Tue Dec  4 21:16:02 2018], epoch [19420], lr[0.00019531] ,loss[0.0747411251]\n",
      "[ Tue Dec  4 21:16:02 2018], validation: iter [19420], loss[0.0309376456]\n",
      "[ Tue Dec  4 21:16:03 2018], epoch [19440], lr[0.00019531] ,loss[0.0747406930]\n",
      "[ Tue Dec  4 21:16:03 2018], validation: iter [19440], loss[0.0309376717]\n",
      "[ Tue Dec  4 21:16:03 2018], epoch [19460], lr[0.00019531] ,loss[0.0747407824]\n",
      "[ Tue Dec  4 21:16:03 2018], validation: iter [19460], loss[0.0309376419]\n",
      "[ Tue Dec  4 21:16:04 2018], epoch [19480], lr[0.00019531] ,loss[0.0747403279]\n",
      "[ Tue Dec  4 21:16:04 2018], validation: iter [19480], loss[0.0309376046]\n",
      "[ Tue Dec  4 21:16:05 2018], epoch [19500], lr[0.00019531] ,loss[0.0747400746]\n",
      "[ Tue Dec  4 21:16:05 2018], validation: iter [19500], loss[0.0309375580]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_19500']\n",
      "[ Tue Dec  4 21:16:05 2018], epoch [19520], lr[0.00019531] ,loss[0.0747407228]\n",
      "[ Tue Dec  4 21:16:05 2018], validation: iter [19520], loss[0.0309372321]\n",
      "[ Tue Dec  4 21:16:06 2018], epoch [19540], lr[0.00019531] ,loss[0.0747398213]\n",
      "[ Tue Dec  4 21:16:06 2018], validation: iter [19540], loss[0.0309378169]\n",
      "[ Tue Dec  4 21:16:06 2018], epoch [19560], lr[0.00019531] ,loss[0.0747405216]\n",
      "[ Tue Dec  4 21:16:06 2018], validation: iter [19560], loss[0.0309375543]\n",
      "[ Tue Dec  4 21:16:07 2018], epoch [19580], lr[0.00019531] ,loss[0.0747398958]\n",
      "[ Tue Dec  4 21:16:07 2018], validation: iter [19580], loss[0.0309377778]\n",
      "[ Tue Dec  4 21:16:07 2018], epoch [19600], lr[0.00019531] ,loss[0.0747396946]\n",
      "[ Tue Dec  4 21:16:07 2018], validation: iter [19600], loss[0.0309382416]\n",
      "[ Tue Dec  4 21:16:08 2018], epoch [19620], lr[0.00019531] ,loss[0.0747408569]\n",
      "[ Tue Dec  4 21:16:08 2018], validation: iter [19620], loss[0.0309369825]\n",
      "[ Tue Dec  4 21:16:08 2018], epoch [19640], lr[0.00019531] ,loss[0.0747402534]\n",
      "[ Tue Dec  4 21:16:08 2018], validation: iter [19640], loss[0.0309374724]\n",
      "[ Tue Dec  4 21:16:09 2018], epoch [19660], lr[0.00019531] ,loss[0.0747388974]\n",
      "[ Tue Dec  4 21:16:09 2018], validation: iter [19660], loss[0.0309376810]\n",
      "[ Tue Dec  4 21:16:10 2018], epoch [19680], lr[0.00019531] ,loss[0.0747390762]\n",
      "[ Tue Dec  4 21:16:10 2018], validation: iter [19680], loss[0.0309377778]\n",
      "[ Tue Dec  4 21:16:10 2018], epoch [19700], lr[0.00019531] ,loss[0.0747387856]\n",
      "[ Tue Dec  4 21:16:10 2018], validation: iter [19700], loss[0.0309379157]\n",
      "[ Tue Dec  4 21:16:11 2018], epoch [19720], lr[0.00019531] ,loss[0.0747392252]\n",
      "[ Tue Dec  4 21:16:11 2018], validation: iter [19720], loss[0.0309392139]\n",
      "[ Tue Dec  4 21:16:11 2018], epoch [19740], lr[0.00019531] ,loss[0.0747393891]\n",
      "[ Tue Dec  4 21:16:11 2018], validation: iter [19740], loss[0.0309380051]\n",
      "[ Tue Dec  4 21:16:12 2018], epoch [19760], lr[0.00019531] ,loss[0.0747391507]\n",
      "[ Tue Dec  4 21:16:12 2018], validation: iter [19760], loss[0.0309376363]\n",
      "[ Tue Dec  4 21:16:12 2018], epoch [19780], lr[0.00019531] ,loss[0.0747380182]\n",
      "[ Tue Dec  4 21:16:12 2018], validation: iter [19780], loss[0.0309377052]\n",
      "[ Tue Dec  4 21:16:13 2018], epoch [19800], lr[0.00019531] ,loss[0.0747377798]\n",
      "[ Tue Dec  4 21:16:13 2018], validation: iter [19800], loss[0.0309382621]\n",
      "[ Tue Dec  4 21:16:13 2018], epoch [19820], lr[0.00019531] ,loss[0.0747395232]\n",
      "[ Tue Dec  4 21:16:13 2018], validation: iter [19820], loss[0.0309371240]\n",
      "[ Tue Dec  4 21:16:14 2018], epoch [19840], lr[0.00019531] ,loss[0.0747378096]\n",
      "[ Tue Dec  4 21:16:14 2018], validation: iter [19840], loss[0.0309377890]\n",
      "[ Tue Dec  4 21:16:14 2018], epoch [19860], lr[0.00019531] ,loss[0.0747377798]\n",
      "[ Tue Dec  4 21:16:14 2018], validation: iter [19860], loss[0.0309377927]\n",
      "[ Tue Dec  4 21:16:15 2018], epoch [19880], lr[0.00019531] ,loss[0.0747374669]\n",
      "[ Tue Dec  4 21:16:15 2018], validation: iter [19880], loss[0.0309377890]\n",
      "[ Tue Dec  4 21:16:15 2018], epoch [19900], lr[0.00019531] ,loss[0.0747380927]\n",
      "[ Tue Dec  4 21:16:15 2018], validation: iter [19900], loss[0.0309378859]\n",
      "[ Tue Dec  4 21:16:16 2018], epoch [19920], lr[0.00019531] ,loss[0.0747377202]\n",
      "[ Tue Dec  4 21:16:16 2018], validation: iter [19920], loss[0.0309377611]\n",
      "[ Tue Dec  4 21:16:16 2018], epoch [19940], lr[0.00019531] ,loss[0.0747372359]\n",
      "[ Tue Dec  4 21:16:16 2018], validation: iter [19940], loss[0.0309378970]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 21:16:17 2018], epoch [19960], lr[0.00019531] ,loss[0.0747364461]\n",
      "[ Tue Dec  4 21:16:17 2018], validation: iter [19960], loss[0.0309386514]\n",
      "[ Tue Dec  4 21:16:17 2018], epoch [19980], lr[0.00019531] ,loss[0.0747377500]\n",
      "[ Tue Dec  4 21:16:17 2018], validation: iter [19980], loss[0.0309371781]\n",
      "[ Tue Dec  4 21:16:18 2018], epoch [20000], lr[0.00019531] ,loss[0.0747375414]\n",
      "[ Tue Dec  4 21:16:18 2018], validation: iter [20000], loss[0.0309375431]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_20000']\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_20000']\n",
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "config.ReadConfigFile()\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "try:\n",
    "    from importlib import reload\n",
    "    reload(MachineLearning)\n",
    "except NameError:\n",
    "    import MachineLearning\n",
    "MachineLearning.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saver restore from:/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitModel/checkpoint_20000\n",
      "INFO:tensorflow:Restoring parameters from /Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitModel/checkpoint_20000\n",
      "Predict complete, cost [  0] seconds\n"
     ]
    }
   ],
   "source": [
    "config.ReadConfigFile()\n",
    "sys.argv[1] = 'evaluation'\n",
    "# config.ResetValue('MachineLearning','normalization','False')\n",
    "# config.ResetValue('MLEvaluation','observation_source',data_dir)\n",
    "# config.ResetValue('MLEvaluation','data_source',data_dir)\n",
    "# config.ResetValue('MachineLearning','save_dir',model_dir)\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "from importlib import reload\n",
    "reload(MachineLearning)\n",
    "pred,loss = MachineLearning.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.019687292857927"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.3869743e+01, 3.5332367e-02, 5.0378479e+01, 1.6044672e+02,\n",
       "        3.8933717e-02],\n",
       "       [5.2307961e+01, 3.5442010e-02, 4.8833618e+01, 1.6179877e+02,\n",
       "        3.9005246e-02],\n",
       "       [5.2112419e+01, 3.5455748e-02, 4.8640198e+01, 1.6196805e+02,\n",
       "        3.9014202e-02],\n",
       "       ...,\n",
       "       [8.2163124e+01, 3.3346012e-02, 7.8365059e+01, 1.3595314e+02,\n",
       "        3.7637815e-02],\n",
       "       [8.3316872e+01, 3.3265024e-02, 7.9506302e+01, 1.3495435e+02,\n",
       "        3.7584972e-02],\n",
       "       [8.5027809e+01, 3.3144906e-02, 8.1198692e+01, 1.3347318e+02,\n",
       "        3.7506610e-02]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.14864059e+01, 1.45728070e-01, 4.27600881e+01, 1.91942253e+02,\n",
       "        1.65801574e-01],\n",
       "       [5.22582368e+01, 1.26984521e-01, 4.41256914e+01, 1.88195763e+02,\n",
       "        1.43298762e-01],\n",
       "       [5.34969108e+01, 1.12672733e-01, 4.58221772e+01, 1.84531258e+02,\n",
       "        1.26497331e-01],\n",
       "       ...,\n",
       "       [8.39717611e+01, 4.17903422e-02, 7.91199144e+01, 1.41345259e+02,\n",
       "        4.83785479e-02],\n",
       "       [8.50500012e+01, 4.04617951e-02, 8.02876748e+01, 1.39905598e+02,\n",
       "        4.68834857e-02],\n",
       "       [8.66576970e+01, 3.86915264e-02, 8.20158413e+01, 1.37861226e+02,\n",
       "        4.49036318e-02]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MachineLearning._Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = MachineLearning._X\n",
    "Y = MachineLearning._Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = pred - Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_seq = (diff ** 2).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_diff_seq = abs(diff/Y).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_norm = (diff ** 2).sum(axis = 1)\n",
    "truth_norm = (Y ** 2).sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_error = diff_norm / truth_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_index = np.argsort(rel_error)\n",
    "sort_index = np.flip(sort_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.11131944, 9.0516749 , 8.78704316, ..., 0.01045162, 0.01044946,\n",
       "       0.01044723])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_error[sort_index[:2300]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_error_index = sort_index[:2300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.nan)\n",
    "index_sorted = np.sort(large_error_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   2,   2,   2,   2,\n",
       "         2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "         2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "         2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "         2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "         2,   2,   2,   2,   3,   3,   3,   3,   3,   3,   3,   3,   3,\n",
       "         3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,\n",
       "         3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,\n",
       "         3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,\n",
       "         3,   3,   3,   3,   3,   3,   3,   4,   4,   4,   4,   4,   4,\n",
       "         4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n",
       "         4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n",
       "         4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n",
       "         4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   5,   5,\n",
       "         5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
       "         5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
       "         5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
       "         5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
       "         5,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
       "         6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
       "         6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
       "         6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   7,\n",
       "         7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "         7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "         7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
       "         7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   8,   8,   8,\n",
       "         8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "         8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "         8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,\n",
       "         8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   9,   9,\n",
       "         9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,\n",
       "         9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,\n",
       "         9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,\n",
       "         9,   9,   9,   9,   9,   9,   9,   9,   9,   9,  10,  10,  10,\n",
       "        10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,\n",
       "        10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,\n",
       "        10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,\n",
       "        10,  10,  10,  10,  10,  10,  10,  11,  11,  11,  11,  11,  11,\n",
       "        11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,\n",
       "        11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,\n",
       "        11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,\n",
       "        11,  11,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,\n",
       "        12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,\n",
       "        12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,\n",
       "        12,  12,  12,  12,  12,  12,  12,  12,  13,  13,  13,  13,  13,\n",
       "        13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,\n",
       "        13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,\n",
       "        13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,\n",
       "        13,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,\n",
       "        14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,\n",
       "        14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,\n",
       "        14,  14,  14,  14,  14,  14,  15,  15,  15,  15,  15,  15,  15,\n",
       "        15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,\n",
       "        15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,\n",
       "        15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  16,  16,\n",
       "        16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,\n",
       "        16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,\n",
       "        16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,  16,\n",
       "        16,  16,  16,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
       "        17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
       "        17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,  17,\n",
       "        17,  17,  17,  17,  17,  17,  17,  17,  18,  18,  18,  18,  18,\n",
       "        18,  18,  18,  18,  18,  18,  18,  18,  18,  18,  18,  18,  18,\n",
       "        18,  18,  18,  18,  18,  18,  18,  18,  18,  18,  18,  18,  18,\n",
       "        18,  18,  18,  18,  18,  18,  18,  18,  18,  18,  18,  18,  18,\n",
       "        19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19,\n",
       "        19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19,\n",
       "        19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19,\n",
       "        19,  19,  20,  20,  20,  20,  20,  20,  20,  20,  20,  20,  20,\n",
       "        20,  20,  20,  20,  20,  20,  20,  20,  20,  20,  20,  20,  20,\n",
       "        20,  20,  20,  20,  20,  20,  20,  20,  20,  20,  20,  20,  20,\n",
       "        20,  20,  20,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,\n",
       "        21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,\n",
       "        21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,  21,\n",
       "        21,  21,  21,  21,  21,  22,  22,  22,  22,  22,  22,  22,  22,\n",
       "        22,  22,  22,  22,  22,  22,  22,  22,  22,  22,  22,  22,  22,\n",
       "        22,  22,  22,  22,  22,  22,  22,  22,  22,  22,  22,  22,  22,\n",
       "        22,  22,  22,  22,  22,  22,  22,  22,  23,  23,  23,  23,  23,\n",
       "        23,  23,  23,  23,  23,  23,  23,  23,  23,  23,  23,  23,  23,\n",
       "        23,  23,  23,  23,  23,  23,  23,  23,  23,  23,  23,  23,  23,\n",
       "        23,  23,  23,  23,  23,  23,  23,  23,  23,  23,  23,  24,  24,\n",
       "        24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "        24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "        24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
       "        24,  24,  24,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
       "        25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
       "        25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,  25,\n",
       "        25,  25,  25,  25,  25,  25,  25,  25,  26,  26,  26,  26,  26,\n",
       "        26,  26,  26,  26,  26,  26,  26,  26,  26,  26,  26,  26,  26,\n",
       "        26,  26,  26,  26,  26,  26,  26,  26,  26,  26,  26,  26,  26,\n",
       "        26,  26,  26,  26,  26,  26,  26,  26,  26,  26,  26,  26,  27,\n",
       "        27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
       "        27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
       "        27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,  27,\n",
       "        27,  27,  27,  28,  28,  28,  28,  28,  28,  28,  28,  28,  28,\n",
       "        28,  28,  28,  28,  28,  28,  28,  28,  28,  28,  28,  28,  28,\n",
       "        28,  28,  28,  28,  28,  28,  28,  28,  28,  28,  28,  28,  28,\n",
       "        28,  28,  28,  29,  29,  29,  29,  29,  29,  29,  29,  29,  29,\n",
       "        29,  29,  29,  29,  29,  29,  29,  29,  29,  29,  29,  29,  29,\n",
       "        29,  29,  29,  29,  29,  29,  29,  29,  29,  29,  29,  29,  29,\n",
       "        30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
       "        30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,  30,\n",
       "        30,  30,  30,  30,  31,  31,  31,  31,  31,  31,  31,  31,  31,\n",
       "        31,  31,  31,  31,  31,  31,  31,  31,  31,  31,  31,  31,  31,\n",
       "        31,  31,  31,  31,  31,  31,  32,  32,  32,  32,  32,  32,  32,\n",
       "        32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
       "        32,  32,  32,  32,  32,  32,  33,  33,  33,  33,  33,  33,  33,\n",
       "        33,  33,  33,  33,  33,  33,  33,  33,  33,  33,  33,  33,  33,\n",
       "        33,  33,  33,  33,  33,  34,  34,  34,  34,  34,  34,  34,  34,\n",
       "        34,  34,  34,  34,  34,  34,  34,  34,  34,  34,  34,  34,  34,\n",
       "        34,  34,  34,  34,  34,  35,  35,  35,  35,  35,  35,  35,  35,\n",
       "        35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,  35,\n",
       "        35,  35,  35,  35,  35,  36,  36,  36,  36,  36,  36,  36,  36,\n",
       "        36,  36,  36,  36,  36,  36,  36,  36,  36,  36,  36,  36,  36,\n",
       "        36,  36,  36,  36,  36,  37,  37,  37,  37,  37,  37,  37,  37,\n",
       "        37,  37,  37,  37,  37,  37,  37,  37,  37,  37,  37,  37,  37,\n",
       "        37,  37,  37,  37,  37,  38,  38,  38,  38,  38,  38,  38,  38,\n",
       "        38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,  38,\n",
       "        38,  38,  38,  38,  38,  39,  39,  39,  39,  39,  39,  39,  39,\n",
       "        39,  39,  39,  39,  39,  39,  39,  39,  39,  39,  39,  39,  39,\n",
       "        39,  39,  39,  39,  39,  40,  40,  40,  40,  40,  40,  40,  40,\n",
       "        40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,  40,\n",
       "        40,  40,  40,  40,  40,  41,  41,  41,  41,  41,  41,  41,  41,\n",
       "        41,  41,  41,  41,  41,  41,  41,  41,  41,  41,  41,  41,  41,\n",
       "        41,  41,  41,  41,  41,  42,  42,  42,  42,  42,  42,  42,  42,\n",
       "        42,  42,  42,  42,  42,  42,  42,  42,  42,  42,  42,  42,  42,\n",
       "        42,  42,  42,  42,  42,  42,  42,  42,  43,  43,  43,  43,  43,\n",
       "        43,  43,  43,  43,  43,  43,  43,  43,  43,  43,  43,  43,  43,\n",
       "        43,  43,  43,  43,  43,  43,  43,  43,  43,  43,  43,  43,  44,\n",
       "        44,  44,  44,  44,  44,  44,  44,  44,  44,  44,  44,  44,  44,\n",
       "        44,  44,  44,  44,  44,  44,  44,  44,  44,  44,  44,  44,  44,\n",
       "        44,  44,  44,  44,  44,  44,  45,  45,  45,  45,  45,  45,  45,\n",
       "        45,  45,  45,  45,  45,  45,  45,  45,  45,  45,  45,  45,  45,\n",
       "        45,  45,  45,  45,  45,  45,  45,  45,  45,  45,  45,  45,  45,\n",
       "        45,  45,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,\n",
       "        46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  46,\n",
       "        46,  46,  46,  46,  46,  46,  46,  46,  46,  46,  47,  47,  47,\n",
       "        47,  47,  47,  47,  47,  47,  47,  47,  47,  47,  47,  47,  47,\n",
       "        47,  47,  47,  47,  47,  47,  47,  47,  47,  47,  47,  47,  47,\n",
       "        47,  48,  48,  48,  48,  48,  48,  48,  48,  48,  48,  48,  48,\n",
       "        48,  48,  48,  48,  48,  48,  48,  48,  48,  48,  48,  48,  48,\n",
       "        48,  49,  49,  49,  49,  49,  49,  49,  49,  49,  49,  49,  49,\n",
       "        49,  49,  49,  49,  49,  49,  49,  49,  49,  49,  49,  49,  49,\n",
       "        50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
       "        50,  50,  50,  50,  50,  51,  51,  51,  51,  51,  51,  51,  51,\n",
       "        51,  51,  51,  51,  51,  51,  52,  52,  52,  52,  52,  52,  52,\n",
       "        52,  52,  52,  52,  53,  53,  53,  53,  53,  53,  53,  53,  53,\n",
       "        54,  54,  54,  54,  54,  54,  54,  54,  54,  55,  55,  55,  55,\n",
       "        55,  55,  55,  55,  56,  56,  56,  56,  56,  56,  56,  56,  56,\n",
       "        57,  57,  57,  57,  57,  57,  57,  57,  57,  58,  58,  58,  58,\n",
       "        58,  58,  58,  58,  58,  59,  59,  59,  59,  59,  59,  59,  59,\n",
       "        59,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,\n",
       "        61,  61,  61,  61,  61,  61,  61,  61,  61,  61,  61,  61,  61,\n",
       "        62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62,\n",
       "        62,  62,  63,  63,  63,  63,  63,  63,  63,  63,  63,  63,  63,\n",
       "        63,  63,  63,  63,  64,  64,  64,  64,  64,  64,  64,  64,  64,\n",
       "        64,  64,  64,  64,  64,  64,  64,  64,  64,  64,  64,  65,  65,\n",
       "        65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,  65,\n",
       "        65,  65,  65,  65,  65,  65,  65,  66,  66,  66,  66,  66,  66,\n",
       "        66,  66,  66,  66,  66,  66,  66,  66,  66,  66,  66,  66,  66,\n",
       "        66,  66,  67,  67,  67,  67,  67,  67,  67,  67,  67,  67,  67,\n",
       "        67,  67,  67,  67,  68,  68,  68,  68,  68,  68,  68,  68,  68,\n",
       "        68,  68,  68,  68,  69,  69,  69,  69,  69,  69,  69,  69,  70,\n",
       "        70,  70,  70,  70,  71,  71,  71,  71,  72,  72,  73,  74,  75,\n",
       "        76,  77,  78,  79,  79,  80,  80,  81,  81,  81,  81,  82,  82,\n",
       "        82,  82,  82,  83,  83,  83,  83,  83,  84,  84,  84,  84,  84,\n",
       "        85,  85,  85,  85,  85,  85,  86,  86,  86,  86,  86,  87,  87,\n",
       "        87,  87,  87,  88,  88,  88,  89,  90, 103, 104, 105, 106])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(index_sorted % 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([605., 479., 391., 288., 256., 117., 112.,  27.,  21.,   4.]),\n",
       " array([  0. ,  10.6,  21.2,  31.8,  42.4,  53. ,  63.6,  74.2,  84.8,\n",
       "         95.4, 106. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(index_sorted % 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2,    24,    25,    26,    27,    45,    46,\n",
       "        2004,  2005,  2006,  2007,  2008,  2009,  2022,  2023,  2024,\n",
       "        2025,  2026,  2027,  2028,  5000,  5001,  5002,  5003,  5004,\n",
       "        5005,  5006,  5007,  5008,  5009,  5010,  5011,  5012,  5013,\n",
       "        5014,  5015,  5016,  5017,  5018,  5019,  5020,  5021,  5022,\n",
       "        5023,  5024,  5025,  5026,  5027,  5028,  5029,  5030,  5031,\n",
       "        5032,  5033,  5034,  5035,  5036,  5037,  5038,  5039,  5040,\n",
       "        5041,  5042,  5043,  5044,  5045,  5046,  5047,  5048,  5049,\n",
       "        5050,  5064,  5065,  5066,  8000,  8001,  8002,  8003,  8004,\n",
       "        8005,  8006,  8007,  8008,  8009,  9000,  9001, 10000, 10001,\n",
       "       10002, 11000, 11001, 11002, 11003, 11004, 11005, 11006, 11007,\n",
       "       11008, 11009, 11010, 11011, 11012, 11013, 11014, 11015, 11016,\n",
       "       11017, 11018, 11019, 11020, 11021, 11022, 11023, 11024, 11025,\n",
       "       11026, 11027, 11028, 11029, 11030, 11031, 11032, 11033, 11034,\n",
       "       11035, 11036, 11037, 11038, 11039, 11040, 11041, 11042, 11043,\n",
       "       11044, 11045, 11046, 11047, 11048, 11049, 11065, 12000, 12001,\n",
       "       12002, 12003, 12004, 12005, 12006, 12007, 12008, 12009, 12010,\n",
       "       12011, 12012, 12013, 12014, 12015, 12016, 12017, 12018, 12019,\n",
       "       12020, 12021, 12022, 12023, 12024, 12025, 12026, 12027, 12028,\n",
       "       12029, 12030, 12031, 12032, 12033, 12034, 12035, 12036, 12037,\n",
       "       12038, 12039, 12040, 12041, 12042, 12043, 12044, 12045, 12046,\n",
       "       12047, 12048, 12049, 12050, 12051, 12052, 12053, 12054, 12055,\n",
       "       12056, 12057, 12058, 12059, 12060, 12061, 12062, 12063, 12064,\n",
       "       12065, 12066, 12067, 12068, 12069, 12070, 12082, 12083, 12084,\n",
       "       12085, 12086, 12087, 13000, 13001, 13002, 13003, 13004, 13005,\n",
       "       13006, 13007, 13008, 13009, 13010, 13011, 13012, 13013, 13014,\n",
       "       13015, 13016, 13017, 13018, 13019, 13020, 13021, 13022, 13023,\n",
       "       13024, 13025, 13026, 13027, 13028, 13029, 13030, 13031, 13032,\n",
       "       13033, 13034, 13035, 13036, 13037, 13038, 13039, 13040, 13041,\n",
       "       13042, 13043, 13044, 13045, 13046, 13047, 13048, 13049, 14000,\n",
       "       14001, 14002, 14003, 14004, 14005, 14006, 14007, 14008, 14009,\n",
       "       14010, 14011, 14012, 14013, 14014, 14015, 14016, 14017, 14018,\n",
       "       14019, 14020, 14021, 14022, 14023, 14024, 14025, 14026, 14027,\n",
       "       14028, 14029, 14030, 14031, 14032, 14033, 14034, 14035, 14036,\n",
       "       14037, 14038, 14039, 14040, 14041, 14042, 14043, 14044, 14045,\n",
       "       14046, 14047, 14048, 14049, 14050, 14051, 14062, 14063, 14064,\n",
       "       14065, 14066, 14067, 15000, 15001, 15002, 15003, 15004, 15005,\n",
       "       15006, 15007, 15008, 15009, 15010, 15011, 15012, 15013, 15014,\n",
       "       15015, 15016, 15017, 15018, 15019, 15020, 15021, 15022, 15023,\n",
       "       15024, 15025, 15026, 15027, 15028, 15029, 15030, 15031, 15032,\n",
       "       15033, 15034, 15035, 15036, 15037, 15038, 15039, 15040, 15041,\n",
       "       15042, 15043, 15044, 15045, 15046, 15047, 15048, 15049, 15050,\n",
       "       15051, 15052, 15053, 15054, 15055, 15056, 15057, 15058, 15059,\n",
       "       15060, 15061, 15062, 15063, 15064, 15065, 15066, 15067, 15068,\n",
       "       15069, 15070, 15071, 15072, 15073, 15074, 15075, 15076, 15077,\n",
       "       15078, 15079, 15080, 15081, 15082, 15083, 15084, 15085, 15086,\n",
       "       15087, 15088, 15089, 15090, 15103, 15104, 15105, 15106, 17000,\n",
       "       17001, 17002, 17003, 17004, 17005, 17006, 17007, 17008, 17009,\n",
       "       17010, 17011, 17012, 17013, 17014, 17015, 17016, 17017, 17018,\n",
       "       17019, 17020, 17021, 17022, 17023, 17024, 17025, 17026, 17027,\n",
       "       17028, 17029, 17030, 17031, 17032, 17033, 17034, 17035, 17036,\n",
       "       17037, 17038, 17039, 17040, 17041, 17042, 17043, 17044, 17045,\n",
       "       17046, 17047, 17048, 17049, 17065, 17066, 18001, 18002, 18003,\n",
       "       18004, 18005, 18008, 18009, 18010, 18011, 18012, 18013, 18014,\n",
       "       18015, 18016, 18017, 18018, 19000, 19001, 19002, 19003, 19004,\n",
       "       19005, 19006, 19007, 19008, 19009, 19010, 19011, 19012, 19013,\n",
       "       19014, 19015, 19016, 19017, 19018, 19019, 19020, 19021, 19022,\n",
       "       19023, 19024, 19025, 19026, 19027, 19028, 19029, 19030, 19031,\n",
       "       19032, 19033, 19034, 19035, 19036, 19037, 19038, 19039, 19040,\n",
       "       19041, 19042, 19043, 19044, 19045, 19046, 19047, 19048, 19049,\n",
       "       19050, 19051, 19052, 19053, 19054, 19055, 19056, 19057, 19058,\n",
       "       19059, 19060, 19061, 19062, 19063, 19064, 19065, 19066, 19067,\n",
       "       19068, 19069, 20000, 20001, 20002, 20003, 20004, 20005, 20006,\n",
       "       20007, 20008, 20009, 20010, 20011, 20012, 20013, 20014, 20015,\n",
       "       20016, 20017, 20018, 20019, 20020, 20021, 20022, 20023, 20024,\n",
       "       20025, 20026, 20027, 20028, 20029, 20030, 20031, 20032, 20033,\n",
       "       20034, 20035, 20036, 20037, 20038, 20039, 20040, 20041, 20042,\n",
       "       20043, 20044, 20045, 20046, 20047, 20048, 20049, 20050, 20051,\n",
       "       20052, 20053, 20054, 20055, 20056, 20057, 20058, 20059, 20060,\n",
       "       20061, 20062, 20063, 20064, 20065, 20066, 20067, 20068, 20069,\n",
       "       20070, 20071, 20072, 20079, 20080, 20081, 20082, 20083, 20084,\n",
       "       20085, 20086, 20087, 20088, 22000, 22001, 22002, 22003, 22004,\n",
       "       22005, 22006, 22007, 22008, 22009, 22010, 23000, 23001, 23002,\n",
       "       23003, 23004, 23005, 23006, 23007, 23008, 23009, 23010, 23011,\n",
       "       23012, 23013, 23014, 23015, 23016, 23017, 23018, 23019, 23020,\n",
       "       23021, 23022, 23023, 23024, 23025, 23026, 23027, 23028, 23029,\n",
       "       23030, 23031, 23032, 23040, 23041, 23042, 23043, 23044, 23045,\n",
       "       23046, 23047, 23048, 24000, 24001, 24002, 24003, 24004, 24005,\n",
       "       24006, 24007, 24008, 24009, 24010, 24011, 24012, 24013, 24014,\n",
       "       24015, 24016, 24017, 24018, 24019, 24020, 24021, 24022, 24023,\n",
       "       24024, 24025, 24026, 24027, 24028, 24029, 24030, 24031, 24042,\n",
       "       24043, 24044, 24045, 24046, 24047, 25000, 25001, 25002, 25003,\n",
       "       25004, 25005, 25006, 25007, 25008, 25009, 25010, 25011, 25012,\n",
       "       25013, 25014, 25015, 25016, 25017, 25018, 25019, 25020, 25021,\n",
       "       25022, 25023, 25024, 25025, 25026, 25027, 25028, 26000, 26001,\n",
       "       26002, 26003, 26004, 26005, 26006, 26007, 26008, 26009, 26010,\n",
       "       26011, 26012, 26013, 26014, 26015, 26016, 26017, 26018, 26019,\n",
       "       26020, 26021, 26022, 26023, 26024, 26025, 26026, 26027, 26028,\n",
       "       26029, 26030, 26031, 26032, 26033, 26034, 26035, 26036, 26037,\n",
       "       26038, 26039, 26040, 26041, 26042, 26043, 26044, 26045, 26046,\n",
       "       26047, 26048, 26049, 26050, 26051, 26052, 26053, 26054, 26055,\n",
       "       26056, 26057, 26058, 26059, 26060, 26061, 26062, 26063, 26064,\n",
       "       26065, 26066, 26067, 26068, 26069, 26085, 27001, 27002, 27003,\n",
       "       27004, 27005, 27008, 27009, 27010, 27011, 27012, 27013, 27014,\n",
       "       27015, 27016, 27017, 27018, 28000, 28001, 28002, 28003, 28004,\n",
       "       28005, 28006, 28007, 28008, 28009, 28010, 28011, 28012, 28013,\n",
       "       28014, 28015, 28016, 28017, 28018, 28019, 28020, 28021, 28022,\n",
       "       28023, 28024, 28025, 28026, 28027, 28028, 28029, 28030, 28031,\n",
       "       28032, 28033, 28034, 28035, 28036, 28037, 28038, 28039, 28040,\n",
       "       28041, 28042, 28043, 28044, 28045, 28046, 28047, 28048, 28049,\n",
       "       28050, 28051, 28052, 28060, 28061, 28062, 28063, 28064, 28065,\n",
       "       28066, 28067, 28068, 29000, 30000, 30001, 30002, 30003, 30004,\n",
       "       30005, 30006, 30007, 30008, 30009, 30010, 30011, 30012, 30013,\n",
       "       30014, 30015, 30016, 30017, 30018, 30019, 30020, 30021, 30022,\n",
       "       30023, 30024, 30025, 30026, 30027, 30028, 30029, 30044, 30045,\n",
       "       30046, 32000, 32001, 32002, 32003, 32004, 34000, 34001, 34002,\n",
       "       34003, 34004, 34005, 34006, 34007, 34008, 34009, 34010, 34011,\n",
       "       34012, 34013, 34014, 34015, 34016, 34017, 34018, 34019, 34020,\n",
       "       34021, 34022, 34023, 34024, 34025, 34026, 34027, 37001, 37002,\n",
       "       37003, 37004, 37005, 37006, 37007, 37008, 37009, 37010, 37011,\n",
       "       37012, 37013, 37014, 37015, 37016, 37017, 37018, 37019, 37020,\n",
       "       37021, 37022, 37023, 37024, 37025, 37026, 37027, 37028, 37029,\n",
       "       37030, 37043, 37044, 37045, 37046, 37047, 38000, 38001, 38002,\n",
       "       38003, 38004, 38005, 38006, 38007, 38008, 38009, 38010, 38011,\n",
       "       38012, 38013, 38014, 38015, 38016, 38017, 38018, 38019, 38020,\n",
       "       38021, 38022, 38023, 38024, 38025, 38026, 38027, 38028, 38029,\n",
       "       38030, 38031, 38032, 38033, 38034, 38035, 38036, 38037, 38038,\n",
       "       38039, 38040, 38041, 38042, 38043, 38044, 38045, 38046, 38047,\n",
       "       38048, 38049, 38050, 38051, 38060, 38061, 38062, 38063, 38064,\n",
       "       38065, 38066, 38067, 38068, 39000, 39001, 41000, 41001, 41002,\n",
       "       41003, 41004, 41005, 41006, 41007, 41008, 41009, 41010, 41011,\n",
       "       41012, 41013, 41014, 41015, 41016, 41017, 41018, 41019, 41020,\n",
       "       41021, 41022, 41023, 41024, 41025, 41026, 41027, 41028, 41029,\n",
       "       41030, 41031, 41032, 41033, 41034, 41035, 41036, 41037, 41038,\n",
       "       41039, 41040, 41041, 41042, 41043, 41044, 41045, 41046, 41047,\n",
       "       41048, 41049, 41050, 41051, 41052, 41053, 41054, 41055, 41056,\n",
       "       41057, 41058, 41059, 41060, 41061, 41062, 41063, 41064, 41065,\n",
       "       41066, 41067, 41068, 41069, 41070, 41071, 41081, 41082, 41083,\n",
       "       41084, 41085, 41086, 41087, 42000, 42001, 42002, 42003, 42004,\n",
       "       42005, 42006, 42007, 42008, 42009, 42010, 42011, 42012, 42013,\n",
       "       42014, 42015, 42016, 42017, 42018, 42019, 42020, 42021, 42022,\n",
       "       42023, 42024, 42025, 44004, 44005, 44006, 44007, 44024, 44025,\n",
       "       44026, 44027, 45000, 45001, 45002, 45003, 45004, 45005, 45006,\n",
       "       45007, 45008, 45009, 45010, 45011, 45012, 45013, 45014, 45015,\n",
       "       45016, 45017, 45018, 45019, 45020, 45021, 45022, 45023, 45024,\n",
       "       45025, 45026, 45027, 45028, 45029, 45030, 45031, 45032, 45033,\n",
       "       45034, 45035, 45036, 45037, 45038, 45039, 45040, 45041, 45042,\n",
       "       45043, 45044, 45045, 45046, 45047, 45048, 45049, 46000, 46001,\n",
       "       46002, 46003, 46004, 46005, 46006, 46007, 46008, 46009, 46010,\n",
       "       46011, 46012, 46013, 46014, 46015, 46016, 46017, 46018, 46019,\n",
       "       46020, 46021, 46022, 46023, 46024, 46025, 46026, 46027, 46028,\n",
       "       46029, 46030, 46031, 46032, 46033, 46034, 46035, 46036, 46037,\n",
       "       46038, 46039, 46040, 46041, 46042, 46043, 46044, 46045, 46046,\n",
       "       46047, 46048, 46049, 46050, 46051, 46052, 46053, 46054, 46055,\n",
       "       46056, 46057, 46058, 46059, 46060, 46061, 46062, 46063, 46064,\n",
       "       46065, 46066, 46067, 46068, 46069, 48000, 48001, 48002, 48003,\n",
       "       50000, 50001, 50002, 50003, 50004, 50005, 50006, 50007, 50008,\n",
       "       50009, 50010, 50011, 50012, 50013, 50014, 50015, 50016, 50017,\n",
       "       50018, 50019, 50020, 50021, 50022, 50023, 50024, 50025, 50026,\n",
       "       50027, 50028, 50029, 50030, 50031, 50032, 50033, 50034, 50035,\n",
       "       50036, 50037, 50038, 50039, 50040, 50041, 50042, 50043, 50044,\n",
       "       50045, 50046, 50047, 50048, 50049, 50064, 50065, 50066, 51000,\n",
       "       51001, 51002, 54000, 54001, 54002, 54003, 54004, 54005, 56013,\n",
       "       56014, 56015, 56016, 56017, 56018, 56019, 58000, 58001, 58002,\n",
       "       58003, 58004, 58005, 58006, 58007, 58008, 58009, 58010, 58011,\n",
       "       58012, 58013, 58014, 58015, 58016, 58017, 58018, 58019, 58020,\n",
       "       58021, 58022, 58023, 58024, 58025, 58026, 58027, 58028, 58029,\n",
       "       58030, 58031, 58042, 58043, 58044, 58045, 58046, 58047, 59000,\n",
       "       60000, 60001, 60002, 60003, 60004, 60005, 60006, 60007, 60008,\n",
       "       62000, 62001, 62002, 62003, 62004, 62005, 62006, 62007, 62008,\n",
       "       62009, 62010, 62011, 62012, 62013, 62014, 62015, 62016, 62017,\n",
       "       62018, 62019, 62020, 62021, 62022, 62023, 62024, 62025, 62026,\n",
       "       62027, 62028, 62029, 62030, 62031, 62032, 62033, 62034, 62035,\n",
       "       62036, 62037, 62038, 62039, 62040, 62041, 62042, 62043, 62044,\n",
       "       62045, 62046, 62047, 62048, 62049, 62050, 62051, 62052, 62053,\n",
       "       62054, 62056, 62057, 62058, 62059, 62060, 62061, 62062, 62063,\n",
       "       62064, 62065, 62066, 62067, 62068, 64000, 64001, 64002, 64003,\n",
       "       64004, 64005, 64006, 64007, 64008, 64009, 64010, 64011, 64012,\n",
       "       64013, 64014, 64015, 64016, 64017, 64018, 64019, 64020, 64021,\n",
       "       64022, 64023, 64024, 64025, 64026, 64027, 64028, 64029, 64030,\n",
       "       64031, 64032, 64033, 64034, 64035, 64036, 64037, 64038, 64039,\n",
       "       64040, 64041, 64042, 64043, 64044, 64045, 64046, 64047, 64048,\n",
       "       64049, 64050, 64064, 64065, 64066, 66000, 66001, 66002, 66003,\n",
       "       66004, 66005, 66006, 66007, 66008, 66009, 66010, 66011, 66012,\n",
       "       67000, 67001, 67002, 68000, 68001, 70000, 70001, 70002, 70003,\n",
       "       70004, 70005, 70006, 70007, 70008, 70009, 70010, 70011, 70012,\n",
       "       70013, 70014, 70015, 70016, 70017, 70018, 70019, 70020, 70021,\n",
       "       70022, 70023, 70024, 70025, 70026, 70027, 70028, 70029, 71002,\n",
       "       71003, 71004, 71005, 71006, 71007, 71008, 71009, 71010, 71011,\n",
       "       71012, 71013, 71014, 71015, 71016, 71017, 71018, 71019, 71020,\n",
       "       71021, 71022, 71023, 71024, 71025, 71026, 71027, 71028, 71029,\n",
       "       71044, 71045, 71046, 72000, 72001, 72002, 73000, 73001, 73002,\n",
       "       73003, 73004, 73005, 73006, 73007, 73008, 73009, 73010, 73011,\n",
       "       73012, 73013, 73014, 73015, 73016, 73017, 73018, 73019, 73020,\n",
       "       73021, 73022, 73023, 73024, 73025, 73026, 73027, 73028, 73029,\n",
       "       73030, 73031, 73032, 73033, 73034, 73035, 73036, 73037, 73038,\n",
       "       73039, 73040, 73041, 73042, 73043, 73044, 73045, 73046, 73047,\n",
       "       73048, 73049, 73050, 73064, 73065, 73066, 74000, 74001, 74002,\n",
       "       74003, 74004, 74005, 74006, 74007, 74008, 74009, 74010, 74011,\n",
       "       74012, 74013, 74014, 74015, 74016, 74017, 74018, 74019, 74020,\n",
       "       74021, 74022, 74023, 74024, 74025, 74026, 74027, 74028, 74029,\n",
       "       74044, 74045, 74046, 75000, 75001, 75002, 75003, 75004, 75005,\n",
       "       75006, 75007, 75008, 75009, 75010, 75011, 75012, 75013, 75014,\n",
       "       75015, 75016, 75017, 75018, 75019, 75020, 75021, 75022, 75023,\n",
       "       75024, 75025, 75026, 75027, 75028, 77000, 79000, 79001, 79002,\n",
       "       79003, 79004, 79005, 79006, 79007, 79008, 79009, 79010, 79011,\n",
       "       79012, 79013, 79014, 79015, 79016, 79017, 79018, 79019, 79020,\n",
       "       79021, 79022, 79023, 79024, 79025, 79026, 79027, 79028, 79029,\n",
       "       79030, 79031, 79032, 79033, 79034, 79035, 79036, 79037, 79038,\n",
       "       79039, 79040, 79041, 79042, 79043, 79044, 79045, 79046, 79047,\n",
       "       79048, 79049, 79050, 79062, 79063, 79064, 79065, 79066, 79067,\n",
       "       81000, 81001, 81002, 81003, 81004, 81005, 81006, 81007, 81008,\n",
       "       81009, 81010, 81011, 81021, 81022, 81023, 81024, 81025, 81026,\n",
       "       81027, 82000, 82001, 82002, 83000, 83001, 83002, 83003, 83004,\n",
       "       83005, 83006, 83007, 83008, 83009, 83010, 83011, 83012, 83013,\n",
       "       83014, 83015, 83016, 83017, 83018, 83019, 83020, 83021, 83022,\n",
       "       83023, 83024, 83025, 83026, 83027, 83028, 83029, 83030, 83031,\n",
       "       83032, 83033, 83034, 83035, 83036, 83037, 83038, 83039, 83040,\n",
       "       83041, 83042, 83043, 83044, 83045, 83046, 83047, 83048, 83049,\n",
       "       85000, 85001, 85002, 85003, 85004, 85005, 85006, 85007, 85008,\n",
       "       85009, 85010, 85011, 85012, 85013, 85014, 85015, 85016, 85017,\n",
       "       85018, 85019, 85020, 85021, 85022, 85023, 85024, 85025, 85026,\n",
       "       85027, 85028, 85029, 85034, 85035, 85036, 85037, 85038, 85039,\n",
       "       86000, 86001, 86002, 86003, 86004, 86005, 86006, 86007, 86008,\n",
       "       86009, 86010, 86011, 86012, 86013, 87000, 87001, 87002, 87003,\n",
       "       87004, 87005, 87006, 87007, 87008, 88000, 88001, 88002, 88003,\n",
       "       88004, 88005, 88008, 88009, 88010, 88011, 88012, 88013, 88014,\n",
       "       88015, 88016, 88017, 88018, 89000, 89001, 89002, 89003, 89004,\n",
       "       89005, 89008, 89009, 89010, 89011, 89012, 89013, 89014, 89015,\n",
       "       89016, 89017, 89018, 90000, 90001, 90002, 90003, 90004, 90005,\n",
       "       90006, 90007, 90008, 90009, 90010, 90011, 90012, 90013, 90014,\n",
       "       90015, 90016, 90017, 90018, 90019, 90020, 90021, 90022, 90023,\n",
       "       90024, 90025, 90026, 90027, 90028, 90029, 90030, 90031, 90032,\n",
       "       90033, 90034, 90035, 90036, 90037, 90038, 90039, 90040, 90041,\n",
       "       90042, 90043, 90044, 90045, 90046, 90047, 90048, 90049, 90050,\n",
       "       90051, 90052, 90060, 90061, 90062, 90063, 90064, 90065, 90066,\n",
       "       90067, 90068, 91000, 91001, 91002, 91003, 91004, 91005, 91006,\n",
       "       91007, 91008, 91009, 91010, 91011, 91012, 91013, 91014, 91015,\n",
       "       91016, 91017, 91018, 91019, 91020, 91021, 91022, 91023, 91024,\n",
       "       91025, 91026, 91027, 91028, 91029, 91030, 91031, 91032, 91033,\n",
       "       91034, 91035, 91036, 91037, 91038, 91039, 91040, 91041, 91042,\n",
       "       91043, 91044, 91045, 91046, 91047, 91048, 91049, 91050, 91051,\n",
       "       91061, 91062, 91063, 91064, 91065, 91066, 91067, 91068, 92000,\n",
       "       93000, 93001, 93002, 93003, 93004, 93005, 93006, 93007, 93008,\n",
       "       93009, 93010, 93011, 93012, 93013, 93014, 93015, 93016, 93017,\n",
       "       93018, 93019, 93020, 93021, 93022, 93023, 93024, 93025, 93026,\n",
       "       93027, 93028, 93029, 93030, 93031, 93032, 93033, 93034, 93035,\n",
       "       93036, 93037, 93038, 93039, 93040, 93041, 93042, 93043, 93044,\n",
       "       93045, 93046, 93047, 93048, 93049, 93050, 93051, 93052, 93053,\n",
       "       93054, 93055, 93056, 93057, 93058, 93059, 93060, 93061, 93062,\n",
       "       93063, 93064, 93065, 93066, 93067, 93068, 93069, 93070, 93071,\n",
       "       93081, 93082, 93083, 93084, 93085, 93086, 93087, 93088, 94000,\n",
       "       94001, 94002, 94003, 94004, 94005, 94006, 94007, 94008, 94009,\n",
       "       94010, 94011, 94012, 94013, 94014, 94015, 94016, 94017, 94018,\n",
       "       94019, 94020, 94021, 94022, 94023, 94024, 94025, 94026, 94027,\n",
       "       94028, 94029, 94030, 94031, 94032, 94033, 94034, 94035, 94036,\n",
       "       94037, 94038, 94039, 94040, 94041, 94042, 94043, 94044, 94045,\n",
       "       94046, 94047, 94048, 94049, 94064, 94065, 94066, 95003, 95004,\n",
       "       95005, 95006, 95007, 95008, 95009, 95010, 95011, 95019, 95020,\n",
       "       95021, 95022, 95023, 95024, 95025, 95026, 95027, 95028, 95029,\n",
       "       95045, 96000, 96001, 96002, 96003, 96004, 96005, 96006, 96007,\n",
       "       96008, 96009, 96010, 96011, 96012, 96013, 96014, 96015, 96016,\n",
       "       96017, 96018, 96019, 96020, 96021, 96022, 96023, 96024, 96025,\n",
       "       96026, 96027, 96028, 96029, 96030, 96042, 96043, 96044, 96045,\n",
       "       96046, 96047, 97000, 97001, 97002, 97003, 97004, 97005, 97006,\n",
       "       97007, 97008, 97009, 97010, 98000])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x132054128>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0],X[:,1],s=0.1)\n",
    "#plt.plot(X[large_error_index,0],X[large_error_index,1],'r.',markersize=0.5)\n",
    "#plt.scatter(X[large_error_index,0],X[large_error_index,1],s=0.1,c='r')\n",
    "th = 2000\n",
    "plt.scatter(X[sort_index[:th],0],X[sort_index[:th],1],s=0.1,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitData/'\n",
    "model_dir = '/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/'\n",
    "CFP = config.CFP\n",
    "config.ReadConfigFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning Training: global variable initialization...\n",
      "[ Tue Dec  4 20:42:00 2018], epoch [  20], lr[0.10000000] ,loss[0.3413880169]\n",
      "[ Tue Dec  4 20:42:00 2018], validation: iter [  20], loss[0.3624087870]\n",
      "[ Tue Dec  4 20:42:00 2018], epoch [  40], lr[0.10000000] ,loss[0.3104988635]\n",
      "[ Tue Dec  4 20:42:00 2018], validation: iter [  40], loss[0.3296366334]\n",
      "[ Tue Dec  4 20:42:01 2018], epoch [  60], lr[0.10000000] ,loss[0.2455753088]\n",
      "[ Tue Dec  4 20:42:01 2018], validation: iter [  60], loss[0.2626973689]\n",
      "[ Tue Dec  4 20:42:01 2018], epoch [  80], lr[0.10000000] ,loss[0.2410315573]\n",
      "[ Tue Dec  4 20:42:01 2018], validation: iter [  80], loss[0.2589938641]\n",
      "[ Tue Dec  4 20:42:02 2018], epoch [ 100], lr[0.10000000] ,loss[0.2392812520]\n",
      "[ Tue Dec  4 20:42:02 2018], validation: iter [ 100], loss[0.2572931945]\n",
      "[ Tue Dec  4 20:42:02 2018], epoch [ 120], lr[0.10000000] ,loss[0.2375936061]\n",
      "[ Tue Dec  4 20:42:02 2018], validation: iter [ 120], loss[0.2555260360]\n",
      "[ Tue Dec  4 20:42:03 2018], epoch [ 140], lr[0.10000000] ,loss[0.2364774197]\n",
      "[ Tue Dec  4 20:42:03 2018], validation: iter [ 140], loss[0.2541678846]\n",
      "[ Tue Dec  4 20:42:04 2018], epoch [ 160], lr[0.10000000] ,loss[0.2357871830]\n",
      "[ Tue Dec  4 20:42:04 2018], validation: iter [ 160], loss[0.2533368468]\n",
      "[ Tue Dec  4 20:42:04 2018], epoch [ 180], lr[0.10000000] ,loss[0.2352219373]\n",
      "[ Tue Dec  4 20:42:04 2018], validation: iter [ 180], loss[0.2526501417]\n",
      "[ Tue Dec  4 20:42:05 2018], epoch [ 200], lr[0.10000000] ,loss[0.2347698808]\n",
      "[ Tue Dec  4 20:42:05 2018], validation: iter [ 200], loss[0.2520855069]\n",
      "[ Tue Dec  4 20:42:05 2018], epoch [ 220], lr[0.10000000] ,loss[0.2343674302]\n",
      "[ Tue Dec  4 20:42:05 2018], validation: iter [ 220], loss[0.2516012192]\n",
      "[ Tue Dec  4 20:42:06 2018], epoch [ 240], lr[0.10000000] ,loss[0.2340948284]\n",
      "[ Tue Dec  4 20:42:06 2018], validation: iter [ 240], loss[0.2512950301]\n",
      "[ Tue Dec  4 20:42:06 2018], epoch [ 260], lr[0.10000000] ,loss[0.2351403832]\n",
      "[ Tue Dec  4 20:42:06 2018], validation: iter [ 260], loss[0.2524310946]\n",
      "[ Tue Dec  4 20:42:07 2018], epoch [ 280], lr[0.10000000] ,loss[0.2338763028]\n",
      "[ Tue Dec  4 20:42:07 2018], validation: iter [ 280], loss[0.2507865131]\n",
      "[ Tue Dec  4 20:42:07 2018], epoch [ 300], lr[0.10000000] ,loss[0.2349250019]\n",
      "[ Tue Dec  4 20:42:07 2018], validation: iter [ 300], loss[0.2515260279]\n",
      "[ Tue Dec  4 20:42:08 2018], epoch [ 320], lr[0.10000000] ,loss[0.2357762158]\n",
      "[ Tue Dec  4 20:42:08 2018], validation: iter [ 320], loss[0.2520000339]\n",
      "[ Tue Dec  4 20:42:09 2018], epoch [ 340], lr[0.10000000] ,loss[0.2332606614]\n",
      "[ Tue Dec  4 20:42:09 2018], validation: iter [ 340], loss[0.2503201663]\n",
      "[ Tue Dec  4 20:42:09 2018], epoch [ 360], lr[0.10000000] ,loss[0.2346689999]\n",
      "[ Tue Dec  4 20:42:09 2018], validation: iter [ 360], loss[0.2523664534]\n",
      "[ Tue Dec  4 20:42:10 2018], epoch [ 380], lr[0.10000000] ,loss[0.2332225144]\n",
      "[ Tue Dec  4 20:42:10 2018], validation: iter [ 380], loss[0.2500010431]\n",
      "[ Tue Dec  4 20:42:10 2018], epoch [ 400], lr[0.10000000] ,loss[0.2336444259]\n",
      "[ Tue Dec  4 20:42:10 2018], validation: iter [ 400], loss[0.2505348325]\n",
      "[ Tue Dec  4 20:42:11 2018], epoch [ 420], lr[0.10000000] ,loss[0.2340707332]\n",
      "[ Tue Dec  4 20:42:11 2018], validation: iter [ 420], loss[0.2513877749]\n",
      "[ Tue Dec  4 20:42:12 2018], epoch [ 440], lr[0.10000000] ,loss[0.2330252081]\n",
      "[ Tue Dec  4 20:42:12 2018], validation: iter [ 440], loss[0.2501318455]\n",
      "[ Tue Dec  4 20:42:12 2018], epoch [ 460], lr[0.10000000] ,loss[0.2347181588]\n",
      "[ Tue Dec  4 20:42:12 2018], validation: iter [ 460], loss[0.2513037622]\n",
      "[ Tue Dec  4 20:42:13 2018], epoch [ 480], lr[0.10000000] ,loss[0.2331387103]\n",
      "[ Tue Dec  4 20:42:13 2018], validation: iter [ 480], loss[0.2497824281]\n",
      "[ Tue Dec  4 20:42:13 2018], epoch [ 500], lr[0.10000000] ,loss[0.2378503531]\n",
      "[ Tue Dec  4 20:42:13 2018], validation: iter [ 500], loss[0.2562409639]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_500']\n",
      "[ Tue Dec  4 20:42:14 2018], epoch [ 520], lr[0.10000000] ,loss[0.2327725291]\n",
      "[ Tue Dec  4 20:42:14 2018], validation: iter [ 520], loss[0.2495492995]\n",
      "[ Tue Dec  4 20:42:15 2018], epoch [ 540], lr[0.10000000] ,loss[0.2325532585]\n",
      "[ Tue Dec  4 20:42:15 2018], validation: iter [ 540], loss[0.2490663677]\n",
      "[ Tue Dec  4 20:42:15 2018], epoch [ 560], lr[0.10000000] ,loss[0.2328709960]\n",
      "[ Tue Dec  4 20:42:15 2018], validation: iter [ 560], loss[0.2493575960]\n",
      "[ Tue Dec  4 20:42:16 2018], epoch [ 580], lr[0.10000000] ,loss[0.2330568880]\n",
      "[ Tue Dec  4 20:42:16 2018], validation: iter [ 580], loss[0.2497798055]\n",
      "[ Tue Dec  4 20:42:16 2018], epoch [ 600], lr[0.10000000] ,loss[0.2349459082]\n",
      "[ Tue Dec  4 20:42:16 2018], validation: iter [ 600], loss[0.2513667047]\n",
      "[ Tue Dec  4 20:42:17 2018], epoch [ 620], lr[0.10000000] ,loss[0.2325350344]\n",
      "[ Tue Dec  4 20:42:17 2018], validation: iter [ 620], loss[0.2491126359]\n",
      "[ Tue Dec  4 20:42:17 2018], epoch [ 640], lr[0.10000000] ,loss[0.2327858955]\n",
      "[ Tue Dec  4 20:42:17 2018], validation: iter [ 640], loss[0.2491154522]\n",
      "[ Tue Dec  4 20:42:18 2018], epoch [ 660], lr[0.10000000] ,loss[0.2327534407]\n",
      "[ Tue Dec  4 20:42:18 2018], validation: iter [ 660], loss[0.2487824410]\n",
      "[ Tue Dec  4 20:42:18 2018], epoch [ 680], lr[0.10000000] ,loss[0.2327540964]\n",
      "[ Tue Dec  4 20:42:18 2018], validation: iter [ 680], loss[0.2492421418]\n",
      "[ Tue Dec  4 20:42:19 2018], epoch [ 700], lr[0.10000000] ,loss[0.2325870544]\n",
      "[ Tue Dec  4 20:42:19 2018], validation: iter [ 700], loss[0.2487482429]\n",
      "[ Tue Dec  4 20:42:19 2018], epoch [ 720], lr[0.10000000] ,loss[0.2322748899]\n",
      "[ Tue Dec  4 20:42:19 2018], validation: iter [ 720], loss[0.2487407625]\n",
      "[ Tue Dec  4 20:42:20 2018], epoch [ 740], lr[0.10000000] ,loss[0.2329706997]\n",
      "[ Tue Dec  4 20:42:20 2018], validation: iter [ 740], loss[0.2491248846]\n",
      "[ Tue Dec  4 20:42:21 2018], epoch [ 760], lr[0.10000000] ,loss[0.2326614857]\n",
      "[ Tue Dec  4 20:42:21 2018], validation: iter [ 760], loss[0.2491972297]\n",
      "[ Tue Dec  4 20:42:21 2018], epoch [ 780], lr[0.10000000] ,loss[0.2344386280]\n",
      "[ Tue Dec  4 20:42:21 2018], validation: iter [ 780], loss[0.2497285604]\n",
      "[ Tue Dec  4 20:42:22 2018], epoch [ 800], lr[0.10000000] ,loss[0.2321462333]\n",
      "[ Tue Dec  4 20:42:22 2018], validation: iter [ 800], loss[0.2484278083]\n",
      "[ Tue Dec  4 20:42:23 2018], epoch [ 820], lr[0.10000000] ,loss[0.2320242375]\n",
      "[ Tue Dec  4 20:42:23 2018], validation: iter [ 820], loss[0.2483829260]\n",
      "[ Tue Dec  4 20:42:23 2018], epoch [ 840], lr[0.10000000] ,loss[0.2320335060]\n",
      "[ Tue Dec  4 20:42:23 2018], validation: iter [ 840], loss[0.2484863102]\n",
      "[ Tue Dec  4 20:42:24 2018], epoch [ 860], lr[0.10000000] ,loss[0.2331841439]\n",
      "[ Tue Dec  4 20:42:24 2018], validation: iter [ 860], loss[0.2484963685]\n",
      "[ Tue Dec  4 20:42:24 2018], epoch [ 880], lr[0.10000000] ,loss[0.2320405543]\n",
      "[ Tue Dec  4 20:42:24 2018], validation: iter [ 880], loss[0.2485403121]\n",
      "[ Tue Dec  4 20:42:25 2018], epoch [ 900], lr[0.10000000] ,loss[0.2319167405]\n",
      "[ Tue Dec  4 20:42:25 2018], validation: iter [ 900], loss[0.2482519150]\n",
      "[ Tue Dec  4 20:42:25 2018], epoch [ 920], lr[0.10000000] ,loss[0.2331918031]\n",
      "[ Tue Dec  4 20:42:25 2018], validation: iter [ 920], loss[0.2494702786]\n",
      "[ Tue Dec  4 20:42:26 2018], epoch [ 940], lr[0.10000000] ,loss[0.2323232591]\n",
      "[ Tue Dec  4 20:42:26 2018], validation: iter [ 940], loss[0.2485652715]\n",
      "[ Tue Dec  4 20:42:26 2018], epoch [ 960], lr[0.10000000] ,loss[0.2374230921]\n",
      "[ Tue Dec  4 20:42:26 2018], validation: iter [ 960], loss[0.2560905814]\n",
      "[ Tue Dec  4 20:42:27 2018], epoch [ 980], lr[0.10000000] ,loss[0.2330980599]\n",
      "[ Tue Dec  4 20:42:27 2018], validation: iter [ 980], loss[0.2489715666]\n",
      "[ Tue Dec  4 20:42:28 2018], epoch [1000], lr[0.10000000] ,loss[0.2317483723]\n",
      "[ Tue Dec  4 20:42:28 2018], validation: iter [1000], loss[0.2480982840]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_1000']\n",
      "[ Tue Dec  4 20:42:28 2018], epoch [1020], lr[0.10000000] ,loss[0.2319789827]\n",
      "[ Tue Dec  4 20:42:28 2018], validation: iter [1020], loss[0.2481994778]\n",
      "[ Tue Dec  4 20:42:29 2018], epoch [1040], lr[0.10000000] ,loss[0.2333986461]\n",
      "[ Tue Dec  4 20:42:29 2018], validation: iter [1040], loss[0.2496056259]\n",
      "[ Tue Dec  4 20:42:30 2018], epoch [1060], lr[0.10000000] ,loss[0.2322190553]\n",
      "[ Tue Dec  4 20:42:30 2018], validation: iter [1060], loss[0.2486949265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 20:42:30 2018], epoch [1080], lr[0.10000000] ,loss[0.2317035049]\n",
      "[ Tue Dec  4 20:42:30 2018], validation: iter [1080], loss[0.2481981069]\n",
      "[ Tue Dec  4 20:42:31 2018], epoch [1100], lr[0.10000000] ,loss[0.2324570864]\n",
      "[ Tue Dec  4 20:42:31 2018], validation: iter [1100], loss[0.2492799610]\n",
      "[ Tue Dec  4 20:42:32 2018], epoch [1120], lr[0.10000000] ,loss[0.2319381237]\n",
      "[ Tue Dec  4 20:42:32 2018], validation: iter [1120], loss[0.2479735911]\n",
      "[ Tue Dec  4 20:42:33 2018], epoch [1140], lr[0.10000000] ,loss[0.2321629524]\n",
      "[ Tue Dec  4 20:42:33 2018], validation: iter [1140], loss[0.2482413352]\n",
      "[ Tue Dec  4 20:42:33 2018], epoch [1160], lr[0.10000000] ,loss[0.2322482616]\n",
      "[ Tue Dec  4 20:42:33 2018], validation: iter [1160], loss[0.2485295683]\n",
      "[ Tue Dec  4 20:42:34 2018], epoch [1180], lr[0.10000000] ,loss[0.2317163497]\n",
      "[ Tue Dec  4 20:42:34 2018], validation: iter [1180], loss[0.2484838665]\n",
      "[ Tue Dec  4 20:42:34 2018], epoch [1200], lr[0.10000000] ,loss[0.2320197374]\n",
      "[ Tue Dec  4 20:42:34 2018], validation: iter [1200], loss[0.2481332421]\n",
      "[ Tue Dec  4 20:42:35 2018], epoch [1220], lr[0.10000000] ,loss[0.2318747193]\n",
      "[ Tue Dec  4 20:42:35 2018], validation: iter [1220], loss[0.2483723760]\n",
      "[ Tue Dec  4 20:42:35 2018], epoch [1240], lr[0.10000000] ,loss[0.2314432710]\n",
      "[ Tue Dec  4 20:42:35 2018], validation: iter [1240], loss[0.2477433532]\n",
      "[ Tue Dec  4 20:42:36 2018], epoch [1260], lr[0.10000000] ,loss[0.2384950072]\n",
      "[ Tue Dec  4 20:42:36 2018], validation: iter [1260], loss[0.2506868243]\n",
      "[ Tue Dec  4 20:42:36 2018], epoch [1280], lr[0.10000000] ,loss[0.2316738665]\n",
      "[ Tue Dec  4 20:42:36 2018], validation: iter [1280], loss[0.2483371645]\n",
      "[ Tue Dec  4 20:42:37 2018], epoch [1300], lr[0.10000000] ,loss[0.2315569371]\n",
      "[ Tue Dec  4 20:42:37 2018], validation: iter [1300], loss[0.2477072626]\n",
      "[ Tue Dec  4 20:42:37 2018], epoch [1320], lr[0.10000000] ,loss[0.2313483655]\n",
      "[ Tue Dec  4 20:42:37 2018], validation: iter [1320], loss[0.2475978136]\n",
      "[ Tue Dec  4 20:42:38 2018], epoch [1340], lr[0.10000000] ,loss[0.2315585464]\n",
      "[ Tue Dec  4 20:42:38 2018], validation: iter [1340], loss[0.2478140295]\n",
      "[ Tue Dec  4 20:42:39 2018], epoch [1360], lr[0.10000000] ,loss[0.2342159599]\n",
      "[ Tue Dec  4 20:42:39 2018], validation: iter [1360], loss[0.2497613430]\n",
      "[ Tue Dec  4 20:42:39 2018], epoch [1380], lr[0.10000000] ,loss[0.2318231612]\n",
      "[ Tue Dec  4 20:42:39 2018], validation: iter [1380], loss[0.2477845252]\n",
      "[ Tue Dec  4 20:42:40 2018], epoch [1400], lr[0.10000000] ,loss[0.2314544171]\n",
      "[ Tue Dec  4 20:42:40 2018], validation: iter [1400], loss[0.2476073951]\n",
      "[ Tue Dec  4 20:42:40 2018], epoch [1420], lr[0.10000000] ,loss[0.2312921882]\n",
      "[ Tue Dec  4 20:42:40 2018], validation: iter [1420], loss[0.2475988269]\n",
      "[ Tue Dec  4 20:42:41 2018], epoch [1440], lr[0.10000000] ,loss[0.2384298295]\n",
      "[ Tue Dec  4 20:42:41 2018], validation: iter [1440], loss[0.2548896372]\n",
      "[ Tue Dec  4 20:42:41 2018], epoch [1460], lr[0.10000000] ,loss[0.2324156612]\n",
      "[ Tue Dec  4 20:42:41 2018], validation: iter [1460], loss[0.2483121455]\n",
      "[ Tue Dec  4 20:42:42 2018], epoch [1480], lr[0.10000000] ,loss[0.2313202024]\n",
      "[ Tue Dec  4 20:42:42 2018], validation: iter [1480], loss[0.2474219799]\n",
      "[ Tue Dec  4 20:42:43 2018], epoch [1500], lr[0.10000000] ,loss[0.2312228680]\n",
      "[ Tue Dec  4 20:42:43 2018], validation: iter [1500], loss[0.2474576533]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_1500']\n",
      "[ Tue Dec  4 20:42:43 2018], epoch [1520], lr[0.10000000] ,loss[0.2314550728]\n",
      "[ Tue Dec  4 20:42:43 2018], validation: iter [1520], loss[0.2477124184]\n",
      "[ Tue Dec  4 20:42:44 2018], epoch [1540], lr[0.10000000] ,loss[0.2321278751]\n",
      "[ Tue Dec  4 20:42:44 2018], validation: iter [1540], loss[0.2475655675]\n",
      "[ Tue Dec  4 20:42:44 2018], epoch [1560], lr[0.10000000] ,loss[0.2311934531]\n",
      "[ Tue Dec  4 20:42:44 2018], validation: iter [1560], loss[0.2477062941]\n",
      "[ Tue Dec  4 20:42:45 2018], epoch [1580], lr[0.10000000] ,loss[0.2311013788]\n",
      "[ Tue Dec  4 20:42:45 2018], validation: iter [1580], loss[0.2474672496]\n",
      "[ Tue Dec  4 20:42:46 2018], epoch [1600], lr[0.10000000] ,loss[0.2311561108]\n",
      "[ Tue Dec  4 20:42:46 2018], validation: iter [1600], loss[0.2473590821]\n",
      "[ Tue Dec  4 20:42:46 2018], epoch [1620], lr[0.10000000] ,loss[0.2316804975]\n",
      "[ Tue Dec  4 20:42:46 2018], validation: iter [1620], loss[0.2480619103]\n",
      "[ Tue Dec  4 20:42:47 2018], epoch [1640], lr[0.10000000] ,loss[0.2315551490]\n",
      "[ Tue Dec  4 20:42:47 2018], validation: iter [1640], loss[0.2490145713]\n",
      "[ Tue Dec  4 20:42:47 2018], epoch [1660], lr[0.10000000] ,loss[0.2311053127]\n",
      "[ Tue Dec  4 20:42:47 2018], validation: iter [1660], loss[0.2475427687]\n",
      "[ Tue Dec  4 20:42:48 2018], epoch [1680], lr[0.10000000] ,loss[0.2310943156]\n",
      "[ Tue Dec  4 20:42:48 2018], validation: iter [1680], loss[0.2472112924]\n",
      "[ Tue Dec  4 20:42:49 2018], epoch [1700], lr[0.10000000] ,loss[0.2310024649]\n",
      "[ Tue Dec  4 20:42:49 2018], validation: iter [1700], loss[0.2472682744]\n",
      "[ Tue Dec  4 20:42:49 2018], epoch [1720], lr[0.10000000] ,loss[0.2378491908]\n",
      "[ Tue Dec  4 20:42:49 2018], validation: iter [1720], loss[0.2544798553]\n",
      "[ Tue Dec  4 20:42:50 2018], epoch [1740], lr[0.10000000] ,loss[0.2315116823]\n",
      "[ Tue Dec  4 20:42:50 2018], validation: iter [1740], loss[0.2482389063]\n",
      "[ Tue Dec  4 20:42:50 2018], epoch [1760], lr[0.10000000] ,loss[0.2311691642]\n",
      "[ Tue Dec  4 20:42:50 2018], validation: iter [1760], loss[0.2475231588]\n",
      "[ Tue Dec  4 20:42:51 2018], epoch [1780], lr[0.10000000] ,loss[0.2310048491]\n",
      "[ Tue Dec  4 20:42:51 2018], validation: iter [1780], loss[0.2471879721]\n",
      "[ Tue Dec  4 20:42:51 2018], epoch [1800], lr[0.10000000] ,loss[0.2315207124]\n",
      "[ Tue Dec  4 20:42:51 2018], validation: iter [1800], loss[0.2480543107]\n",
      "[ Tue Dec  4 20:42:52 2018], epoch [1820], lr[0.10000000] ,loss[0.2310325354]\n",
      "[ Tue Dec  4 20:42:52 2018], validation: iter [1820], loss[0.2472765297]\n",
      "[ Tue Dec  4 20:42:53 2018], epoch [1840], lr[0.10000000] ,loss[0.2317224145]\n",
      "[ Tue Dec  4 20:42:53 2018], validation: iter [1840], loss[0.2479441017]\n",
      "[ Tue Dec  4 20:42:53 2018], epoch [1860], lr[0.10000000] ,loss[0.2319432348]\n",
      "[ Tue Dec  4 20:42:53 2018], validation: iter [1860], loss[0.2476405054]\n",
      "[ Tue Dec  4 20:42:54 2018], epoch [1880], lr[0.10000000] ,loss[0.2311335057]\n",
      "[ Tue Dec  4 20:42:54 2018], validation: iter [1880], loss[0.2475427538]\n",
      "[ Tue Dec  4 20:42:54 2018], epoch [1900], lr[0.10000000] ,loss[0.2313224673]\n",
      "[ Tue Dec  4 20:42:54 2018], validation: iter [1900], loss[0.2476356626]\n",
      "[ Tue Dec  4 20:42:55 2018], epoch [1920], lr[0.10000000] ,loss[0.2317291647]\n",
      "[ Tue Dec  4 20:42:55 2018], validation: iter [1920], loss[0.2480486333]\n",
      "[ Tue Dec  4 20:42:55 2018], epoch [1940], lr[0.10000000] ,loss[0.2309184372]\n",
      "[ Tue Dec  4 20:42:55 2018], validation: iter [1940], loss[0.2471365482]\n",
      "[ Tue Dec  4 20:42:56 2018], epoch [1960], lr[0.10000000] ,loss[0.2361943722]\n",
      "[ Tue Dec  4 20:42:56 2018], validation: iter [1960], loss[0.2545959353]\n",
      "[ Tue Dec  4 20:42:56 2018], epoch [1980], lr[0.10000000] ,loss[0.2320201695]\n",
      "[ Tue Dec  4 20:42:56 2018], validation: iter [1980], loss[0.2483698577]\n",
      "[ Tue Dec  4 20:42:57 2018], epoch [2000], lr[0.10000000] ,loss[0.2311120182]\n",
      "[ Tue Dec  4 20:42:57 2018], validation: iter [2000], loss[0.2471873015]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_2000']\n",
      "[ Tue Dec  4 20:42:58 2018], epoch [2020], lr[0.05000000] ,loss[0.2308869809]\n",
      "[ Tue Dec  4 20:42:58 2018], validation: iter [2020], loss[0.2470877767]\n",
      "[ Tue Dec  4 20:42:58 2018], epoch [2040], lr[0.05000000] ,loss[0.2308665663]\n",
      "[ Tue Dec  4 20:42:58 2018], validation: iter [2040], loss[0.2471084744]\n",
      "[ Tue Dec  4 20:42:59 2018], epoch [2060], lr[0.05000000] ,loss[0.2308437526]\n",
      "[ Tue Dec  4 20:42:59 2018], validation: iter [2060], loss[0.2470675707]\n",
      "[ Tue Dec  4 20:42:59 2018], epoch [2080], lr[0.05000000] ,loss[0.2308316529]\n",
      "[ Tue Dec  4 20:42:59 2018], validation: iter [2080], loss[0.2470662147]\n",
      "[ Tue Dec  4 20:43:00 2018], epoch [2100], lr[0.05000000] ,loss[0.2308192700]\n",
      "[ Tue Dec  4 20:43:00 2018], validation: iter [2100], loss[0.2470352501]\n",
      "[ Tue Dec  4 20:43:00 2018], epoch [2120], lr[0.05000000] ,loss[0.2308057696]\n",
      "[ Tue Dec  4 20:43:00 2018], validation: iter [2120], loss[0.2470408529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 20:43:01 2018], epoch [2140], lr[0.05000000] ,loss[0.2307899892]\n",
      "[ Tue Dec  4 20:43:01 2018], validation: iter [2140], loss[0.2470216602]\n",
      "[ Tue Dec  4 20:43:02 2018], epoch [2160], lr[0.05000000] ,loss[0.2307938486]\n",
      "[ Tue Dec  4 20:43:02 2018], validation: iter [2160], loss[0.2470064461]\n",
      "[ Tue Dec  4 20:43:02 2018], epoch [2180], lr[0.05000000] ,loss[0.2307692468]\n",
      "[ Tue Dec  4 20:43:02 2018], validation: iter [2180], loss[0.2470029294]\n",
      "[ Tue Dec  4 20:43:03 2018], epoch [2200], lr[0.05000000] ,loss[0.2307568192]\n",
      "[ Tue Dec  4 20:43:03 2018], validation: iter [2200], loss[0.2469751686]\n",
      "[ Tue Dec  4 20:43:03 2018], epoch [2220], lr[0.05000000] ,loss[0.2307647467]\n",
      "[ Tue Dec  4 20:43:03 2018], validation: iter [2220], loss[0.2469614893]\n",
      "[ Tue Dec  4 20:43:04 2018], epoch [2240], lr[0.05000000] ,loss[0.2307508737]\n",
      "[ Tue Dec  4 20:43:04 2018], validation: iter [2240], loss[0.2469799668]\n",
      "[ Tue Dec  4 20:43:04 2018], epoch [2260], lr[0.05000000] ,loss[0.2307483405]\n",
      "[ Tue Dec  4 20:43:04 2018], validation: iter [2260], loss[0.2469668686]\n",
      "[ Tue Dec  4 20:43:05 2018], epoch [2280], lr[0.05000000] ,loss[0.2307362109]\n",
      "[ Tue Dec  4 20:43:05 2018], validation: iter [2280], loss[0.2469597310]\n",
      "[ Tue Dec  4 20:43:06 2018], epoch [2300], lr[0.05000000] ,loss[0.2307302058]\n",
      "[ Tue Dec  4 20:43:06 2018], validation: iter [2300], loss[0.2469419986]\n",
      "[ Tue Dec  4 20:43:06 2018], epoch [2320], lr[0.05000000] ,loss[0.2307211459]\n",
      "[ Tue Dec  4 20:43:06 2018], validation: iter [2320], loss[0.2469278723]\n",
      "[ Tue Dec  4 20:43:07 2018], epoch [2340], lr[0.05000000] ,loss[0.2307098061]\n",
      "[ Tue Dec  4 20:43:07 2018], validation: iter [2340], loss[0.2469027787]\n",
      "[ Tue Dec  4 20:43:08 2018], epoch [2360], lr[0.05000000] ,loss[0.2307160348]\n",
      "[ Tue Dec  4 20:43:08 2018], validation: iter [2360], loss[0.2468948662]\n",
      "[ Tue Dec  4 20:43:08 2018], epoch [2380], lr[0.05000000] ,loss[0.2307049930]\n",
      "[ Tue Dec  4 20:43:08 2018], validation: iter [2380], loss[0.2468879819]\n",
      "[ Tue Dec  4 20:43:09 2018], epoch [2400], lr[0.05000000] ,loss[0.2306809425]\n",
      "[ Tue Dec  4 20:43:09 2018], validation: iter [2400], loss[0.2468826920]\n",
      "[ Tue Dec  4 20:43:10 2018], epoch [2420], lr[0.05000000] ,loss[0.2306734324]\n",
      "[ Tue Dec  4 20:43:10 2018], validation: iter [2420], loss[0.2469075322]\n",
      "[ Tue Dec  4 20:43:10 2018], epoch [2440], lr[0.05000000] ,loss[0.2306776047]\n",
      "[ Tue Dec  4 20:43:10 2018], validation: iter [2440], loss[0.2468771338]\n",
      "[ Tue Dec  4 20:43:11 2018], epoch [2460], lr[0.05000000] ,loss[0.2306650281]\n",
      "[ Tue Dec  4 20:43:11 2018], validation: iter [2460], loss[0.2468656600]\n",
      "[ Tue Dec  4 20:43:12 2018], epoch [2480], lr[0.05000000] ,loss[0.2306757569]\n",
      "[ Tue Dec  4 20:43:12 2018], validation: iter [2480], loss[0.2468532026]\n",
      "[ Tue Dec  4 20:43:13 2018], epoch [2500], lr[0.05000000] ,loss[0.2306738943]\n",
      "[ Tue Dec  4 20:43:13 2018], validation: iter [2500], loss[0.2468236089]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_2500']\n",
      "[ Tue Dec  4 20:43:13 2018], epoch [2520], lr[0.05000000] ,loss[0.2306381613]\n",
      "[ Tue Dec  4 20:43:13 2018], validation: iter [2520], loss[0.2468381226]\n",
      "[ Tue Dec  4 20:43:14 2018], epoch [2540], lr[0.05000000] ,loss[0.2306737006]\n",
      "[ Tue Dec  4 20:43:14 2018], validation: iter [2540], loss[0.2468270361]\n",
      "[ Tue Dec  4 20:43:14 2018], epoch [2560], lr[0.05000000] ,loss[0.2306300700]\n",
      "[ Tue Dec  4 20:43:14 2018], validation: iter [2560], loss[0.2468039691]\n",
      "[ Tue Dec  4 20:43:15 2018], epoch [2580], lr[0.05000000] ,loss[0.2306265682]\n",
      "[ Tue Dec  4 20:43:15 2018], validation: iter [2580], loss[0.2468232810]\n",
      "[ Tue Dec  4 20:43:16 2018], epoch [2600], lr[0.05000000] ,loss[0.2305996567]\n",
      "[ Tue Dec  4 20:43:16 2018], validation: iter [2600], loss[0.2467850745]\n",
      "[ Tue Dec  4 20:43:16 2018], epoch [2620], lr[0.05000000] ,loss[0.2306203097]\n",
      "[ Tue Dec  4 20:43:16 2018], validation: iter [2620], loss[0.2467704713]\n",
      "[ Tue Dec  4 20:43:17 2018], epoch [2640], lr[0.05000000] ,loss[0.2306022495]\n",
      "[ Tue Dec  4 20:43:17 2018], validation: iter [2640], loss[0.2468022704]\n",
      "[ Tue Dec  4 20:43:17 2018], epoch [2660], lr[0.05000000] ,loss[0.2305918932]\n",
      "[ Tue Dec  4 20:43:17 2018], validation: iter [2660], loss[0.2467642576]\n",
      "[ Tue Dec  4 20:43:18 2018], epoch [2680], lr[0.05000000] ,loss[0.2305938601]\n",
      "[ Tue Dec  4 20:43:18 2018], validation: iter [2680], loss[0.2467516810]\n",
      "[ Tue Dec  4 20:43:19 2018], epoch [2700], lr[0.05000000] ,loss[0.2306071222]\n",
      "[ Tue Dec  4 20:43:19 2018], validation: iter [2700], loss[0.2467468381]\n",
      "[ Tue Dec  4 20:43:20 2018], epoch [2720], lr[0.05000000] ,loss[0.2305995077]\n",
      "[ Tue Dec  4 20:43:20 2018], validation: iter [2720], loss[0.2467660606]\n",
      "[ Tue Dec  4 20:43:20 2018], epoch [2740], lr[0.05000000] ,loss[0.2305845767]\n",
      "[ Tue Dec  4 20:43:20 2018], validation: iter [2740], loss[0.2467287481]\n",
      "[ Tue Dec  4 20:43:21 2018], epoch [2760], lr[0.05000000] ,loss[0.2305853814]\n",
      "[ Tue Dec  4 20:43:21 2018], validation: iter [2760], loss[0.2467063218]\n",
      "[ Tue Dec  4 20:43:21 2018], epoch [2780], lr[0.05000000] ,loss[0.2305638194]\n",
      "[ Tue Dec  4 20:43:21 2018], validation: iter [2780], loss[0.2467037439]\n",
      "[ Tue Dec  4 20:43:22 2018], epoch [2800], lr[0.05000000] ,loss[0.2305659950]\n",
      "[ Tue Dec  4 20:43:22 2018], validation: iter [2800], loss[0.2467168421]\n",
      "[ Tue Dec  4 20:43:23 2018], epoch [2820], lr[0.05000000] ,loss[0.2305504829]\n",
      "[ Tue Dec  4 20:43:23 2018], validation: iter [2820], loss[0.2467063069]\n",
      "[ Tue Dec  4 20:43:23 2018], epoch [2840], lr[0.05000000] ,loss[0.2305476665]\n",
      "[ Tue Dec  4 20:43:23 2018], validation: iter [2840], loss[0.2466986924]\n",
      "[ Tue Dec  4 20:43:24 2018], epoch [2860], lr[0.05000000] ,loss[0.2305394113]\n",
      "[ Tue Dec  4 20:43:24 2018], validation: iter [2860], loss[0.2466865480]\n",
      "[ Tue Dec  4 20:43:25 2018], epoch [2880], lr[0.05000000] ,loss[0.2305313200]\n",
      "[ Tue Dec  4 20:43:25 2018], validation: iter [2880], loss[0.2466609776]\n",
      "[ Tue Dec  4 20:43:25 2018], epoch [2900], lr[0.05000000] ,loss[0.2305263877]\n",
      "[ Tue Dec  4 20:43:25 2018], validation: iter [2900], loss[0.2466378957]\n",
      "[ Tue Dec  4 20:43:26 2018], epoch [2920], lr[0.05000000] ,loss[0.2305496484]\n",
      "[ Tue Dec  4 20:43:26 2018], validation: iter [2920], loss[0.2466514409]\n",
      "[ Tue Dec  4 20:43:27 2018], epoch [2940], lr[0.05000000] ,loss[0.2305405587]\n",
      "[ Tue Dec  4 20:43:27 2018], validation: iter [2940], loss[0.2466427088]\n",
      "[ Tue Dec  4 20:43:27 2018], epoch [2960], lr[0.05000000] ,loss[0.2305384427]\n",
      "[ Tue Dec  4 20:43:27 2018], validation: iter [2960], loss[0.2466128170]\n",
      "[ Tue Dec  4 20:43:28 2018], epoch [2980], lr[0.05000000] ,loss[0.2305186838]\n",
      "[ Tue Dec  4 20:43:28 2018], validation: iter [2980], loss[0.2466199994]\n",
      "[ Tue Dec  4 20:43:28 2018], epoch [3000], lr[0.05000000] ,loss[0.2304966152]\n",
      "[ Tue Dec  4 20:43:28 2018], validation: iter [3000], loss[0.2466423512]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_3000']\n",
      "[ Tue Dec  4 20:43:29 2018], epoch [3020], lr[0.05000000] ,loss[0.2305071205]\n",
      "[ Tue Dec  4 20:43:29 2018], validation: iter [3020], loss[0.2466379851]\n",
      "[ Tue Dec  4 20:43:30 2018], epoch [3040], lr[0.05000000] ,loss[0.2305085361]\n",
      "[ Tue Dec  4 20:43:30 2018], validation: iter [3040], loss[0.2466323078]\n",
      "[ Tue Dec  4 20:43:30 2018], epoch [3060], lr[0.05000000] ,loss[0.2304933518]\n",
      "[ Tue Dec  4 20:43:30 2018], validation: iter [3060], loss[0.2466939390]\n",
      "[ Tue Dec  4 20:43:31 2018], epoch [3080], lr[0.05000000] ,loss[0.2305084765]\n",
      "[ Tue Dec  4 20:43:31 2018], validation: iter [3080], loss[0.2466090620]\n",
      "[ Tue Dec  4 20:43:31 2018], epoch [3100], lr[0.05000000] ,loss[0.2305742055]\n",
      "[ Tue Dec  4 20:43:31 2018], validation: iter [3100], loss[0.2466146946]\n",
      "[ Tue Dec  4 20:43:32 2018], epoch [3120], lr[0.05000000] ,loss[0.2305195779]\n",
      "[ Tue Dec  4 20:43:32 2018], validation: iter [3120], loss[0.2466859370]\n",
      "[ Tue Dec  4 20:43:32 2018], epoch [3140], lr[0.05000000] ,loss[0.2306535691]\n",
      "[ Tue Dec  4 20:43:32 2018], validation: iter [3140], loss[0.2467819601]\n",
      "[ Tue Dec  4 20:43:33 2018], epoch [3160], lr[0.05000000] ,loss[0.2305488735]\n",
      "[ Tue Dec  4 20:43:33 2018], validation: iter [3160], loss[0.2467112094]\n",
      "[ Tue Dec  4 20:43:34 2018], epoch [3180], lr[0.05000000] ,loss[0.2307246923]\n",
      "[ Tue Dec  4 20:43:34 2018], validation: iter [3180], loss[0.2469159365]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 20:43:34 2018], epoch [3200], lr[0.05000000] ,loss[0.2310281098]\n",
      "[ Tue Dec  4 20:43:34 2018], validation: iter [3200], loss[0.2470323890]\n",
      "[ Tue Dec  4 20:43:35 2018], epoch [3220], lr[0.05000000] ,loss[0.2305053473]\n",
      "[ Tue Dec  4 20:43:35 2018], validation: iter [3220], loss[0.2465889454]\n",
      "[ Tue Dec  4 20:43:35 2018], epoch [3240], lr[0.05000000] ,loss[0.2305561751]\n",
      "[ Tue Dec  4 20:43:35 2018], validation: iter [3240], loss[0.2467885911]\n",
      "[ Tue Dec  4 20:43:36 2018], epoch [3260], lr[0.05000000] ,loss[0.2308375388]\n",
      "[ Tue Dec  4 20:43:36 2018], validation: iter [3260], loss[0.2470826507]\n",
      "[ Tue Dec  4 20:43:37 2018], epoch [3280], lr[0.05000000] ,loss[0.2305803448]\n",
      "[ Tue Dec  4 20:43:37 2018], validation: iter [3280], loss[0.2465852499]\n",
      "[ Tue Dec  4 20:43:37 2018], epoch [3300], lr[0.05000000] ,loss[0.2310499549]\n",
      "[ Tue Dec  4 20:43:37 2018], validation: iter [3300], loss[0.2469413280]\n",
      "[ Tue Dec  4 20:43:38 2018], epoch [3320], lr[0.05000000] ,loss[0.2306978852]\n",
      "[ Tue Dec  4 20:43:38 2018], validation: iter [3320], loss[0.2468639463]\n",
      "[ Tue Dec  4 20:43:38 2018], epoch [3340], lr[0.05000000] ,loss[0.2305278182]\n",
      "[ Tue Dec  4 20:43:38 2018], validation: iter [3340], loss[0.2466008216]\n",
      "[ Tue Dec  4 20:43:39 2018], epoch [3360], lr[0.05000000] ,loss[0.2307322770]\n",
      "[ Tue Dec  4 20:43:39 2018], validation: iter [3360], loss[0.2469021082]\n",
      "[ Tue Dec  4 20:43:39 2018], epoch [3380], lr[0.05000000] ,loss[0.2306126505]\n",
      "[ Tue Dec  4 20:43:39 2018], validation: iter [3380], loss[0.2466920167]\n",
      "[ Tue Dec  4 20:43:40 2018], epoch [3400], lr[0.05000000] ,loss[0.2305536419]\n",
      "[ Tue Dec  4 20:43:40 2018], validation: iter [3400], loss[0.2466071844]\n",
      "[ Tue Dec  4 20:43:40 2018], epoch [3420], lr[0.05000000] ,loss[0.2307266295]\n",
      "[ Tue Dec  4 20:43:40 2018], validation: iter [3420], loss[0.2469184250]\n",
      "[ Tue Dec  4 20:43:41 2018], epoch [3440], lr[0.05000000] ,loss[0.2311205566]\n",
      "[ Tue Dec  4 20:43:41 2018], validation: iter [3440], loss[0.2471826226]\n",
      "[ Tue Dec  4 20:43:41 2018], epoch [3460], lr[0.05000000] ,loss[0.2306856662]\n",
      "[ Tue Dec  4 20:43:41 2018], validation: iter [3460], loss[0.2468303144]\n",
      "[ Tue Dec  4 20:43:42 2018], epoch [3480], lr[0.05000000] ,loss[0.2306540608]\n",
      "[ Tue Dec  4 20:43:42 2018], validation: iter [3480], loss[0.2468039691]\n",
      "[ Tue Dec  4 20:43:42 2018], epoch [3500], lr[0.05000000] ,loss[0.2305267304]\n",
      "[ Tue Dec  4 20:43:42 2018], validation: iter [3500], loss[0.2466255873]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_3500']\n",
      "[ Tue Dec  4 20:43:43 2018], epoch [3520], lr[0.05000000] ,loss[0.2305351794]\n",
      "[ Tue Dec  4 20:43:43 2018], validation: iter [3520], loss[0.2465293109]\n",
      "[ Tue Dec  4 20:43:43 2018], epoch [3540], lr[0.05000000] ,loss[0.2309995145]\n",
      "[ Tue Dec  4 20:43:43 2018], validation: iter [3540], loss[0.2468794882]\n",
      "[ Tue Dec  4 20:43:44 2018], epoch [3560], lr[0.05000000] ,loss[0.2305044681]\n",
      "[ Tue Dec  4 20:43:44 2018], validation: iter [3560], loss[0.2466818392]\n",
      "[ Tue Dec  4 20:43:44 2018], epoch [3580], lr[0.05000000] ,loss[0.2313807160]\n",
      "[ Tue Dec  4 20:43:44 2018], validation: iter [3580], loss[0.2474136651]\n",
      "[ Tue Dec  4 20:43:45 2018], epoch [3600], lr[0.05000000] ,loss[0.2306455523]\n",
      "[ Tue Dec  4 20:43:45 2018], validation: iter [3600], loss[0.2465974987]\n",
      "[ Tue Dec  4 20:43:45 2018], epoch [3620], lr[0.05000000] ,loss[0.2305558622]\n",
      "[ Tue Dec  4 20:43:45 2018], validation: iter [3620], loss[0.2465545386]\n",
      "[ Tue Dec  4 20:43:46 2018], epoch [3640], lr[0.05000000] ,loss[0.2310282290]\n",
      "[ Tue Dec  4 20:43:46 2018], validation: iter [3640], loss[0.2473127544]\n",
      "[ Tue Dec  4 20:43:46 2018], epoch [3660], lr[0.05000000] ,loss[0.2307369858]\n",
      "[ Tue Dec  4 20:43:46 2018], validation: iter [3660], loss[0.2467448860]\n",
      "[ Tue Dec  4 20:43:47 2018], epoch [3680], lr[0.05000000] ,loss[0.2308390290]\n",
      "[ Tue Dec  4 20:43:47 2018], validation: iter [3680], loss[0.2467554063]\n",
      "[ Tue Dec  4 20:43:47 2018], epoch [3700], lr[0.05000000] ,loss[0.2307400107]\n",
      "[ Tue Dec  4 20:43:47 2018], validation: iter [3700], loss[0.2467200756]\n",
      "[ Tue Dec  4 20:43:48 2018], epoch [3720], lr[0.05000000] ,loss[0.2306502461]\n",
      "[ Tue Dec  4 20:43:48 2018], validation: iter [3720], loss[0.2466618419]\n",
      "[ Tue Dec  4 20:43:48 2018], epoch [3740], lr[0.05000000] ,loss[0.2305146754]\n",
      "[ Tue Dec  4 20:43:48 2018], validation: iter [3740], loss[0.2467254251]\n",
      "[ Tue Dec  4 20:43:49 2018], epoch [3760], lr[0.05000000] ,loss[0.2304964960]\n",
      "[ Tue Dec  4 20:43:49 2018], validation: iter [3760], loss[0.2465495914]\n",
      "[ Tue Dec  4 20:43:49 2018], epoch [3780], lr[0.05000000] ,loss[0.2304387838]\n",
      "[ Tue Dec  4 20:43:49 2018], validation: iter [3780], loss[0.2464606017]\n",
      "[ Tue Dec  4 20:43:50 2018], epoch [3800], lr[0.05000000] ,loss[0.2305417955]\n",
      "[ Tue Dec  4 20:43:50 2018], validation: iter [3800], loss[0.2465102673]\n",
      "[ Tue Dec  4 20:43:50 2018], epoch [3820], lr[0.05000000] ,loss[0.2312526852]\n",
      "[ Tue Dec  4 20:43:50 2018], validation: iter [3820], loss[0.2468456626]\n",
      "[ Tue Dec  4 20:43:51 2018], epoch [3840], lr[0.05000000] ,loss[0.2305185795]\n",
      "[ Tue Dec  4 20:43:51 2018], validation: iter [3840], loss[0.2465395629]\n",
      "[ Tue Dec  4 20:43:51 2018], epoch [3860], lr[0.05000000] ,loss[0.2304910868]\n",
      "[ Tue Dec  4 20:43:51 2018], validation: iter [3860], loss[0.2465445101]\n",
      "[ Tue Dec  4 20:43:52 2018], epoch [3880], lr[0.05000000] ,loss[0.2305418402]\n",
      "[ Tue Dec  4 20:43:52 2018], validation: iter [3880], loss[0.2465429753]\n",
      "[ Tue Dec  4 20:43:52 2018], epoch [3900], lr[0.05000000] ,loss[0.2308196872]\n",
      "[ Tue Dec  4 20:43:52 2018], validation: iter [3900], loss[0.2467073649]\n",
      "[ Tue Dec  4 20:43:53 2018], epoch [3920], lr[0.05000000] ,loss[0.2306063175]\n",
      "[ Tue Dec  4 20:43:53 2018], validation: iter [3920], loss[0.2467582822]\n",
      "[ Tue Dec  4 20:43:53 2018], epoch [3940], lr[0.05000000] ,loss[0.2305898070]\n",
      "[ Tue Dec  4 20:43:53 2018], validation: iter [3940], loss[0.2465710789]\n",
      "[ Tue Dec  4 20:43:54 2018], epoch [3960], lr[0.05000000] ,loss[0.2305030376]\n",
      "[ Tue Dec  4 20:43:54 2018], validation: iter [3960], loss[0.2467126101]\n",
      "[ Tue Dec  4 20:43:54 2018], epoch [3980], lr[0.05000000] ,loss[0.2304388136]\n",
      "[ Tue Dec  4 20:43:54 2018], validation: iter [3980], loss[0.2464720756]\n",
      "[ Tue Dec  4 20:43:55 2018], epoch [4000], lr[0.05000000] ,loss[0.2314499617]\n",
      "[ Tue Dec  4 20:43:55 2018], validation: iter [4000], loss[0.2469462305]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_4000']\n",
      "[ Tue Dec  4 20:43:55 2018], epoch [4020], lr[0.02500000] ,loss[0.2304569632]\n",
      "[ Tue Dec  4 20:43:55 2018], validation: iter [4020], loss[0.2465256900]\n",
      "[ Tue Dec  4 20:43:56 2018], epoch [4040], lr[0.02500000] ,loss[0.2304598093]\n",
      "[ Tue Dec  4 20:43:56 2018], validation: iter [4040], loss[0.2465198487]\n",
      "[ Tue Dec  4 20:43:56 2018], epoch [4060], lr[0.02500000] ,loss[0.2304345816]\n",
      "[ Tue Dec  4 20:43:56 2018], validation: iter [4060], loss[0.2464868724]\n",
      "[ Tue Dec  4 20:43:57 2018], epoch [4080], lr[0.02500000] ,loss[0.2304333150]\n",
      "[ Tue Dec  4 20:43:57 2018], validation: iter [4080], loss[0.2464935184]\n",
      "[ Tue Dec  4 20:43:57 2018], epoch [4100], lr[0.02500000] ,loss[0.2304302901]\n",
      "[ Tue Dec  4 20:43:57 2018], validation: iter [4100], loss[0.2464964390]\n",
      "[ Tue Dec  4 20:43:58 2018], epoch [4120], lr[0.02500000] ,loss[0.2304167300]\n",
      "[ Tue Dec  4 20:43:58 2018], validation: iter [4120], loss[0.2464871109]\n",
      "[ Tue Dec  4 20:43:58 2018], epoch [4140], lr[0.02500000] ,loss[0.2304192334]\n",
      "[ Tue Dec  4 20:43:58 2018], validation: iter [4140], loss[0.2464868426]\n",
      "[ Tue Dec  4 20:43:59 2018], epoch [4160], lr[0.02500000] ,loss[0.2304260731]\n",
      "[ Tue Dec  4 20:43:59 2018], validation: iter [4160], loss[0.2464837432]\n",
      "[ Tue Dec  4 20:43:59 2018], epoch [4180], lr[0.02500000] ,loss[0.2304291874]\n",
      "[ Tue Dec  4 20:43:59 2018], validation: iter [4180], loss[0.2464789450]\n",
      "[ Tue Dec  4 20:44:00 2018], epoch [4200], lr[0.02500000] ,loss[0.2304280698]\n",
      "[ Tue Dec  4 20:44:00 2018], validation: iter [4200], loss[0.2464814484]\n",
      "[ Tue Dec  4 20:44:00 2018], epoch [4220], lr[0.02500000] ,loss[0.2304122597]\n",
      "[ Tue Dec  4 20:44:00 2018], validation: iter [4220], loss[0.2464816868]\n",
      "[ Tue Dec  4 20:44:01 2018], epoch [4240], lr[0.02500000] ,loss[0.2303979546]\n",
      "[ Tue Dec  4 20:44:01 2018], validation: iter [4240], loss[0.2464748472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 20:44:01 2018], epoch [4260], lr[0.02500000] ,loss[0.2303964794]\n",
      "[ Tue Dec  4 20:44:01 2018], validation: iter [4260], loss[0.2464756519]\n",
      "[ Tue Dec  4 20:44:01 2018], epoch [4280], lr[0.02500000] ,loss[0.2303977013]\n",
      "[ Tue Dec  4 20:44:01 2018], validation: iter [4280], loss[0.2464720756]\n",
      "[ Tue Dec  4 20:44:02 2018], epoch [4300], lr[0.02500000] ,loss[0.2303940952]\n",
      "[ Tue Dec  4 20:44:02 2018], validation: iter [4300], loss[0.2464603931]\n",
      "[ Tue Dec  4 20:44:02 2018], epoch [4320], lr[0.02500000] ,loss[0.2303955704]\n",
      "[ Tue Dec  4 20:44:02 2018], validation: iter [4320], loss[0.2464621663]\n",
      "[ Tue Dec  4 20:44:03 2018], epoch [4340], lr[0.02500000] ,loss[0.2303958684]\n",
      "[ Tue Dec  4 20:44:03 2018], validation: iter [4340], loss[0.2464536875]\n",
      "[ Tue Dec  4 20:44:04 2018], epoch [4360], lr[0.02500000] ,loss[0.2304186523]\n",
      "[ Tue Dec  4 20:44:04 2018], validation: iter [4360], loss[0.2464622259]\n",
      "[ Tue Dec  4 20:44:04 2018], epoch [4380], lr[0.02500000] ,loss[0.2304083109]\n",
      "[ Tue Dec  4 20:44:04 2018], validation: iter [4380], loss[0.2464632690]\n",
      "[ Tue Dec  4 20:44:05 2018], epoch [4400], lr[0.02500000] ,loss[0.2303935438]\n",
      "[ Tue Dec  4 20:44:05 2018], validation: iter [4400], loss[0.2464583665]\n",
      "[ Tue Dec  4 20:44:05 2018], epoch [4420], lr[0.02500000] ,loss[0.2303972393]\n",
      "[ Tue Dec  4 20:44:05 2018], validation: iter [4420], loss[0.2464540452]\n",
      "[ Tue Dec  4 20:44:06 2018], epoch [4440], lr[0.02500000] ,loss[0.2303787917]\n",
      "[ Tue Dec  4 20:44:06 2018], validation: iter [4440], loss[0.2464585155]\n",
      "[ Tue Dec  4 20:44:06 2018], epoch [4460], lr[0.02500000] ,loss[0.2303954512]\n",
      "[ Tue Dec  4 20:44:06 2018], validation: iter [4460], loss[0.2464592606]\n",
      "[ Tue Dec  4 20:44:07 2018], epoch [4480], lr[0.02500000] ,loss[0.2303839922]\n",
      "[ Tue Dec  4 20:44:07 2018], validation: iter [4480], loss[0.2464503497]\n",
      "[ Tue Dec  4 20:44:07 2018], epoch [4500], lr[0.02500000] ,loss[0.2304072976]\n",
      "[ Tue Dec  4 20:44:07 2018], validation: iter [4500], loss[0.2464571893]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_4500']\n",
      "[ Tue Dec  4 20:44:08 2018], epoch [4520], lr[0.02500000] ,loss[0.2304126322]\n",
      "[ Tue Dec  4 20:44:08 2018], validation: iter [4520], loss[0.2464544773]\n",
      "[ Tue Dec  4 20:44:09 2018], epoch [4540], lr[0.02500000] ,loss[0.2303914279]\n",
      "[ Tue Dec  4 20:44:09 2018], validation: iter [4540], loss[0.2464427799]\n",
      "[ Tue Dec  4 20:44:09 2018], epoch [4560], lr[0.02500000] ,loss[0.2303991020]\n",
      "[ Tue Dec  4 20:44:09 2018], validation: iter [4560], loss[0.2464588434]\n",
      "[ Tue Dec  4 20:44:10 2018], epoch [4580], lr[0.02500000] ,loss[0.2303854376]\n",
      "[ Tue Dec  4 20:44:10 2018], validation: iter [4580], loss[0.2464306653]\n",
      "[ Tue Dec  4 20:44:10 2018], epoch [4600], lr[0.02500000] ,loss[0.2303849310]\n",
      "[ Tue Dec  4 20:44:10 2018], validation: iter [4600], loss[0.2464502007]\n",
      "[ Tue Dec  4 20:44:11 2018], epoch [4620], lr[0.02500000] ,loss[0.2303909361]\n",
      "[ Tue Dec  4 20:44:11 2018], validation: iter [4620], loss[0.2464598268]\n",
      "[ Tue Dec  4 20:44:11 2018], epoch [4640], lr[0.02500000] ,loss[0.2303877473]\n",
      "[ Tue Dec  4 20:44:11 2018], validation: iter [4640], loss[0.2464278489]\n",
      "[ Tue Dec  4 20:44:12 2018], epoch [4660], lr[0.02500000] ,loss[0.2303934693]\n",
      "[ Tue Dec  4 20:44:12 2018], validation: iter [4660], loss[0.2464655638]\n",
      "[ Tue Dec  4 20:44:12 2018], epoch [4680], lr[0.02500000] ,loss[0.2303819507]\n",
      "[ Tue Dec  4 20:44:12 2018], validation: iter [4680], loss[0.2464564890]\n",
      "[ Tue Dec  4 20:44:13 2018], epoch [4700], lr[0.02500000] ,loss[0.2303774059]\n",
      "[ Tue Dec  4 20:44:13 2018], validation: iter [4700], loss[0.2464278191]\n",
      "[ Tue Dec  4 20:44:13 2018], epoch [4720], lr[0.02500000] ,loss[0.2303980440]\n",
      "[ Tue Dec  4 20:44:13 2018], validation: iter [4720], loss[0.2464591563]\n",
      "[ Tue Dec  4 20:44:14 2018], epoch [4740], lr[0.02500000] ,loss[0.2303886861]\n",
      "[ Tue Dec  4 20:44:14 2018], validation: iter [4740], loss[0.2464451790]\n",
      "[ Tue Dec  4 20:44:14 2018], epoch [4760], lr[0.02500000] ,loss[0.2303909659]\n",
      "[ Tue Dec  4 20:44:14 2018], validation: iter [4760], loss[0.2464434952]\n",
      "[ Tue Dec  4 20:44:15 2018], epoch [4780], lr[0.02500000] ,loss[0.2303927243]\n",
      "[ Tue Dec  4 20:44:15 2018], validation: iter [4780], loss[0.2464430034]\n",
      "[ Tue Dec  4 20:44:15 2018], epoch [4800], lr[0.02500000] ,loss[0.2303915918]\n",
      "[ Tue Dec  4 20:44:15 2018], validation: iter [4800], loss[0.2464415282]\n",
      "[ Tue Dec  4 20:44:16 2018], epoch [4820], lr[0.02500000] ,loss[0.2303927094]\n",
      "[ Tue Dec  4 20:44:16 2018], validation: iter [4820], loss[0.2464415878]\n",
      "[ Tue Dec  4 20:44:16 2018], epoch [4840], lr[0.02500000] ,loss[0.2303929925]\n",
      "[ Tue Dec  4 20:44:16 2018], validation: iter [4840], loss[0.2464402020]\n",
      "[ Tue Dec  4 20:44:17 2018], epoch [4860], lr[0.02500000] ,loss[0.2303937227]\n",
      "[ Tue Dec  4 20:44:17 2018], validation: iter [4860], loss[0.2464380413]\n",
      "[ Tue Dec  4 20:44:17 2018], epoch [4880], lr[0.02500000] ,loss[0.2303900570]\n",
      "[ Tue Dec  4 20:44:17 2018], validation: iter [4880], loss[0.2464373112]\n",
      "[ Tue Dec  4 20:44:18 2018], epoch [4900], lr[0.02500000] ,loss[0.2303888500]\n",
      "[ Tue Dec  4 20:44:18 2018], validation: iter [4900], loss[0.2464365959]\n",
      "[ Tue Dec  4 20:44:18 2018], epoch [4920], lr[0.02500000] ,loss[0.2303871214]\n",
      "[ Tue Dec  4 20:44:18 2018], validation: iter [4920], loss[0.2464362681]\n",
      "[ Tue Dec  4 20:44:19 2018], epoch [4940], lr[0.02500000] ,loss[0.2303897440]\n",
      "[ Tue Dec  4 20:44:19 2018], validation: iter [4940], loss[0.2464347482]\n",
      "[ Tue Dec  4 20:44:19 2018], epoch [4960], lr[0.02500000] ,loss[0.2303859740]\n",
      "[ Tue Dec  4 20:44:19 2018], validation: iter [4960], loss[0.2464341372]\n",
      "[ Tue Dec  4 20:44:20 2018], epoch [4980], lr[0.02500000] ,loss[0.2303908020]\n",
      "[ Tue Dec  4 20:44:20 2018], validation: iter [4980], loss[0.2464350015]\n",
      "[ Tue Dec  4 20:44:20 2018], epoch [5000], lr[0.02500000] ,loss[0.2303929031]\n",
      "[ Tue Dec  4 20:44:20 2018], validation: iter [5000], loss[0.2464334816]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_5000']\n",
      "[ Tue Dec  4 20:44:21 2018], epoch [5020], lr[0.02500000] ,loss[0.2303945422]\n",
      "[ Tue Dec  4 20:44:21 2018], validation: iter [5020], loss[0.2464326322]\n",
      "[ Tue Dec  4 20:44:21 2018], epoch [5040], lr[0.02500000] ,loss[0.2303899378]\n",
      "[ Tue Dec  4 20:44:21 2018], validation: iter [5040], loss[0.2464323193]\n",
      "[ Tue Dec  4 20:44:22 2018], epoch [5060], lr[0.02500000] ,loss[0.2303897887]\n",
      "[ Tue Dec  4 20:44:22 2018], validation: iter [5060], loss[0.2464308590]\n",
      "[ Tue Dec  4 20:44:22 2018], epoch [5080], lr[0.02500000] ,loss[0.2303941250]\n",
      "[ Tue Dec  4 20:44:22 2018], validation: iter [5080], loss[0.2464297265]\n",
      "[ Tue Dec  4 20:44:23 2018], epoch [5100], lr[0.02500000] ,loss[0.2303942591]\n",
      "[ Tue Dec  4 20:44:23 2018], validation: iter [5100], loss[0.2464299649]\n",
      "[ Tue Dec  4 20:44:23 2018], epoch [5120], lr[0.02500000] ,loss[0.2303921729]\n",
      "[ Tue Dec  4 20:44:23 2018], validation: iter [5120], loss[0.2464296222]\n",
      "[ Tue Dec  4 20:44:24 2018], epoch [5140], lr[0.02500000] ,loss[0.2304061502]\n",
      "[ Tue Dec  4 20:44:24 2018], validation: iter [5140], loss[0.2464246154]\n",
      "[ Tue Dec  4 20:44:24 2018], epoch [5160], lr[0.02500000] ,loss[0.2304167300]\n",
      "[ Tue Dec  4 20:44:24 2018], validation: iter [5160], loss[0.2464004159]\n",
      "[ Tue Dec  4 20:44:25 2018], epoch [5180], lr[0.02500000] ,loss[0.2303684354]\n",
      "[ Tue Dec  4 20:44:25 2018], validation: iter [5180], loss[0.2464693040]\n",
      "[ Tue Dec  4 20:44:25 2018], epoch [5200], lr[0.02500000] ,loss[0.2303561866]\n",
      "[ Tue Dec  4 20:44:25 2018], validation: iter [5200], loss[0.2463982850]\n",
      "[ Tue Dec  4 20:44:26 2018], epoch [5220], lr[0.02500000] ,loss[0.2304158956]\n",
      "[ Tue Dec  4 20:44:26 2018], validation: iter [5220], loss[0.2463916391]\n",
      "[ Tue Dec  4 20:44:26 2018], epoch [5240], lr[0.02500000] ,loss[0.2303586453]\n",
      "[ Tue Dec  4 20:44:26 2018], validation: iter [5240], loss[0.2464661747]\n",
      "[ Tue Dec  4 20:44:27 2018], epoch [5260], lr[0.02500000] ,loss[0.2303594798]\n",
      "[ Tue Dec  4 20:44:27 2018], validation: iter [5260], loss[0.2463948876]\n",
      "[ Tue Dec  4 20:44:27 2018], epoch [5280], lr[0.02500000] ,loss[0.2304158956]\n",
      "[ Tue Dec  4 20:44:27 2018], validation: iter [5280], loss[0.2463869601]\n",
      "[ Tue Dec  4 20:44:28 2018], epoch [5300], lr[0.02500000] ,loss[0.2303590178]\n",
      "[ Tue Dec  4 20:44:28 2018], validation: iter [5300], loss[0.2464643419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 20:44:28 2018], epoch [5320], lr[0.02500000] ,loss[0.2303622961]\n",
      "[ Tue Dec  4 20:44:28 2018], validation: iter [5320], loss[0.2463919520]\n",
      "[ Tue Dec  4 20:44:29 2018], epoch [5340], lr[0.02500000] ,loss[0.2304157764]\n",
      "[ Tue Dec  4 20:44:29 2018], validation: iter [5340], loss[0.2463845313]\n",
      "[ Tue Dec  4 20:44:29 2018], epoch [5360], lr[0.02500000] ,loss[0.2303570211]\n",
      "[ Tue Dec  4 20:44:29 2018], validation: iter [5360], loss[0.2464641035]\n",
      "[ Tue Dec  4 20:44:30 2018], epoch [5380], lr[0.02500000] ,loss[0.2303632647]\n",
      "[ Tue Dec  4 20:44:30 2018], validation: iter [5380], loss[0.2463966459]\n",
      "[ Tue Dec  4 20:44:30 2018], epoch [5400], lr[0.02500000] ,loss[0.2304638177]\n",
      "[ Tue Dec  4 20:44:30 2018], validation: iter [5400], loss[0.2464337945]\n",
      "[ Tue Dec  4 20:44:31 2018], epoch [5420], lr[0.02500000] ,loss[0.2308681607]\n",
      "[ Tue Dec  4 20:44:31 2018], validation: iter [5420], loss[0.2470235527]\n",
      "[ Tue Dec  4 20:44:31 2018], epoch [5440], lr[0.02500000] ,loss[0.2304275036]\n",
      "[ Tue Dec  4 20:44:31 2018], validation: iter [5440], loss[0.2464977354]\n",
      "[ Tue Dec  4 20:44:32 2018], epoch [5460], lr[0.02500000] ,loss[0.2304130346]\n",
      "[ Tue Dec  4 20:44:32 2018], validation: iter [5460], loss[0.2464450449]\n",
      "[ Tue Dec  4 20:44:32 2018], epoch [5480], lr[0.02500000] ,loss[0.2304273546]\n",
      "[ Tue Dec  4 20:44:32 2018], validation: iter [5480], loss[0.2463555932]\n",
      "[ Tue Dec  4 20:44:33 2018], epoch [5500], lr[0.02500000] ,loss[0.2303722501]\n",
      "[ Tue Dec  4 20:44:33 2018], validation: iter [5500], loss[0.2463754117]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_5500']\n",
      "[ Tue Dec  4 20:44:33 2018], epoch [5520], lr[0.02500000] ,loss[0.2303650677]\n",
      "[ Tue Dec  4 20:44:33 2018], validation: iter [5520], loss[0.2464089692]\n",
      "[ Tue Dec  4 20:44:34 2018], epoch [5540], lr[0.02500000] ,loss[0.2303658128]\n",
      "[ Tue Dec  4 20:44:34 2018], validation: iter [5540], loss[0.2463874668]\n",
      "[ Tue Dec  4 20:44:34 2018], epoch [5560], lr[0.02500000] ,loss[0.2303617746]\n",
      "[ Tue Dec  4 20:44:34 2018], validation: iter [5560], loss[0.2464073598]\n",
      "[ Tue Dec  4 20:44:35 2018], epoch [5580], lr[0.02500000] ,loss[0.2303558439]\n",
      "[ Tue Dec  4 20:44:35 2018], validation: iter [5580], loss[0.2464123219]\n",
      "[ Tue Dec  4 20:44:35 2018], epoch [5600], lr[0.02500000] ,loss[0.2303667367]\n",
      "[ Tue Dec  4 20:44:35 2018], validation: iter [5600], loss[0.2464380860]\n",
      "[ Tue Dec  4 20:44:36 2018], epoch [5620], lr[0.02500000] ,loss[0.2303767651]\n",
      "[ Tue Dec  4 20:44:36 2018], validation: iter [5620], loss[0.2463846803]\n",
      "[ Tue Dec  4 20:44:36 2018], epoch [5640], lr[0.02500000] ,loss[0.2303718626]\n",
      "[ Tue Dec  4 20:44:36 2018], validation: iter [5640], loss[0.2463772446]\n",
      "[ Tue Dec  4 20:44:37 2018], epoch [5660], lr[0.02500000] ,loss[0.2304536849]\n",
      "[ Tue Dec  4 20:44:37 2018], validation: iter [5660], loss[0.2465996146]\n",
      "[ Tue Dec  4 20:44:37 2018], epoch [5680], lr[0.02500000] ,loss[0.2303618640]\n",
      "[ Tue Dec  4 20:44:37 2018], validation: iter [5680], loss[0.2464205921]\n",
      "[ Tue Dec  4 20:44:38 2018], epoch [5700], lr[0.02500000] ,loss[0.2303788662]\n",
      "[ Tue Dec  4 20:44:38 2018], validation: iter [5700], loss[0.2464243919]\n",
      "[ Tue Dec  4 20:44:38 2018], epoch [5720], lr[0.02500000] ,loss[0.2311687618]\n",
      "[ Tue Dec  4 20:44:38 2018], validation: iter [5720], loss[0.2470241040]\n",
      "[ Tue Dec  4 20:44:38 2018], epoch [5740], lr[0.02500000] ,loss[0.2304852605]\n",
      "[ Tue Dec  4 20:44:38 2018], validation: iter [5740], loss[0.2464465052]\n",
      "[ Tue Dec  4 20:44:39 2018], epoch [5760], lr[0.02500000] ,loss[0.2303847224]\n",
      "[ Tue Dec  4 20:44:39 2018], validation: iter [5760], loss[0.2464272976]\n",
      "[ Tue Dec  4 20:44:39 2018], epoch [5780], lr[0.02500000] ,loss[0.2303737849]\n",
      "[ Tue Dec  4 20:44:39 2018], validation: iter [5780], loss[0.2464244068]\n",
      "[ Tue Dec  4 20:44:40 2018], epoch [5800], lr[0.02500000] ,loss[0.2303875387]\n",
      "[ Tue Dec  4 20:44:40 2018], validation: iter [5800], loss[0.2464081198]\n",
      "[ Tue Dec  4 20:44:40 2018], epoch [5820], lr[0.02500000] ,loss[0.2304101735]\n",
      "[ Tue Dec  4 20:44:40 2018], validation: iter [5820], loss[0.2464367002]\n",
      "[ Tue Dec  4 20:44:41 2018], epoch [5840], lr[0.02500000] ,loss[0.2303506136]\n",
      "[ Tue Dec  4 20:44:41 2018], validation: iter [5840], loss[0.2465039492]\n",
      "[ Tue Dec  4 20:44:41 2018], epoch [5860], lr[0.02500000] ,loss[0.2303411067]\n",
      "[ Tue Dec  4 20:44:41 2018], validation: iter [5860], loss[0.2464236766]\n",
      "[ Tue Dec  4 20:44:42 2018], epoch [5880], lr[0.02500000] ,loss[0.2303969562]\n",
      "[ Tue Dec  4 20:44:42 2018], validation: iter [5880], loss[0.2463931292]\n",
      "[ Tue Dec  4 20:44:42 2018], epoch [5900], lr[0.02500000] ,loss[0.2303529829]\n",
      "[ Tue Dec  4 20:44:42 2018], validation: iter [5900], loss[0.2464208156]\n",
      "[ Tue Dec  4 20:44:43 2018], epoch [5920], lr[0.02500000] ,loss[0.2303499579]\n",
      "[ Tue Dec  4 20:44:43 2018], validation: iter [5920], loss[0.2464010417]\n",
      "[ Tue Dec  4 20:44:43 2018], epoch [5940], lr[0.02500000] ,loss[0.2304787189]\n",
      "[ Tue Dec  4 20:44:43 2018], validation: iter [5940], loss[0.2465112507]\n",
      "[ Tue Dec  4 20:44:44 2018], epoch [5960], lr[0.02500000] ,loss[0.2303704917]\n",
      "[ Tue Dec  4 20:44:44 2018], validation: iter [5960], loss[0.2464028895]\n",
      "[ Tue Dec  4 20:44:44 2018], epoch [5980], lr[0.02500000] ,loss[0.2303636074]\n",
      "[ Tue Dec  4 20:44:44 2018], validation: iter [5980], loss[0.2464599162]\n",
      "[ Tue Dec  4 20:44:45 2018], epoch [6000], lr[0.02500000] ,loss[0.2304057628]\n",
      "[ Tue Dec  4 20:44:45 2018], validation: iter [6000], loss[0.2465071082]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_6000']\n",
      "[ Tue Dec  4 20:44:46 2018], epoch [6020], lr[0.01250000] ,loss[0.2303576767]\n",
      "[ Tue Dec  4 20:44:46 2018], validation: iter [6020], loss[0.2463852018]\n",
      "[ Tue Dec  4 20:44:46 2018], epoch [6040], lr[0.01250000] ,loss[0.2303548306]\n",
      "[ Tue Dec  4 20:44:46 2018], validation: iter [6040], loss[0.2463883162]\n",
      "[ Tue Dec  4 20:44:47 2018], epoch [6060], lr[0.01250000] ,loss[0.2303671837]\n",
      "[ Tue Dec  4 20:44:47 2018], validation: iter [6060], loss[0.2464062721]\n",
      "[ Tue Dec  4 20:44:47 2018], epoch [6080], lr[0.01250000] ,loss[0.2303440273]\n",
      "[ Tue Dec  4 20:44:47 2018], validation: iter [6080], loss[0.2463738620]\n",
      "[ Tue Dec  4 20:44:48 2018], epoch [6100], lr[0.01250000] ,loss[0.2303478122]\n",
      "[ Tue Dec  4 20:44:48 2018], validation: iter [6100], loss[0.2463884354]\n",
      "[ Tue Dec  4 20:44:48 2018], epoch [6120], lr[0.01250000] ,loss[0.2303412110]\n",
      "[ Tue Dec  4 20:44:48 2018], validation: iter [6120], loss[0.2463911325]\n",
      "[ Tue Dec  4 20:44:49 2018], epoch [6140], lr[0.01250000] ,loss[0.2303498238]\n",
      "[ Tue Dec  4 20:44:49 2018], validation: iter [6140], loss[0.2463930845]\n",
      "[ Tue Dec  4 20:44:49 2018], epoch [6160], lr[0.01250000] ,loss[0.2303522527]\n",
      "[ Tue Dec  4 20:44:49 2018], validation: iter [6160], loss[0.2463893890]\n",
      "[ Tue Dec  4 20:44:50 2018], epoch [6180], lr[0.01250000] ,loss[0.2303457260]\n",
      "[ Tue Dec  4 20:44:50 2018], validation: iter [6180], loss[0.2463961691]\n",
      "[ Tue Dec  4 20:44:50 2018], epoch [6200], lr[0.01250000] ,loss[0.2303406596]\n",
      "[ Tue Dec  4 20:44:50 2018], validation: iter [6200], loss[0.2463860214]\n",
      "[ Tue Dec  4 20:44:51 2018], epoch [6220], lr[0.01250000] ,loss[0.2303539962]\n",
      "[ Tue Dec  4 20:44:51 2018], validation: iter [6220], loss[0.2463826984]\n",
      "[ Tue Dec  4 20:44:51 2018], epoch [6240], lr[0.01250000] ,loss[0.2303581238]\n",
      "[ Tue Dec  4 20:44:51 2018], validation: iter [6240], loss[0.2463960350]\n",
      "[ Tue Dec  4 20:44:52 2018], epoch [6260], lr[0.01250000] ,loss[0.2303522974]\n",
      "[ Tue Dec  4 20:44:52 2018], validation: iter [6260], loss[0.2463975996]\n",
      "[ Tue Dec  4 20:44:52 2018], epoch [6280], lr[0.01250000] ,loss[0.2303487659]\n",
      "[ Tue Dec  4 20:44:52 2018], validation: iter [6280], loss[0.2463803291]\n",
      "[ Tue Dec  4 20:44:53 2018], epoch [6300], lr[0.01250000] ,loss[0.2303543091]\n",
      "[ Tue Dec  4 20:44:53 2018], validation: iter [6300], loss[0.2463858277]\n",
      "[ Tue Dec  4 20:44:53 2018], epoch [6320], lr[0.01250000] ,loss[0.2303577811]\n",
      "[ Tue Dec  4 20:44:53 2018], validation: iter [6320], loss[0.2463829815]\n",
      "[ Tue Dec  4 20:44:54 2018], epoch [6340], lr[0.01250000] ,loss[0.2303500324]\n",
      "[ Tue Dec  4 20:44:54 2018], validation: iter [6340], loss[0.2463702559]\n",
      "[ Tue Dec  4 20:44:55 2018], epoch [6360], lr[0.01250000] ,loss[0.2303456664]\n",
      "[ Tue Dec  4 20:44:55 2018], validation: iter [6360], loss[0.2463835776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 20:44:55 2018], epoch [6380], lr[0.01250000] ,loss[0.2303457111]\n",
      "[ Tue Dec  4 20:44:55 2018], validation: iter [6380], loss[0.2463867515]\n",
      "[ Tue Dec  4 20:44:56 2018], epoch [6400], lr[0.01250000] ,loss[0.2303384244]\n",
      "[ Tue Dec  4 20:44:56 2018], validation: iter [6400], loss[0.2463813722]\n",
      "[ Tue Dec  4 20:44:56 2018], epoch [6420], lr[0.01250000] ,loss[0.2303425074]\n",
      "[ Tue Dec  4 20:44:56 2018], validation: iter [6420], loss[0.2463714629]\n",
      "[ Tue Dec  4 20:44:57 2018], epoch [6440], lr[0.01250000] ,loss[0.2303416729]\n",
      "[ Tue Dec  4 20:44:57 2018], validation: iter [6440], loss[0.2463787496]\n",
      "[ Tue Dec  4 20:44:57 2018], epoch [6460], lr[0.01250000] ,loss[0.2303467393]\n",
      "[ Tue Dec  4 20:44:57 2018], validation: iter [6460], loss[0.2463975549]\n",
      "[ Tue Dec  4 20:44:58 2018], epoch [6480], lr[0.01250000] ,loss[0.2303534001]\n",
      "[ Tue Dec  4 20:44:58 2018], validation: iter [6480], loss[0.2463897318]\n",
      "[ Tue Dec  4 20:44:58 2018], epoch [6500], lr[0.01250000] ,loss[0.2303487360]\n",
      "[ Tue Dec  4 20:44:58 2018], validation: iter [6500], loss[0.2463894784]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_6500']\n",
      "[ Tue Dec  4 20:44:59 2018], epoch [6520], lr[0.01250000] ,loss[0.2303493023]\n",
      "[ Tue Dec  4 20:44:59 2018], validation: iter [6520], loss[0.2463910878]\n",
      "[ Tue Dec  4 20:44:59 2018], epoch [6540], lr[0.01250000] ,loss[0.2303541005]\n",
      "[ Tue Dec  4 20:44:59 2018], validation: iter [6540], loss[0.2463908345]\n",
      "[ Tue Dec  4 20:45:00 2018], epoch [6560], lr[0.01250000] ,loss[0.2303551584]\n",
      "[ Tue Dec  4 20:45:00 2018], validation: iter [6560], loss[0.2463915944]\n",
      "[ Tue Dec  4 20:45:00 2018], epoch [6580], lr[0.01250000] ,loss[0.2303541303]\n",
      "[ Tue Dec  4 20:45:00 2018], validation: iter [6580], loss[0.2463909388]\n",
      "[ Tue Dec  4 20:45:01 2018], epoch [6600], lr[0.01250000] ,loss[0.2303518206]\n",
      "[ Tue Dec  4 20:45:01 2018], validation: iter [6600], loss[0.2463913709]\n",
      "[ Tue Dec  4 20:45:01 2018], epoch [6620], lr[0.01250000] ,loss[0.2303497940]\n",
      "[ Tue Dec  4 20:45:01 2018], validation: iter [6620], loss[0.2463900745]\n",
      "[ Tue Dec  4 20:45:02 2018], epoch [6640], lr[0.01250000] ,loss[0.2303481698]\n",
      "[ Tue Dec  4 20:45:02 2018], validation: iter [6640], loss[0.2463901192]\n",
      "[ Tue Dec  4 20:45:02 2018], epoch [6660], lr[0.01250000] ,loss[0.2303434163]\n",
      "[ Tue Dec  4 20:45:02 2018], validation: iter [6660], loss[0.2463907003]\n",
      "[ Tue Dec  4 20:45:03 2018], epoch [6680], lr[0.01250000] ,loss[0.2303451151]\n",
      "[ Tue Dec  4 20:45:03 2018], validation: iter [6680], loss[0.2463907450]\n",
      "[ Tue Dec  4 20:45:03 2018], epoch [6700], lr[0.01250000] ,loss[0.2303424776]\n",
      "[ Tue Dec  4 20:45:03 2018], validation: iter [6700], loss[0.2463907748]\n",
      "[ Tue Dec  4 20:45:04 2018], epoch [6720], lr[0.01250000] ,loss[0.2303393334]\n",
      "[ Tue Dec  4 20:45:04 2018], validation: iter [6720], loss[0.2463912517]\n",
      "[ Tue Dec  4 20:45:04 2018], epoch [6740], lr[0.01250000] ,loss[0.2303443253]\n",
      "[ Tue Dec  4 20:45:04 2018], validation: iter [6740], loss[0.2463922501]\n",
      "[ Tue Dec  4 20:45:05 2018], epoch [6760], lr[0.01250000] ,loss[0.2303473502]\n",
      "[ Tue Dec  4 20:45:05 2018], validation: iter [6760], loss[0.2463925034]\n",
      "[ Tue Dec  4 20:45:05 2018], epoch [6780], lr[0.01250000] ,loss[0.2303505540]\n",
      "[ Tue Dec  4 20:45:05 2018], validation: iter [6780], loss[0.2463918924]\n",
      "[ Tue Dec  4 20:45:06 2018], epoch [6800], lr[0.01250000] ,loss[0.2303544134]\n",
      "[ Tue Dec  4 20:45:06 2018], validation: iter [6800], loss[0.2463930845]\n",
      "[ Tue Dec  4 20:45:06 2018], epoch [6820], lr[0.01250000] ,loss[0.2303545773]\n",
      "[ Tue Dec  4 20:45:06 2018], validation: iter [6820], loss[0.2463940233]\n",
      "[ Tue Dec  4 20:45:07 2018], epoch [6840], lr[0.01250000] ,loss[0.2303479314]\n",
      "[ Tue Dec  4 20:45:07 2018], validation: iter [6840], loss[0.2463939786]\n",
      "[ Tue Dec  4 20:45:07 2018], epoch [6860], lr[0.01250000] ,loss[0.2303500623]\n",
      "[ Tue Dec  4 20:45:07 2018], validation: iter [6860], loss[0.2463932037]\n",
      "[ Tue Dec  4 20:45:08 2018], epoch [6880], lr[0.01250000] ,loss[0.2303552330]\n",
      "[ Tue Dec  4 20:45:08 2018], validation: iter [6880], loss[0.2463927865]\n",
      "[ Tue Dec  4 20:45:08 2018], epoch [6900], lr[0.01250000] ,loss[0.2303466946]\n",
      "[ Tue Dec  4 20:45:08 2018], validation: iter [6900], loss[0.2463929355]\n",
      "[ Tue Dec  4 20:45:09 2018], epoch [6920], lr[0.01250000] ,loss[0.2303547114]\n",
      "[ Tue Dec  4 20:45:09 2018], validation: iter [6920], loss[0.2463914901]\n",
      "[ Tue Dec  4 20:45:09 2018], epoch [6940], lr[0.01250000] ,loss[0.2303609401]\n",
      "[ Tue Dec  4 20:45:09 2018], validation: iter [6940], loss[0.2463908195]\n",
      "[ Tue Dec  4 20:45:09 2018], epoch [6960], lr[0.01250000] ,loss[0.2303686291]\n",
      "[ Tue Dec  4 20:45:09 2018], validation: iter [6960], loss[0.2463878542]\n",
      "[ Tue Dec  4 20:45:10 2018], epoch [6980], lr[0.01250000] ,loss[0.2303695083]\n",
      "[ Tue Dec  4 20:45:10 2018], validation: iter [6980], loss[0.2463666648]\n",
      "[ Tue Dec  4 20:45:10 2018], epoch [7000], lr[0.01250000] ,loss[0.2303334475]\n",
      "[ Tue Dec  4 20:45:10 2018], validation: iter [7000], loss[0.2463485748]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_7000']\n",
      "[ Tue Dec  4 20:45:11 2018], epoch [7020], lr[0.01250000] ,loss[0.2303361297]\n",
      "[ Tue Dec  4 20:45:11 2018], validation: iter [7020], loss[0.2463713437]\n",
      "[ Tue Dec  4 20:45:12 2018], epoch [7040], lr[0.01250000] ,loss[0.2303440422]\n",
      "[ Tue Dec  4 20:45:12 2018], validation: iter [7040], loss[0.2463776171]\n",
      "[ Tue Dec  4 20:45:12 2018], epoch [7060], lr[0.01250000] ,loss[0.2303468287]\n",
      "[ Tue Dec  4 20:45:12 2018], validation: iter [7060], loss[0.2463662177]\n",
      "[ Tue Dec  4 20:45:13 2018], epoch [7080], lr[0.01250000] ,loss[0.2303497791]\n",
      "[ Tue Dec  4 20:45:13 2018], validation: iter [7080], loss[0.2463649213]\n",
      "[ Tue Dec  4 20:45:13 2018], epoch [7100], lr[0.01250000] ,loss[0.2303458154]\n",
      "[ Tue Dec  4 20:45:13 2018], validation: iter [7100], loss[0.2463652939]\n",
      "[ Tue Dec  4 20:45:14 2018], epoch [7120], lr[0.01250000] ,loss[0.2303438783]\n",
      "[ Tue Dec  4 20:45:14 2018], validation: iter [7120], loss[0.2463668734]\n",
      "[ Tue Dec  4 20:45:14 2018], epoch [7140], lr[0.01250000] ,loss[0.2303502709]\n",
      "[ Tue Dec  4 20:45:14 2018], validation: iter [7140], loss[0.2463668734]\n",
      "[ Tue Dec  4 20:45:15 2018], epoch [7160], lr[0.01250000] ,loss[0.2303543091]\n",
      "[ Tue Dec  4 20:45:15 2018], validation: iter [7160], loss[0.2463684231]\n",
      "[ Tue Dec  4 20:45:15 2018], epoch [7180], lr[0.01250000] ,loss[0.2303538322]\n",
      "[ Tue Dec  4 20:45:15 2018], validation: iter [7180], loss[0.2463698089]\n",
      "[ Tue Dec  4 20:45:15 2018], epoch [7200], lr[0.01250000] ,loss[0.2303561419]\n",
      "[ Tue Dec  4 20:45:15 2018], validation: iter [7200], loss[0.2463727146]\n",
      "[ Tue Dec  4 20:45:16 2018], epoch [7220], lr[0.01250000] ,loss[0.2303510606]\n",
      "[ Tue Dec  4 20:45:16 2018], validation: iter [7220], loss[0.2463742644]\n",
      "[ Tue Dec  4 20:45:16 2018], epoch [7240], lr[0.01250000] ,loss[0.2303472012]\n",
      "[ Tue Dec  4 20:45:16 2018], validation: iter [7240], loss[0.2463704646]\n",
      "[ Tue Dec  4 20:45:17 2018], epoch [7260], lr[0.01250000] ,loss[0.2303291559]\n",
      "[ Tue Dec  4 20:45:17 2018], validation: iter [7260], loss[0.2463646084]\n",
      "[ Tue Dec  4 20:45:17 2018], epoch [7280], lr[0.01250000] ,loss[0.2303405404]\n",
      "[ Tue Dec  4 20:45:17 2018], validation: iter [7280], loss[0.2463676929]\n",
      "[ Tue Dec  4 20:45:18 2018], epoch [7300], lr[0.01250000] ,loss[0.2303330898]\n",
      "[ Tue Dec  4 20:45:18 2018], validation: iter [7300], loss[0.2463507354]\n",
      "[ Tue Dec  4 20:45:18 2018], epoch [7320], lr[0.01250000] ,loss[0.2303495109]\n",
      "[ Tue Dec  4 20:45:18 2018], validation: iter [7320], loss[0.2463501543]\n",
      "[ Tue Dec  4 20:45:19 2018], epoch [7340], lr[0.01250000] ,loss[0.2303434759]\n",
      "[ Tue Dec  4 20:45:19 2018], validation: iter [7340], loss[0.2463533580]\n",
      "[ Tue Dec  4 20:45:19 2018], epoch [7360], lr[0.01250000] ,loss[0.2303586751]\n",
      "[ Tue Dec  4 20:45:19 2018], validation: iter [7360], loss[0.2463617176]\n",
      "[ Tue Dec  4 20:45:20 2018], epoch [7380], lr[0.01250000] ,loss[0.2303452790]\n",
      "[ Tue Dec  4 20:45:20 2018], validation: iter [7380], loss[0.2463545352]\n",
      "[ Tue Dec  4 20:45:20 2018], epoch [7400], lr[0.01250000] ,loss[0.2303374261]\n",
      "[ Tue Dec  4 20:45:20 2018], validation: iter [7400], loss[0.2463619858]\n",
      "[ Tue Dec  4 20:45:21 2018], epoch [7420], lr[0.01250000] ,loss[0.2303311229]\n",
      "[ Tue Dec  4 20:45:21 2018], validation: iter [7420], loss[0.2463711351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 20:45:21 2018], epoch [7440], lr[0.01250000] ,loss[0.2303411812]\n",
      "[ Tue Dec  4 20:45:21 2018], validation: iter [7440], loss[0.2463759035]\n",
      "[ Tue Dec  4 20:45:22 2018], epoch [7460], lr[0.01250000] ,loss[0.2303456664]\n",
      "[ Tue Dec  4 20:45:22 2018], validation: iter [7460], loss[0.2463607937]\n",
      "[ Tue Dec  4 20:45:22 2018], epoch [7480], lr[0.01250000] ,loss[0.2303224504]\n",
      "[ Tue Dec  4 20:45:22 2018], validation: iter [7480], loss[0.2463694662]\n",
      "[ Tue Dec  4 20:45:23 2018], epoch [7500], lr[0.01250000] ,loss[0.2303258330]\n",
      "[ Tue Dec  4 20:45:23 2018], validation: iter [7500], loss[0.2463545650]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_7500']\n",
      "[ Tue Dec  4 20:45:23 2018], epoch [7520], lr[0.01250000] ,loss[0.2303645015]\n",
      "[ Tue Dec  4 20:45:23 2018], validation: iter [7520], loss[0.2463769466]\n",
      "[ Tue Dec  4 20:45:24 2018], epoch [7540], lr[0.01250000] ,loss[0.2303943038]\n",
      "[ Tue Dec  4 20:45:24 2018], validation: iter [7540], loss[0.2463847250]\n",
      "[ Tue Dec  4 20:45:24 2018], epoch [7560], lr[0.01250000] ,loss[0.2303408682]\n",
      "[ Tue Dec  4 20:45:24 2018], validation: iter [7560], loss[0.2463611364]\n",
      "[ Tue Dec  4 20:45:25 2018], epoch [7580], lr[0.01250000] ,loss[0.2303506285]\n",
      "[ Tue Dec  4 20:45:25 2018], validation: iter [7580], loss[0.2463553101]\n",
      "[ Tue Dec  4 20:45:25 2018], epoch [7600], lr[0.01250000] ,loss[0.2303298563]\n",
      "[ Tue Dec  4 20:45:25 2018], validation: iter [7600], loss[0.2463558018]\n",
      "[ Tue Dec  4 20:45:26 2018], epoch [7620], lr[0.01250000] ,loss[0.2303320318]\n",
      "[ Tue Dec  4 20:45:26 2018], validation: iter [7620], loss[0.2463626713]\n",
      "[ Tue Dec  4 20:45:26 2018], epoch [7640], lr[0.01250000] ,loss[0.2303259671]\n",
      "[ Tue Dec  4 20:45:26 2018], validation: iter [7640], loss[0.2463849932]\n",
      "[ Tue Dec  4 20:45:27 2018], epoch [7660], lr[0.01250000] ,loss[0.2303956896]\n",
      "[ Tue Dec  4 20:45:27 2018], validation: iter [7660], loss[0.2463851422]\n",
      "[ Tue Dec  4 20:45:27 2018], epoch [7680], lr[0.01250000] ,loss[0.2303399295]\n",
      "[ Tue Dec  4 20:45:27 2018], validation: iter [7680], loss[0.2463593036]\n",
      "[ Tue Dec  4 20:45:28 2018], epoch [7700], lr[0.01250000] ,loss[0.2303317338]\n",
      "[ Tue Dec  4 20:45:28 2018], validation: iter [7700], loss[0.2463678867]\n",
      "[ Tue Dec  4 20:45:28 2018], epoch [7720], lr[0.01250000] ,loss[0.2303182483]\n",
      "[ Tue Dec  4 20:45:28 2018], validation: iter [7720], loss[0.2463590652]\n",
      "[ Tue Dec  4 20:45:29 2018], epoch [7740], lr[0.01250000] ,loss[0.2303308398]\n",
      "[ Tue Dec  4 20:45:29 2018], validation: iter [7740], loss[0.2463620752]\n",
      "[ Tue Dec  4 20:45:29 2018], epoch [7760], lr[0.01250000] ,loss[0.2303297222]\n",
      "[ Tue Dec  4 20:45:29 2018], validation: iter [7760], loss[0.2463635504]\n",
      "[ Tue Dec  4 20:45:30 2018], epoch [7780], lr[0.01250000] ,loss[0.2305668890]\n",
      "[ Tue Dec  4 20:45:30 2018], validation: iter [7780], loss[0.2465332597]\n",
      "[ Tue Dec  4 20:45:30 2018], epoch [7800], lr[0.01250000] ,loss[0.2303582579]\n",
      "[ Tue Dec  4 20:45:30 2018], validation: iter [7800], loss[0.2463956624]\n",
      "[ Tue Dec  4 20:45:31 2018], epoch [7820], lr[0.01250000] ,loss[0.2303219587]\n",
      "[ Tue Dec  4 20:45:31 2018], validation: iter [7820], loss[0.2463700771]\n",
      "[ Tue Dec  4 20:45:31 2018], epoch [7840], lr[0.01250000] ,loss[0.2303458303]\n",
      "[ Tue Dec  4 20:45:31 2018], validation: iter [7840], loss[0.2463648021]\n",
      "[ Tue Dec  4 20:45:32 2018], epoch [7860], lr[0.01250000] ,loss[0.2303224951]\n",
      "[ Tue Dec  4 20:45:32 2018], validation: iter [7860], loss[0.2463617921]\n",
      "[ Tue Dec  4 20:45:32 2018], epoch [7880], lr[0.01250000] ,loss[0.2303393334]\n",
      "[ Tue Dec  4 20:45:32 2018], validation: iter [7880], loss[0.2463637888]\n",
      "[ Tue Dec  4 20:45:33 2018], epoch [7900], lr[0.01250000] ,loss[0.2303271294]\n",
      "[ Tue Dec  4 20:45:33 2018], validation: iter [7900], loss[0.2463647723]\n",
      "[ Tue Dec  4 20:45:33 2018], epoch [7920], lr[0.01250000] ,loss[0.2303345799]\n",
      "[ Tue Dec  4 20:45:33 2018], validation: iter [7920], loss[0.2463709563]\n",
      "[ Tue Dec  4 20:45:34 2018], epoch [7940], lr[0.01250000] ,loss[0.2303240001]\n",
      "[ Tue Dec  4 20:45:34 2018], validation: iter [7940], loss[0.2463521510]\n",
      "[ Tue Dec  4 20:45:34 2018], epoch [7960], lr[0.01250000] ,loss[0.2303328514]\n",
      "[ Tue Dec  4 20:45:34 2018], validation: iter [7960], loss[0.2463583201]\n",
      "[ Tue Dec  4 20:45:35 2018], epoch [7980], lr[0.01250000] ,loss[0.2303011864]\n",
      "[ Tue Dec  4 20:45:35 2018], validation: iter [7980], loss[0.2463596910]\n",
      "[ Tue Dec  4 20:45:35 2018], epoch [8000], lr[0.01250000] ,loss[0.2303132862]\n",
      "[ Tue Dec  4 20:45:35 2018], validation: iter [8000], loss[0.2463702857]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_8000']\n",
      "[ Tue Dec  4 20:45:36 2018], epoch [8020], lr[0.00625000] ,loss[0.2303181887]\n",
      "[ Tue Dec  4 20:45:36 2018], validation: iter [8020], loss[0.2463500202]\n",
      "[ Tue Dec  4 20:45:37 2018], epoch [8040], lr[0.00625000] ,loss[0.2303226441]\n",
      "[ Tue Dec  4 20:45:37 2018], validation: iter [8040], loss[0.2463549227]\n",
      "[ Tue Dec  4 20:45:37 2018], epoch [8060], lr[0.00625000] ,loss[0.2303259075]\n",
      "[ Tue Dec  4 20:45:37 2018], validation: iter [8060], loss[0.2463558465]\n",
      "[ Tue Dec  4 20:45:38 2018], epoch [8080], lr[0.00625000] ,loss[0.2303287536]\n",
      "[ Tue Dec  4 20:45:38 2018], validation: iter [8080], loss[0.2463368028]\n",
      "[ Tue Dec  4 20:45:38 2018], epoch [8100], lr[0.00625000] ,loss[0.2303296328]\n",
      "[ Tue Dec  4 20:45:38 2018], validation: iter [8100], loss[0.2463418394]\n",
      "[ Tue Dec  4 20:45:38 2018], epoch [8120], lr[0.00625000] ,loss[0.2303167582]\n",
      "[ Tue Dec  4 20:45:38 2018], validation: iter [8120], loss[0.2463516593]\n",
      "[ Tue Dec  4 20:45:39 2018], epoch [8140], lr[0.00625000] ,loss[0.2303210795]\n",
      "[ Tue Dec  4 20:45:39 2018], validation: iter [8140], loss[0.2463605106]\n",
      "[ Tue Dec  4 20:45:39 2018], epoch [8160], lr[0.00625000] ,loss[0.2303369790]\n",
      "[ Tue Dec  4 20:45:39 2018], validation: iter [8160], loss[0.2463663667]\n",
      "[ Tue Dec  4 20:45:40 2018], epoch [8180], lr[0.00625000] ,loss[0.2303279191]\n",
      "[ Tue Dec  4 20:45:40 2018], validation: iter [8180], loss[0.2463543117]\n",
      "[ Tue Dec  4 20:45:40 2018], epoch [8200], lr[0.00625000] ,loss[0.2303164899]\n",
      "[ Tue Dec  4 20:45:40 2018], validation: iter [8200], loss[0.2463373691]\n",
      "[ Tue Dec  4 20:45:41 2018], epoch [8220], lr[0.00625000] ,loss[0.2303172499]\n",
      "[ Tue Dec  4 20:45:41 2018], validation: iter [8220], loss[0.2463522255]\n",
      "[ Tue Dec  4 20:45:41 2018], epoch [8240], lr[0.00625000] ,loss[0.2303253114]\n",
      "[ Tue Dec  4 20:45:41 2018], validation: iter [8240], loss[0.2463636100]\n",
      "[ Tue Dec  4 20:45:42 2018], epoch [8260], lr[0.00625000] ,loss[0.2303370088]\n",
      "[ Tue Dec  4 20:45:42 2018], validation: iter [8260], loss[0.2463599592]\n",
      "[ Tue Dec  4 20:45:42 2018], epoch [8280], lr[0.00625000] ,loss[0.2303322554]\n",
      "[ Tue Dec  4 20:45:42 2018], validation: iter [8280], loss[0.2463399172]\n",
      "[ Tue Dec  4 20:45:43 2018], epoch [8300], lr[0.00625000] ,loss[0.2303106189]\n",
      "[ Tue Dec  4 20:45:43 2018], validation: iter [8300], loss[0.2463503778]\n",
      "[ Tue Dec  4 20:45:43 2018], epoch [8320], lr[0.00625000] ,loss[0.2303287536]\n",
      "[ Tue Dec  4 20:45:43 2018], validation: iter [8320], loss[0.2463635504]\n",
      "[ Tue Dec  4 20:45:44 2018], epoch [8340], lr[0.00625000] ,loss[0.2303232998]\n",
      "[ Tue Dec  4 20:45:44 2018], validation: iter [8340], loss[0.2463448495]\n",
      "[ Tue Dec  4 20:45:44 2018], epoch [8360], lr[0.00625000] ,loss[0.2303100675]\n",
      "[ Tue Dec  4 20:45:44 2018], validation: iter [8360], loss[0.2463476509]\n",
      "[ Tue Dec  4 20:45:45 2018], epoch [8380], lr[0.00625000] ,loss[0.2303255945]\n",
      "[ Tue Dec  4 20:45:45 2018], validation: iter [8380], loss[0.2463485003]\n",
      "[ Tue Dec  4 20:45:45 2018], epoch [8400], lr[0.00625000] ,loss[0.2303264886]\n",
      "[ Tue Dec  4 20:45:45 2018], validation: iter [8400], loss[0.2463393807]\n",
      "[ Tue Dec  4 20:45:46 2018], epoch [8420], lr[0.00625000] ,loss[0.2303312123]\n",
      "[ Tue Dec  4 20:45:46 2018], validation: iter [8420], loss[0.2463495284]\n",
      "[ Tue Dec  4 20:45:46 2018], epoch [8440], lr[0.00625000] ,loss[0.2303212434]\n",
      "[ Tue Dec  4 20:45:46 2018], validation: iter [8440], loss[0.2463509440]\n",
      "[ Tue Dec  4 20:45:47 2018], epoch [8460], lr[0.00625000] ,loss[0.2303227782]\n",
      "[ Tue Dec  4 20:45:47 2018], validation: iter [8460], loss[0.2463488728]\n",
      "[ Tue Dec  4 20:45:47 2018], epoch [8480], lr[0.00625000] ,loss[0.2303244770]\n",
      "[ Tue Dec  4 20:45:47 2018], validation: iter [8480], loss[0.2463571429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 20:45:48 2018], epoch [8500], lr[0.00625000] ,loss[0.2303261906]\n",
      "[ Tue Dec  4 20:45:48 2018], validation: iter [8500], loss[0.2463485152]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_8500']\n",
      "[ Tue Dec  4 20:45:48 2018], epoch [8520], lr[0.00625000] ,loss[0.2303225398]\n",
      "[ Tue Dec  4 20:45:48 2018], validation: iter [8520], loss[0.2463498861]\n",
      "[ Tue Dec  4 20:45:49 2018], epoch [8540], lr[0.00625000] ,loss[0.2303244025]\n",
      "[ Tue Dec  4 20:45:49 2018], validation: iter [8540], loss[0.2463555485]\n",
      "[ Tue Dec  4 20:45:49 2018], epoch [8560], lr[0.00625000] ,loss[0.2303237915]\n",
      "[ Tue Dec  4 20:45:49 2018], validation: iter [8560], loss[0.2463486344]\n",
      "[ Tue Dec  4 20:45:50 2018], epoch [8580], lr[0.00625000] ,loss[0.2303236872]\n",
      "[ Tue Dec  4 20:45:50 2018], validation: iter [8580], loss[0.2463490218]\n",
      "[ Tue Dec  4 20:45:50 2018], epoch [8600], lr[0.00625000] ,loss[0.2303206623]\n",
      "[ Tue Dec  4 20:45:50 2018], validation: iter [8600], loss[0.2463561296]\n",
      "[ Tue Dec  4 20:45:51 2018], epoch [8620], lr[0.00625000] ,loss[0.2303247601]\n",
      "[ Tue Dec  4 20:45:51 2018], validation: iter [8620], loss[0.2463494539]\n",
      "[ Tue Dec  4 20:45:51 2018], epoch [8640], lr[0.00625000] ,loss[0.2303252071]\n",
      "[ Tue Dec  4 20:45:51 2018], validation: iter [8640], loss[0.2463483661]\n",
      "[ Tue Dec  4 20:45:52 2018], epoch [8660], lr[0.00625000] ,loss[0.2303202599]\n",
      "[ Tue Dec  4 20:45:52 2018], validation: iter [8660], loss[0.2463557422]\n",
      "[ Tue Dec  4 20:45:52 2018], epoch [8680], lr[0.00625000] ,loss[0.2303263247]\n",
      "[ Tue Dec  4 20:45:52 2018], validation: iter [8680], loss[0.2463489473]\n",
      "[ Tue Dec  4 20:45:53 2018], epoch [8700], lr[0.00625000] ,loss[0.2303232700]\n",
      "[ Tue Dec  4 20:45:53 2018], validation: iter [8700], loss[0.2463473678]\n",
      "[ Tue Dec  4 20:45:53 2018], epoch [8720], lr[0.00625000] ,loss[0.2303259671]\n",
      "[ Tue Dec  4 20:45:53 2018], validation: iter [8720], loss[0.2463553101]\n",
      "[ Tue Dec  4 20:45:54 2018], epoch [8740], lr[0.00625000] ,loss[0.2303237468]\n",
      "[ Tue Dec  4 20:45:54 2018], validation: iter [8740], loss[0.2463488877]\n",
      "[ Tue Dec  4 20:45:54 2018], epoch [8760], lr[0.00625000] ,loss[0.2303237468]\n",
      "[ Tue Dec  4 20:45:54 2018], validation: iter [8760], loss[0.2463474870]\n",
      "[ Tue Dec  4 20:45:55 2018], epoch [8780], lr[0.00625000] ,loss[0.2303370535]\n",
      "[ Tue Dec  4 20:45:55 2018], validation: iter [8780], loss[0.2463432550]\n",
      "[ Tue Dec  4 20:45:55 2018], epoch [8800], lr[0.00625000] ,loss[0.2303225994]\n",
      "[ Tue Dec  4 20:45:55 2018], validation: iter [8800], loss[0.2463498414]\n",
      "[ Tue Dec  4 20:45:56 2018], epoch [8820], lr[0.00625000] ,loss[0.2303335071]\n",
      "[ Tue Dec  4 20:45:56 2018], validation: iter [8820], loss[0.2463499457]\n",
      "[ Tue Dec  4 20:45:56 2018], epoch [8840], lr[0.00625000] ,loss[0.2303201407]\n",
      "[ Tue Dec  4 20:45:56 2018], validation: iter [8840], loss[0.2463572919]\n",
      "[ Tue Dec  4 20:45:57 2018], epoch [8860], lr[0.00625000] ,loss[0.2303257436]\n",
      "[ Tue Dec  4 20:45:57 2018], validation: iter [8860], loss[0.2463466376]\n",
      "[ Tue Dec  4 20:45:57 2018], epoch [8880], lr[0.00625000] ,loss[0.2303135097]\n",
      "[ Tue Dec  4 20:45:57 2018], validation: iter [8880], loss[0.2463423461]\n",
      "[ Tue Dec  4 20:45:58 2018], epoch [8900], lr[0.00625000] ,loss[0.2303252071]\n",
      "[ Tue Dec  4 20:45:58 2018], validation: iter [8900], loss[0.2463628501]\n",
      "[ Tue Dec  4 20:45:58 2018], epoch [8920], lr[0.00625000] ,loss[0.2303296179]\n",
      "[ Tue Dec  4 20:45:58 2018], validation: iter [8920], loss[0.2463514209]\n",
      "[ Tue Dec  4 20:45:59 2018], epoch [8940], lr[0.00625000] ,loss[0.2303193063]\n",
      "[ Tue Dec  4 20:45:59 2018], validation: iter [8940], loss[0.2463475317]\n",
      "[ Tue Dec  4 20:45:59 2018], epoch [8960], lr[0.00625000] ,loss[0.2303263843]\n",
      "[ Tue Dec  4 20:45:59 2018], validation: iter [8960], loss[0.2463590950]\n",
      "[ Tue Dec  4 20:46:00 2018], epoch [8980], lr[0.00625000] ,loss[0.2303229719]\n",
      "[ Tue Dec  4 20:46:00 2018], validation: iter [8980], loss[0.2463507056]\n",
      "[ Tue Dec  4 20:46:00 2018], epoch [9000], lr[0.00625000] ,loss[0.2303181291]\n",
      "[ Tue Dec  4 20:46:00 2018], validation: iter [9000], loss[0.2463473827]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_9000']\n",
      "[ Tue Dec  4 20:46:01 2018], epoch [9020], lr[0.00625000] ,loss[0.2303308994]\n",
      "[ Tue Dec  4 20:46:01 2018], validation: iter [9020], loss[0.2463526726]\n",
      "[ Tue Dec  4 20:46:01 2018], epoch [9040], lr[0.00625000] ,loss[0.2303301245]\n",
      "[ Tue Dec  4 20:46:01 2018], validation: iter [9040], loss[0.2463449538]\n",
      "[ Tue Dec  4 20:46:02 2018], epoch [9060], lr[0.00625000] ,loss[0.2303123921]\n",
      "[ Tue Dec  4 20:46:02 2018], validation: iter [9060], loss[0.2463400066]\n",
      "[ Tue Dec  4 20:46:02 2018], epoch [9080], lr[0.00625000] ,loss[0.2303138524]\n",
      "[ Tue Dec  4 20:46:02 2018], validation: iter [9080], loss[0.2463493347]\n",
      "[ Tue Dec  4 20:46:03 2018], epoch [9100], lr[0.00625000] ,loss[0.2303352207]\n",
      "[ Tue Dec  4 20:46:03 2018], validation: iter [9100], loss[0.2463457882]\n",
      "[ Tue Dec  4 20:46:03 2018], epoch [9120], lr[0.00625000] ,loss[0.2303242683]\n",
      "[ Tue Dec  4 20:46:03 2018], validation: iter [9120], loss[0.2463440299]\n",
      "[ Tue Dec  4 20:46:04 2018], epoch [9140], lr[0.00625000] ,loss[0.2303262800]\n",
      "[ Tue Dec  4 20:46:04 2018], validation: iter [9140], loss[0.2463368326]\n",
      "[ Tue Dec  4 20:46:04 2018], epoch [9160], lr[0.00625000] ,loss[0.2303237021]\n",
      "[ Tue Dec  4 20:46:04 2018], validation: iter [9160], loss[0.2463568747]\n",
      "[ Tue Dec  4 20:46:05 2018], epoch [9180], lr[0.00625000] ,loss[0.2303357869]\n",
      "[ Tue Dec  4 20:46:05 2018], validation: iter [9180], loss[0.2463499457]\n",
      "[ Tue Dec  4 20:46:05 2018], epoch [9200], lr[0.00625000] ,loss[0.2303164303]\n",
      "[ Tue Dec  4 20:46:05 2018], validation: iter [9200], loss[0.2463487834]\n",
      "[ Tue Dec  4 20:46:06 2018], epoch [9220], lr[0.00625000] ,loss[0.2303233743]\n",
      "[ Tue Dec  4 20:46:06 2018], validation: iter [9220], loss[0.2463492602]\n",
      "[ Tue Dec  4 20:46:06 2018], epoch [9240], lr[0.00625000] ,loss[0.2303226441]\n",
      "[ Tue Dec  4 20:46:06 2018], validation: iter [9240], loss[0.2463488281]\n",
      "[ Tue Dec  4 20:46:07 2018], epoch [9260], lr[0.00625000] ,loss[0.2303247601]\n",
      "[ Tue Dec  4 20:46:07 2018], validation: iter [9260], loss[0.2463485897]\n",
      "[ Tue Dec  4 20:46:07 2018], epoch [9280], lr[0.00625000] ,loss[0.2303282619]\n",
      "[ Tue Dec  4 20:46:07 2018], validation: iter [9280], loss[0.2463484406]\n",
      "[ Tue Dec  4 20:46:08 2018], epoch [9300], lr[0.00625000] ,loss[0.2303147018]\n",
      "[ Tue Dec  4 20:46:08 2018], validation: iter [9300], loss[0.2463488430]\n",
      "[ Tue Dec  4 20:46:08 2018], epoch [9320], lr[0.00625000] ,loss[0.2303199768]\n",
      "[ Tue Dec  4 20:46:08 2018], validation: iter [9320], loss[0.2463472039]\n",
      "[ Tue Dec  4 20:46:09 2018], epoch [9340], lr[0.00625000] ,loss[0.2303139567]\n",
      "[ Tue Dec  4 20:46:09 2018], validation: iter [9340], loss[0.2463464886]\n",
      "[ Tue Dec  4 20:46:09 2018], epoch [9360], lr[0.00625000] ,loss[0.2303197235]\n",
      "[ Tue Dec  4 20:46:09 2018], validation: iter [9360], loss[0.2463477105]\n",
      "[ Tue Dec  4 20:46:10 2018], epoch [9380], lr[0.00625000] ,loss[0.2303177118]\n",
      "[ Tue Dec  4 20:46:10 2018], validation: iter [9380], loss[0.2463475764]\n",
      "[ Tue Dec  4 20:46:10 2018], epoch [9400], lr[0.00625000] ,loss[0.2303199321]\n",
      "[ Tue Dec  4 20:46:10 2018], validation: iter [9400], loss[0.2463488728]\n",
      "[ Tue Dec  4 20:46:11 2018], epoch [9420], lr[0.00625000] ,loss[0.2303220779]\n",
      "[ Tue Dec  4 20:46:11 2018], validation: iter [9420], loss[0.2463493794]\n",
      "[ Tue Dec  4 20:46:11 2018], epoch [9440], lr[0.00625000] ,loss[0.2303156704]\n",
      "[ Tue Dec  4 20:46:11 2018], validation: iter [9440], loss[0.2463486344]\n",
      "[ Tue Dec  4 20:46:12 2018], epoch [9460], lr[0.00625000] ,loss[0.2303138524]\n",
      "[ Tue Dec  4 20:46:12 2018], validation: iter [9460], loss[0.2463492900]\n",
      "[ Tue Dec  4 20:46:12 2018], epoch [9480], lr[0.00625000] ,loss[0.2303113043]\n",
      "[ Tue Dec  4 20:46:12 2018], validation: iter [9480], loss[0.2463490069]\n",
      "[ Tue Dec  4 20:46:13 2018], epoch [9500], lr[0.00625000] ,loss[0.2303118706]\n",
      "[ Tue Dec  4 20:46:13 2018], validation: iter [9500], loss[0.2463490665]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_9500']\n",
      "[ Tue Dec  4 20:46:13 2018], epoch [9520], lr[0.00625000] ,loss[0.2303112894]\n",
      "[ Tue Dec  4 20:46:13 2018], validation: iter [9520], loss[0.2463489771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 20:46:14 2018], epoch [9540], lr[0.00625000] ,loss[0.2303109318]\n",
      "[ Tue Dec  4 20:46:14 2018], validation: iter [9540], loss[0.2463488132]\n",
      "[ Tue Dec  4 20:46:14 2018], epoch [9560], lr[0.00625000] ,loss[0.2303118110]\n",
      "[ Tue Dec  4 20:46:14 2018], validation: iter [9560], loss[0.2463483810]\n",
      "[ Tue Dec  4 20:46:15 2018], epoch [9580], lr[0.00625000] ,loss[0.2303122282]\n",
      "[ Tue Dec  4 20:46:15 2018], validation: iter [9580], loss[0.2463481277]\n",
      "[ Tue Dec  4 20:46:15 2018], epoch [9600], lr[0.00625000] ,loss[0.2303121835]\n",
      "[ Tue Dec  4 20:46:15 2018], validation: iter [9600], loss[0.2463481575]\n",
      "[ Tue Dec  4 20:46:16 2018], epoch [9620], lr[0.00625000] ,loss[0.2303120494]\n",
      "[ Tue Dec  4 20:46:16 2018], validation: iter [9620], loss[0.2463483214]\n",
      "[ Tue Dec  4 20:46:16 2018], epoch [9640], lr[0.00625000] ,loss[0.2303106636]\n",
      "[ Tue Dec  4 20:46:16 2018], validation: iter [9640], loss[0.2463481873]\n",
      "[ Tue Dec  4 20:46:17 2018], epoch [9660], lr[0.00625000] ,loss[0.2303116173]\n",
      "[ Tue Dec  4 20:46:17 2018], validation: iter [9660], loss[0.2463480085]\n",
      "[ Tue Dec  4 20:46:17 2018], epoch [9680], lr[0.00625000] ,loss[0.2303121537]\n",
      "[ Tue Dec  4 20:46:17 2018], validation: iter [9680], loss[0.2463473976]\n",
      "[ Tue Dec  4 20:46:18 2018], epoch [9700], lr[0.00625000] ,loss[0.2303120792]\n",
      "[ Tue Dec  4 20:46:18 2018], validation: iter [9700], loss[0.2463474572]\n",
      "[ Tue Dec  4 20:46:18 2018], epoch [9720], lr[0.00625000] ,loss[0.2303120196]\n",
      "[ Tue Dec  4 20:46:18 2018], validation: iter [9720], loss[0.2463473082]\n",
      "[ Tue Dec  4 20:46:19 2018], epoch [9740], lr[0.00625000] ,loss[0.2303119451]\n",
      "[ Tue Dec  4 20:46:19 2018], validation: iter [9740], loss[0.2463471889]\n",
      "[ Tue Dec  4 20:46:19 2018], epoch [9760], lr[0.00625000] ,loss[0.2303119451]\n",
      "[ Tue Dec  4 20:46:19 2018], validation: iter [9760], loss[0.2463473082]\n",
      "[ Tue Dec  4 20:46:20 2018], epoch [9780], lr[0.00625000] ,loss[0.2303122282]\n",
      "[ Tue Dec  4 20:46:20 2018], validation: iter [9780], loss[0.2463475764]\n",
      "[ Tue Dec  4 20:46:21 2018], epoch [9800], lr[0.00625000] ,loss[0.2303130925]\n",
      "[ Tue Dec  4 20:46:21 2018], validation: iter [9800], loss[0.2463473380]\n",
      "[ Tue Dec  4 20:46:21 2018], epoch [9820], lr[0.00625000] ,loss[0.2303133458]\n",
      "[ Tue Dec  4 20:46:21 2018], validation: iter [9820], loss[0.2463470548]\n",
      "[ Tue Dec  4 20:46:22 2018], epoch [9840], lr[0.00625000] ,loss[0.2303149253]\n",
      "[ Tue Dec  4 20:46:22 2018], validation: iter [9840], loss[0.2463471144]\n",
      "[ Tue Dec  4 20:46:23 2018], epoch [9860], lr[0.00625000] ,loss[0.2303141952]\n",
      "[ Tue Dec  4 20:46:23 2018], validation: iter [9860], loss[0.2463469505]\n",
      "[ Tue Dec  4 20:46:24 2018], epoch [9880], lr[0.00625000] ,loss[0.2303150594]\n",
      "[ Tue Dec  4 20:46:24 2018], validation: iter [9880], loss[0.2463469505]\n",
      "[ Tue Dec  4 20:46:24 2018], epoch [9900], lr[0.00625000] ,loss[0.2303148657]\n",
      "[ Tue Dec  4 20:46:24 2018], validation: iter [9900], loss[0.2463468313]\n",
      "[ Tue Dec  4 20:46:25 2018], epoch [9920], lr[0.00625000] ,loss[0.2303150296]\n",
      "[ Tue Dec  4 20:46:25 2018], validation: iter [9920], loss[0.2463467717]\n",
      "[ Tue Dec  4 20:46:25 2018], epoch [9940], lr[0.00625000] ,loss[0.2303155512]\n",
      "[ Tue Dec  4 20:46:25 2018], validation: iter [9940], loss[0.2463467121]\n",
      "[ Tue Dec  4 20:46:26 2018], epoch [9960], lr[0.00625000] ,loss[0.2303154618]\n",
      "[ Tue Dec  4 20:46:26 2018], validation: iter [9960], loss[0.2463465035]\n",
      "[ Tue Dec  4 20:46:26 2018], epoch [9980], lr[0.00625000] ,loss[0.2303157598]\n",
      "[ Tue Dec  4 20:46:26 2018], validation: iter [9980], loss[0.2463461906]\n",
      "[ Tue Dec  4 20:46:27 2018], epoch [10000], lr[0.00625000] ,loss[0.2303157300]\n",
      "[ Tue Dec  4 20:46:27 2018], validation: iter [10000], loss[0.2463463247]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_10000']\n",
      "[ Tue Dec  4 20:46:28 2018], epoch [10020], lr[0.00312500] ,loss[0.2303144038]\n",
      "[ Tue Dec  4 20:46:28 2018], validation: iter [10020], loss[0.2463409305]\n",
      "[ Tue Dec  4 20:46:28 2018], epoch [10040], lr[0.00312500] ,loss[0.2303164899]\n",
      "[ Tue Dec  4 20:46:28 2018], validation: iter [10040], loss[0.2463521361]\n",
      "[ Tue Dec  4 20:46:29 2018], epoch [10060], lr[0.00312500] ,loss[0.2303261757]\n",
      "[ Tue Dec  4 20:46:29 2018], validation: iter [10060], loss[0.2463522851]\n",
      "[ Tue Dec  4 20:46:30 2018], epoch [10080], lr[0.00312500] ,loss[0.2303213477]\n",
      "[ Tue Dec  4 20:46:30 2018], validation: iter [10080], loss[0.2463480532]\n",
      "[ Tue Dec  4 20:46:31 2018], epoch [10100], lr[0.00312500] ,loss[0.2303152084]\n",
      "[ Tue Dec  4 20:46:31 2018], validation: iter [10100], loss[0.2463497221]\n",
      "[ Tue Dec  4 20:46:31 2018], epoch [10120], lr[0.00312500] ,loss[0.2303166091]\n",
      "[ Tue Dec  4 20:46:31 2018], validation: iter [10120], loss[0.2463496327]\n",
      "[ Tue Dec  4 20:46:32 2018], epoch [10140], lr[0.00312500] ,loss[0.2303168178]\n",
      "[ Tue Dec  4 20:46:32 2018], validation: iter [10140], loss[0.2463494092]\n",
      "[ Tue Dec  4 20:46:33 2018], epoch [10160], lr[0.00312500] ,loss[0.2303169072]\n",
      "[ Tue Dec  4 20:46:33 2018], validation: iter [10160], loss[0.2463494092]\n",
      "[ Tue Dec  4 20:46:34 2018], epoch [10180], lr[0.00312500] ,loss[0.2303170860]\n",
      "[ Tue Dec  4 20:46:34 2018], validation: iter [10180], loss[0.2463494539]\n",
      "[ Tue Dec  4 20:46:34 2018], epoch [10200], lr[0.00312500] ,loss[0.2303172499]\n",
      "[ Tue Dec  4 20:46:34 2018], validation: iter [10200], loss[0.2463498414]\n",
      "[ Tue Dec  4 20:46:35 2018], epoch [10220], lr[0.00312500] ,loss[0.2303172499]\n",
      "[ Tue Dec  4 20:46:35 2018], validation: iter [10220], loss[0.2463497221]\n",
      "[ Tue Dec  4 20:46:35 2018], epoch [10240], lr[0.00312500] ,loss[0.2303175032]\n",
      "[ Tue Dec  4 20:46:35 2018], validation: iter [10240], loss[0.2463498414]\n",
      "[ Tue Dec  4 20:46:36 2018], epoch [10260], lr[0.00312500] ,loss[0.2303174585]\n",
      "[ Tue Dec  4 20:46:36 2018], validation: iter [10260], loss[0.2463498265]\n",
      "[ Tue Dec  4 20:46:36 2018], epoch [10280], lr[0.00312500] ,loss[0.2303176373]\n",
      "[ Tue Dec  4 20:46:36 2018], validation: iter [10280], loss[0.2463504225]\n",
      "[ Tue Dec  4 20:46:37 2018], epoch [10300], lr[0.00312500] ,loss[0.2303178012]\n",
      "[ Tue Dec  4 20:46:37 2018], validation: iter [10300], loss[0.2463502288]\n",
      "[ Tue Dec  4 20:46:37 2018], epoch [10320], lr[0.00312500] ,loss[0.2303178757]\n",
      "[ Tue Dec  4 20:46:37 2018], validation: iter [10320], loss[0.2463501990]\n",
      "[ Tue Dec  4 20:46:38 2018], epoch [10340], lr[0.00312500] ,loss[0.2303182185]\n",
      "[ Tue Dec  4 20:46:38 2018], validation: iter [10340], loss[0.2463503331]\n",
      "[ Tue Dec  4 20:46:38 2018], epoch [10360], lr[0.00312500] ,loss[0.2303181887]\n",
      "[ Tue Dec  4 20:46:38 2018], validation: iter [10360], loss[0.2463504821]\n",
      "[ Tue Dec  4 20:46:39 2018], epoch [10380], lr[0.00312500] ,loss[0.2303167582]\n",
      "[ Tue Dec  4 20:46:39 2018], validation: iter [10380], loss[0.2463505864]\n",
      "[ Tue Dec  4 20:46:39 2018], epoch [10400], lr[0.00312500] ,loss[0.2303182930]\n",
      "[ Tue Dec  4 20:46:39 2018], validation: iter [10400], loss[0.2463506460]\n",
      "[ Tue Dec  4 20:46:40 2018], epoch [10420], lr[0.00312500] ,loss[0.2303170115]\n",
      "[ Tue Dec  4 20:46:40 2018], validation: iter [10420], loss[0.2463508546]\n",
      "[ Tue Dec  4 20:46:40 2018], epoch [10440], lr[0.00312500] ,loss[0.2303185016]\n",
      "[ Tue Dec  4 20:46:40 2018], validation: iter [10440], loss[0.2463512868]\n",
      "[ Tue Dec  4 20:46:41 2018], epoch [10460], lr[0.00312500] ,loss[0.2303187102]\n",
      "[ Tue Dec  4 20:46:41 2018], validation: iter [10460], loss[0.2463511676]\n",
      "[ Tue Dec  4 20:46:41 2018], epoch [10480], lr[0.00312500] ,loss[0.2303180248]\n",
      "[ Tue Dec  4 20:46:41 2018], validation: iter [10480], loss[0.2463512719]\n",
      "[ Tue Dec  4 20:46:42 2018], epoch [10500], lr[0.00312500] ,loss[0.2303172499]\n",
      "[ Tue Dec  4 20:46:42 2018], validation: iter [10500], loss[0.2463512272]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_10500']\n",
      "[ Tue Dec  4 20:46:42 2018], epoch [10520], lr[0.00312500] ,loss[0.2303173542]\n",
      "[ Tue Dec  4 20:46:42 2018], validation: iter [10520], loss[0.2463509738]\n",
      "[ Tue Dec  4 20:46:43 2018], epoch [10540], lr[0.00312500] ,loss[0.2303189188]\n",
      "[ Tue Dec  4 20:46:43 2018], validation: iter [10540], loss[0.2463511080]\n",
      "[ Tue Dec  4 20:46:43 2018], epoch [10560], lr[0.00312500] ,loss[0.2303191274]\n",
      "[ Tue Dec  4 20:46:43 2018], validation: iter [10560], loss[0.2463511676]\n",
      "[ Tue Dec  4 20:46:44 2018], epoch [10580], lr[0.00312500] ,loss[0.2303173542]\n",
      "[ Tue Dec  4 20:46:44 2018], validation: iter [10580], loss[0.2463515401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 20:46:44 2018], epoch [10600], lr[0.00312500] ,loss[0.2303173989]\n",
      "[ Tue Dec  4 20:46:44 2018], validation: iter [10600], loss[0.2463510484]\n",
      "[ Tue Dec  4 20:46:45 2018], epoch [10620], lr[0.00312500] ,loss[0.2303175330]\n",
      "[ Tue Dec  4 20:46:45 2018], validation: iter [10620], loss[0.2463512868]\n",
      "[ Tue Dec  4 20:46:45 2018], epoch [10640], lr[0.00312500] ,loss[0.2303175628]\n",
      "[ Tue Dec  4 20:46:45 2018], validation: iter [10640], loss[0.2463512868]\n",
      "[ Tue Dec  4 20:46:46 2018], epoch [10660], lr[0.00312500] ,loss[0.2303193063]\n",
      "[ Tue Dec  4 20:46:46 2018], validation: iter [10660], loss[0.2463512868]\n",
      "[ Tue Dec  4 20:46:46 2018], epoch [10680], lr[0.00312500] ,loss[0.2303193063]\n",
      "[ Tue Dec  4 20:46:46 2018], validation: iter [10680], loss[0.2463517934]\n",
      "[ Tue Dec  4 20:46:47 2018], epoch [10700], lr[0.00312500] ,loss[0.2303176522]\n",
      "[ Tue Dec  4 20:46:47 2018], validation: iter [10700], loss[0.2463515997]\n",
      "[ Tue Dec  4 20:46:47 2018], epoch [10720], lr[0.00312500] ,loss[0.2303178012]\n",
      "[ Tue Dec  4 20:46:47 2018], validation: iter [10720], loss[0.2463516593]\n",
      "[ Tue Dec  4 20:46:48 2018], epoch [10740], lr[0.00312500] ,loss[0.2303193957]\n",
      "[ Tue Dec  4 20:46:48 2018], validation: iter [10740], loss[0.2463516146]\n",
      "[ Tue Dec  4 20:46:48 2018], epoch [10760], lr[0.00312500] ,loss[0.2303178757]\n",
      "[ Tue Dec  4 20:46:48 2018], validation: iter [10760], loss[0.2463514507]\n",
      "[ Tue Dec  4 20:46:49 2018], epoch [10780], lr[0.00312500] ,loss[0.2303193957]\n",
      "[ Tue Dec  4 20:46:49 2018], validation: iter [10780], loss[0.2463515699]\n",
      "[ Tue Dec  4 20:46:49 2018], epoch [10800], lr[0.00312500] ,loss[0.2303194106]\n",
      "[ Tue Dec  4 20:46:49 2018], validation: iter [10800], loss[0.2463515103]\n",
      "[ Tue Dec  4 20:46:49 2018], epoch [10820], lr[0.00312500] ,loss[0.2303179502]\n",
      "[ Tue Dec  4 20:46:49 2018], validation: iter [10820], loss[0.2463515699]\n",
      "[ Tue Dec  4 20:46:50 2018], epoch [10840], lr[0.00312500] ,loss[0.2303194404]\n",
      "[ Tue Dec  4 20:46:50 2018], validation: iter [10840], loss[0.2463517636]\n",
      "[ Tue Dec  4 20:46:50 2018], epoch [10860], lr[0.00312500] ,loss[0.2303178310]\n",
      "[ Tue Dec  4 20:46:50 2018], validation: iter [10860], loss[0.2463519126]\n",
      "[ Tue Dec  4 20:46:51 2018], epoch [10880], lr[0.00312500] ,loss[0.2303194851]\n",
      "[ Tue Dec  4 20:46:51 2018], validation: iter [10880], loss[0.2463517040]\n",
      "[ Tue Dec  4 20:46:51 2018], epoch [10900], lr[0.00312500] ,loss[0.2303194553]\n",
      "[ Tue Dec  4 20:46:51 2018], validation: iter [10900], loss[0.2463518381]\n",
      "[ Tue Dec  4 20:46:52 2018], epoch [10920], lr[0.00312500] ,loss[0.2303189635]\n",
      "[ Tue Dec  4 20:46:52 2018], validation: iter [10920], loss[0.2463519275]\n",
      "[ Tue Dec  4 20:46:52 2018], epoch [10940], lr[0.00312500] ,loss[0.2303181738]\n",
      "[ Tue Dec  4 20:46:52 2018], validation: iter [10940], loss[0.2463522404]\n",
      "[ Tue Dec  4 20:46:53 2018], epoch [10960], lr[0.00312500] ,loss[0.2303179204]\n",
      "[ Tue Dec  4 20:46:53 2018], validation: iter [10960], loss[0.2463523448]\n",
      "[ Tue Dec  4 20:46:53 2018], epoch [10980], lr[0.00312500] ,loss[0.2303196192]\n",
      "[ Tue Dec  4 20:46:53 2018], validation: iter [10980], loss[0.2463518381]\n",
      "[ Tue Dec  4 20:46:54 2018], epoch [11000], lr[0.00312500] ,loss[0.2303182781]\n",
      "[ Tue Dec  4 20:46:54 2018], validation: iter [11000], loss[0.2463522851]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_11000']\n",
      "[ Tue Dec  4 20:46:55 2018], epoch [11020], lr[0.00312500] ,loss[0.2303179055]\n",
      "[ Tue Dec  4 20:46:55 2018], validation: iter [11020], loss[0.2463518530]\n",
      "[ Tue Dec  4 20:46:55 2018], epoch [11040], lr[0.00312500] ,loss[0.2303180844]\n",
      "[ Tue Dec  4 20:46:55 2018], validation: iter [11040], loss[0.2463514060]\n",
      "[ Tue Dec  4 20:46:55 2018], epoch [11060], lr[0.00312500] ,loss[0.2303179651]\n",
      "[ Tue Dec  4 20:46:55 2018], validation: iter [11060], loss[0.2463521659]\n",
      "[ Tue Dec  4 20:46:56 2018], epoch [11080], lr[0.00312500] ,loss[0.2303195149]\n",
      "[ Tue Dec  4 20:46:56 2018], validation: iter [11080], loss[0.2463521361]\n",
      "[ Tue Dec  4 20:46:56 2018], epoch [11100], lr[0.00312500] ,loss[0.2303180844]\n",
      "[ Tue Dec  4 20:46:56 2018], validation: iter [11100], loss[0.2463521808]\n",
      "[ Tue Dec  4 20:46:57 2018], epoch [11120], lr[0.00312500] ,loss[0.2303186059]\n",
      "[ Tue Dec  4 20:46:57 2018], validation: iter [11120], loss[0.2463521361]\n",
      "[ Tue Dec  4 20:46:57 2018], epoch [11140], lr[0.00312500] ,loss[0.2303180844]\n",
      "[ Tue Dec  4 20:46:57 2018], validation: iter [11140], loss[0.2463521510]\n",
      "[ Tue Dec  4 20:46:58 2018], epoch [11160], lr[0.00312500] ,loss[0.2303195149]\n",
      "[ Tue Dec  4 20:46:58 2018], validation: iter [11160], loss[0.2463520169]\n",
      "[ Tue Dec  4 20:46:58 2018], epoch [11180], lr[0.00312500] ,loss[0.2303180248]\n",
      "[ Tue Dec  4 20:46:58 2018], validation: iter [11180], loss[0.2463524342]\n",
      "[ Tue Dec  4 20:46:59 2018], epoch [11200], lr[0.00312500] ,loss[0.2303179801]\n",
      "[ Tue Dec  4 20:46:59 2018], validation: iter [11200], loss[0.2463520467]\n",
      "[ Tue Dec  4 20:46:59 2018], epoch [11220], lr[0.00312500] ,loss[0.2303193063]\n",
      "[ Tue Dec  4 20:46:59 2018], validation: iter [11220], loss[0.2463520169]\n",
      "[ Tue Dec  4 20:47:00 2018], epoch [11240], lr[0.00312500] ,loss[0.2303180546]\n",
      "[ Tue Dec  4 20:47:00 2018], validation: iter [11240], loss[0.2463522702]\n",
      "[ Tue Dec  4 20:47:00 2018], epoch [11260], lr[0.00312500] ,loss[0.2303180844]\n",
      "[ Tue Dec  4 20:47:00 2018], validation: iter [11260], loss[0.2463521063]\n",
      "[ Tue Dec  4 20:47:01 2018], epoch [11280], lr[0.00312500] ,loss[0.2303180248]\n",
      "[ Tue Dec  4 20:47:01 2018], validation: iter [11280], loss[0.2463522106]\n",
      "[ Tue Dec  4 20:47:01 2018], epoch [11300], lr[0.00312500] ,loss[0.2303181291]\n",
      "[ Tue Dec  4 20:47:01 2018], validation: iter [11300], loss[0.2463524193]\n",
      "[ Tue Dec  4 20:47:02 2018], epoch [11320], lr[0.00312500] ,loss[0.2303180546]\n",
      "[ Tue Dec  4 20:47:02 2018], validation: iter [11320], loss[0.2463521808]\n",
      "[ Tue Dec  4 20:47:02 2018], epoch [11340], lr[0.00312500] ,loss[0.2303179055]\n",
      "[ Tue Dec  4 20:47:02 2018], validation: iter [11340], loss[0.2463522851]\n",
      "[ Tue Dec  4 20:47:03 2018], epoch [11360], lr[0.00312500] ,loss[0.2303192019]\n",
      "[ Tue Dec  4 20:47:03 2018], validation: iter [11360], loss[0.2463517040]\n",
      "[ Tue Dec  4 20:47:03 2018], epoch [11380], lr[0.00312500] ,loss[0.2303176224]\n",
      "[ Tue Dec  4 20:47:03 2018], validation: iter [11380], loss[0.2463518530]\n",
      "[ Tue Dec  4 20:47:04 2018], epoch [11400], lr[0.00312500] ,loss[0.2303178459]\n",
      "[ Tue Dec  4 20:47:04 2018], validation: iter [11400], loss[0.2463519871]\n",
      "[ Tue Dec  4 20:47:04 2018], epoch [11420], lr[0.00312500] ,loss[0.2303177416]\n",
      "[ Tue Dec  4 20:47:04 2018], validation: iter [11420], loss[0.2463521659]\n",
      "[ Tue Dec  4 20:47:05 2018], epoch [11440], lr[0.00312500] ,loss[0.2303179204]\n",
      "[ Tue Dec  4 20:47:05 2018], validation: iter [11440], loss[0.2463524938]\n",
      "[ Tue Dec  4 20:47:05 2018], epoch [11460], lr[0.00312500] ,loss[0.2303177267]\n",
      "[ Tue Dec  4 20:47:05 2018], validation: iter [11460], loss[0.2463517934]\n",
      "[ Tue Dec  4 20:47:06 2018], epoch [11480], lr[0.00312500] ,loss[0.2303185463]\n",
      "[ Tue Dec  4 20:47:06 2018], validation: iter [11480], loss[0.2463519573]\n",
      "[ Tue Dec  4 20:47:06 2018], epoch [11500], lr[0.00312500] ,loss[0.2303197682]\n",
      "[ Tue Dec  4 20:47:06 2018], validation: iter [11500], loss[0.2463519871]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_11500']\n",
      "[ Tue Dec  4 20:47:07 2018], epoch [11520], lr[0.00312500] ,loss[0.2303205431]\n",
      "[ Tue Dec  4 20:47:07 2018], validation: iter [11520], loss[0.2463518679]\n",
      "[ Tue Dec  4 20:47:07 2018], epoch [11540], lr[0.00312500] ,loss[0.2303260416]\n",
      "[ Tue Dec  4 20:47:07 2018], validation: iter [11540], loss[0.2463515997]\n",
      "[ Tue Dec  4 20:47:08 2018], epoch [11560], lr[0.00312500] ,loss[0.2303215265]\n",
      "[ Tue Dec  4 20:47:08 2018], validation: iter [11560], loss[0.2463471740]\n",
      "[ Tue Dec  4 20:47:09 2018], epoch [11580], lr[0.00312500] ,loss[0.2303092331]\n",
      "[ Tue Dec  4 20:47:09 2018], validation: iter [11580], loss[0.2463358194]\n",
      "[ Tue Dec  4 20:47:09 2018], epoch [11600], lr[0.00312500] ,loss[0.2303330600]\n",
      "[ Tue Dec  4 20:47:09 2018], validation: iter [11600], loss[0.2463525385]\n",
      "[ Tue Dec  4 20:47:10 2018], epoch [11620], lr[0.00312500] ,loss[0.2303472608]\n",
      "[ Tue Dec  4 20:47:10 2018], validation: iter [11620], loss[0.2463418692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 20:47:10 2018], epoch [11640], lr[0.00312500] ,loss[0.2303250581]\n",
      "[ Tue Dec  4 20:47:10 2018], validation: iter [11640], loss[0.2463489026]\n",
      "[ Tue Dec  4 20:47:11 2018], epoch [11660], lr[0.00312500] ,loss[0.2303135693]\n",
      "[ Tue Dec  4 20:47:11 2018], validation: iter [11660], loss[0.2463384420]\n",
      "[ Tue Dec  4 20:47:11 2018], epoch [11680], lr[0.00312500] ,loss[0.2303230017]\n",
      "[ Tue Dec  4 20:47:11 2018], validation: iter [11680], loss[0.2463548481]\n",
      "[ Tue Dec  4 20:47:12 2018], epoch [11700], lr[0.00312500] ,loss[0.2303130180]\n",
      "[ Tue Dec  4 20:47:12 2018], validation: iter [11700], loss[0.2463527769]\n",
      "[ Tue Dec  4 20:47:12 2018], epoch [11720], lr[0.00312500] ,loss[0.2303255200]\n",
      "[ Tue Dec  4 20:47:12 2018], validation: iter [11720], loss[0.2463397086]\n",
      "[ Tue Dec  4 20:47:12 2018], epoch [11740], lr[0.00312500] ,loss[0.2303200066]\n",
      "[ Tue Dec  4 20:47:12 2018], validation: iter [11740], loss[0.2463527769]\n",
      "[ Tue Dec  4 20:47:13 2018], epoch [11760], lr[0.00312500] ,loss[0.2303290218]\n",
      "[ Tue Dec  4 20:47:13 2018], validation: iter [11760], loss[0.2463454306]\n",
      "[ Tue Dec  4 20:47:13 2018], epoch [11780], lr[0.00312500] ,loss[0.2303266674]\n",
      "[ Tue Dec  4 20:47:13 2018], validation: iter [11780], loss[0.2463497669]\n",
      "[ Tue Dec  4 20:47:14 2018], epoch [11800], lr[0.00312500] ,loss[0.2303266674]\n",
      "[ Tue Dec  4 20:47:14 2018], validation: iter [11800], loss[0.2463420480]\n",
      "[ Tue Dec  4 20:47:14 2018], epoch [11820], lr[0.00312500] ,loss[0.2303104848]\n",
      "[ Tue Dec  4 20:47:14 2018], validation: iter [11820], loss[0.2463405430]\n",
      "[ Tue Dec  4 20:47:15 2018], epoch [11840], lr[0.00312500] ,loss[0.2303118110]\n",
      "[ Tue Dec  4 20:47:15 2018], validation: iter [11840], loss[0.2463569194]\n",
      "[ Tue Dec  4 20:47:15 2018], epoch [11860], lr[0.00312500] ,loss[0.2303191721]\n",
      "[ Tue Dec  4 20:47:15 2018], validation: iter [11860], loss[0.2463583350]\n",
      "[ Tue Dec  4 20:47:16 2018], epoch [11880], lr[0.00312500] ,loss[0.2303121835]\n",
      "[ Tue Dec  4 20:47:16 2018], validation: iter [11880], loss[0.2463373393]\n",
      "[ Tue Dec  4 20:47:16 2018], epoch [11900], lr[0.00312500] ,loss[0.2303271741]\n",
      "[ Tue Dec  4 20:47:16 2018], validation: iter [11900], loss[0.2463501990]\n",
      "[ Tue Dec  4 20:47:17 2018], epoch [11920], lr[0.00312500] ,loss[0.2303072214]\n",
      "[ Tue Dec  4 20:47:17 2018], validation: iter [11920], loss[0.2463394850]\n",
      "[ Tue Dec  4 20:47:18 2018], epoch [11940], lr[0.00312500] ,loss[0.2303157151]\n",
      "[ Tue Dec  4 20:47:18 2018], validation: iter [11940], loss[0.2463490218]\n",
      "[ Tue Dec  4 20:47:18 2018], epoch [11960], lr[0.00312500] ,loss[0.2303082645]\n",
      "[ Tue Dec  4 20:47:18 2018], validation: iter [11960], loss[0.2463591397]\n",
      "[ Tue Dec  4 20:47:18 2018], epoch [11980], lr[0.00312500] ,loss[0.2303130031]\n",
      "[ Tue Dec  4 20:47:18 2018], validation: iter [11980], loss[0.2463539094]\n",
      "[ Tue Dec  4 20:47:19 2018], epoch [12000], lr[0.00312500] ,loss[0.2303129584]\n",
      "[ Tue Dec  4 20:47:19 2018], validation: iter [12000], loss[0.2463375777]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_12000']\n",
      "[ Tue Dec  4 20:47:20 2018], epoch [12020], lr[0.00156250] ,loss[0.2303230017]\n",
      "[ Tue Dec  4 20:47:20 2018], validation: iter [12020], loss[0.2463564873]\n",
      "[ Tue Dec  4 20:47:20 2018], epoch [12040], lr[0.00156250] ,loss[0.2303218991]\n",
      "[ Tue Dec  4 20:47:20 2018], validation: iter [12040], loss[0.2463509887]\n",
      "[ Tue Dec  4 20:47:21 2018], epoch [12060], lr[0.00156250] ,loss[0.2303168029]\n",
      "[ Tue Dec  4 20:47:21 2018], validation: iter [12060], loss[0.2463494986]\n",
      "[ Tue Dec  4 20:47:21 2018], epoch [12080], lr[0.00156250] ,loss[0.2303179055]\n",
      "[ Tue Dec  4 20:47:21 2018], validation: iter [12080], loss[0.2463508248]\n",
      "[ Tue Dec  4 20:47:22 2018], epoch [12100], lr[0.00156250] ,loss[0.2303161174]\n",
      "[ Tue Dec  4 20:47:22 2018], validation: iter [12100], loss[0.2463504076]\n",
      "[ Tue Dec  4 20:47:22 2018], epoch [12120], lr[0.00156250] ,loss[0.2303147614]\n",
      "[ Tue Dec  4 20:47:22 2018], validation: iter [12120], loss[0.2463509589]\n",
      "[ Tue Dec  4 20:47:23 2018], epoch [12140], lr[0.00156250] ,loss[0.2303152084]\n",
      "[ Tue Dec  4 20:47:23 2018], validation: iter [12140], loss[0.2463506609]\n",
      "[ Tue Dec  4 20:47:23 2018], epoch [12160], lr[0.00156250] ,loss[0.2303152084]\n",
      "[ Tue Dec  4 20:47:23 2018], validation: iter [12160], loss[0.2463512868]\n",
      "[ Tue Dec  4 20:47:24 2018], epoch [12180], lr[0.00156250] ,loss[0.2303156406]\n",
      "[ Tue Dec  4 20:47:24 2018], validation: iter [12180], loss[0.2463514805]\n",
      "[ Tue Dec  4 20:47:25 2018], epoch [12200], lr[0.00156250] ,loss[0.2303154916]\n",
      "[ Tue Dec  4 20:47:25 2018], validation: iter [12200], loss[0.2463517189]\n",
      "[ Tue Dec  4 20:47:25 2018], epoch [12220], lr[0.00156250] ,loss[0.2303156555]\n",
      "[ Tue Dec  4 20:47:25 2018], validation: iter [12220], loss[0.2463516444]\n",
      "[ Tue Dec  4 20:47:26 2018], epoch [12240], lr[0.00156250] ,loss[0.2303157300]\n",
      "[ Tue Dec  4 20:47:26 2018], validation: iter [12240], loss[0.2463517040]\n",
      "[ Tue Dec  4 20:47:26 2018], epoch [12260], lr[0.00156250] ,loss[0.2303159088]\n",
      "[ Tue Dec  4 20:47:26 2018], validation: iter [12260], loss[0.2463517189]\n",
      "[ Tue Dec  4 20:47:27 2018], epoch [12280], lr[0.00156250] ,loss[0.2303159237]\n",
      "[ Tue Dec  4 20:47:27 2018], validation: iter [12280], loss[0.2463519126]\n",
      "[ Tue Dec  4 20:47:27 2018], epoch [12300], lr[0.00156250] ,loss[0.2303161621]\n",
      "[ Tue Dec  4 20:47:27 2018], validation: iter [12300], loss[0.2463513911]\n",
      "[ Tue Dec  4 20:47:28 2018], epoch [12320], lr[0.00156250] ,loss[0.2303160429]\n",
      "[ Tue Dec  4 20:47:28 2018], validation: iter [12320], loss[0.2463519573]\n",
      "[ Tue Dec  4 20:47:28 2018], epoch [12340], lr[0.00156250] ,loss[0.2303163856]\n",
      "[ Tue Dec  4 20:47:28 2018], validation: iter [12340], loss[0.2463516742]\n",
      "[ Tue Dec  4 20:47:29 2018], epoch [12360], lr[0.00156250] ,loss[0.2303162217]\n",
      "[ Tue Dec  4 20:47:29 2018], validation: iter [12360], loss[0.2463520318]\n",
      "[ Tue Dec  4 20:47:29 2018], epoch [12380], lr[0.00156250] ,loss[0.2303162217]\n",
      "[ Tue Dec  4 20:47:29 2018], validation: iter [12380], loss[0.2463519871]\n",
      "[ Tue Dec  4 20:47:30 2018], epoch [12400], lr[0.00156250] ,loss[0.2303164899]\n",
      "[ Tue Dec  4 20:47:30 2018], validation: iter [12400], loss[0.2463517934]\n",
      "[ Tue Dec  4 20:47:30 2018], epoch [12420], lr[0.00156250] ,loss[0.2303165644]\n",
      "[ Tue Dec  4 20:47:30 2018], validation: iter [12420], loss[0.2463519126]\n",
      "[ Tue Dec  4 20:47:31 2018], epoch [12440], lr[0.00156250] ,loss[0.2303164601]\n",
      "[ Tue Dec  4 20:47:31 2018], validation: iter [12440], loss[0.2463523448]\n",
      "[ Tue Dec  4 20:47:31 2018], epoch [12460], lr[0.00156250] ,loss[0.2303167731]\n",
      "[ Tue Dec  4 20:47:31 2018], validation: iter [12460], loss[0.2463518977]\n",
      "[ Tue Dec  4 20:47:32 2018], epoch [12480], lr[0.00156250] ,loss[0.2303165495]\n",
      "[ Tue Dec  4 20:47:32 2018], validation: iter [12480], loss[0.2463520318]\n",
      "[ Tue Dec  4 20:47:32 2018], epoch [12500], lr[0.00156250] ,loss[0.2303166389]\n",
      "[ Tue Dec  4 20:47:32 2018], validation: iter [12500], loss[0.2463520318]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_12500']\n",
      "[ Tue Dec  4 20:47:33 2018], epoch [12520], lr[0.00156250] ,loss[0.2303168774]\n",
      "[ Tue Dec  4 20:47:33 2018], validation: iter [12520], loss[0.2463519275]\n",
      "[ Tue Dec  4 20:47:34 2018], epoch [12540], lr[0.00156250] ,loss[0.2303168029]\n",
      "[ Tue Dec  4 20:47:34 2018], validation: iter [12540], loss[0.2463522255]\n",
      "[ Tue Dec  4 20:47:34 2018], epoch [12560], lr[0.00156250] ,loss[0.2303168029]\n",
      "[ Tue Dec  4 20:47:34 2018], validation: iter [12560], loss[0.2463524193]\n",
      "[ Tue Dec  4 20:47:35 2018], epoch [12580], lr[0.00156250] ,loss[0.2303169072]\n",
      "[ Tue Dec  4 20:47:35 2018], validation: iter [12580], loss[0.2463522702]\n",
      "[ Tue Dec  4 20:47:35 2018], epoch [12600], lr[0.00156250] ,loss[0.2303168625]\n",
      "[ Tue Dec  4 20:47:35 2018], validation: iter [12600], loss[0.2463524193]\n",
      "[ Tue Dec  4 20:47:36 2018], epoch [12620], lr[0.00156250] ,loss[0.2303168029]\n",
      "[ Tue Dec  4 20:47:36 2018], validation: iter [12620], loss[0.2463524193]\n",
      "[ Tue Dec  4 20:47:36 2018], epoch [12640], lr[0.00156250] ,loss[0.2303169072]\n",
      "[ Tue Dec  4 20:47:36 2018], validation: iter [12640], loss[0.2463520318]\n",
      "[ Tue Dec  4 20:47:37 2018], epoch [12660], lr[0.00156250] ,loss[0.2303169519]\n",
      "[ Tue Dec  4 20:47:37 2018], validation: iter [12660], loss[0.2463523597]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 20:47:37 2018], epoch [12680], lr[0.00156250] ,loss[0.2303169519]\n",
      "[ Tue Dec  4 20:47:37 2018], validation: iter [12680], loss[0.2463527322]\n",
      "[ Tue Dec  4 20:47:38 2018], epoch [12700], lr[0.00156250] ,loss[0.2303169072]\n",
      "[ Tue Dec  4 20:47:38 2018], validation: iter [12700], loss[0.2463529259]\n",
      "[ Tue Dec  4 20:47:38 2018], epoch [12720], lr[0.00156250] ,loss[0.2303169519]\n",
      "[ Tue Dec  4 20:47:38 2018], validation: iter [12720], loss[0.2463525832]\n",
      "[ Tue Dec  4 20:47:39 2018], epoch [12740], lr[0.00156250] ,loss[0.2303168476]\n",
      "[ Tue Dec  4 20:47:39 2018], validation: iter [12740], loss[0.2463523448]\n",
      "[ Tue Dec  4 20:47:39 2018], epoch [12760], lr[0.00156250] ,loss[0.2303169072]\n",
      "[ Tue Dec  4 20:47:39 2018], validation: iter [12760], loss[0.2463523597]\n",
      "[ Tue Dec  4 20:47:40 2018], epoch [12780], lr[0.00156250] ,loss[0.2303171456]\n",
      "[ Tue Dec  4 20:47:40 2018], validation: iter [12780], loss[0.2463521808]\n",
      "[ Tue Dec  4 20:47:40 2018], epoch [12800], lr[0.00156250] ,loss[0.2303169221]\n",
      "[ Tue Dec  4 20:47:40 2018], validation: iter [12800], loss[0.2463528067]\n",
      "[ Tue Dec  4 20:47:41 2018], epoch [12820], lr[0.00156250] ,loss[0.2303170860]\n",
      "[ Tue Dec  4 20:47:41 2018], validation: iter [12820], loss[0.2463525385]\n",
      "[ Tue Dec  4 20:47:41 2018], epoch [12840], lr[0.00156250] ,loss[0.2303163558]\n",
      "[ Tue Dec  4 20:47:41 2018], validation: iter [12840], loss[0.2463526130]\n",
      "[ Tue Dec  4 20:47:42 2018], epoch [12860], lr[0.00156250] ,loss[0.2303164303]\n",
      "[ Tue Dec  4 20:47:42 2018], validation: iter [12860], loss[0.2463523597]\n",
      "[ Tue Dec  4 20:47:42 2018], epoch [12880], lr[0.00156250] ,loss[0.2303164601]\n",
      "[ Tue Dec  4 20:47:42 2018], validation: iter [12880], loss[0.2463524640]\n",
      "[ Tue Dec  4 20:47:43 2018], epoch [12900], lr[0.00156250] ,loss[0.2303169072]\n",
      "[ Tue Dec  4 20:47:43 2018], validation: iter [12900], loss[0.2463530898]\n",
      "[ Tue Dec  4 20:47:43 2018], epoch [12920], lr[0.00156250] ,loss[0.2303164303]\n",
      "[ Tue Dec  4 20:47:43 2018], validation: iter [12920], loss[0.2463524640]\n",
      "[ Tue Dec  4 20:47:44 2018], epoch [12940], lr[0.00156250] ,loss[0.2303165048]\n",
      "[ Tue Dec  4 20:47:44 2018], validation: iter [12940], loss[0.2463530451]\n",
      "[ Tue Dec  4 20:47:44 2018], epoch [12960], lr[0.00156250] ,loss[0.2303164899]\n",
      "[ Tue Dec  4 20:47:44 2018], validation: iter [12960], loss[0.2463524640]\n",
      "[ Tue Dec  4 20:47:45 2018], epoch [12980], lr[0.00156250] ,loss[0.2303162664]\n",
      "[ Tue Dec  4 20:47:45 2018], validation: iter [12980], loss[0.2463531792]\n",
      "[ Tue Dec  4 20:47:45 2018], epoch [13000], lr[0.00156250] ,loss[0.2303163409]\n",
      "[ Tue Dec  4 20:47:45 2018], validation: iter [13000], loss[0.2463520765]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_13000']\n",
      "[ Tue Dec  4 20:47:46 2018], epoch [13020], lr[0.00156250] ,loss[0.2303169072]\n",
      "[ Tue Dec  4 20:47:46 2018], validation: iter [13020], loss[0.2463526726]\n",
      "[ Tue Dec  4 20:47:46 2018], epoch [13040], lr[0.00156250] ,loss[0.2303170711]\n",
      "[ Tue Dec  4 20:47:46 2018], validation: iter [13040], loss[0.2463523448]\n",
      "[ Tue Dec  4 20:47:47 2018], epoch [13060], lr[0.00156250] ,loss[0.2303170264]\n",
      "[ Tue Dec  4 20:47:47 2018], validation: iter [13060], loss[0.2463523000]\n",
      "[ Tue Dec  4 20:47:47 2018], epoch [13080], lr[0.00156250] ,loss[0.2303164303]\n",
      "[ Tue Dec  4 20:47:47 2018], validation: iter [13080], loss[0.2463526577]\n",
      "[ Tue Dec  4 20:47:48 2018], epoch [13100], lr[0.00156250] ,loss[0.2303167433]\n",
      "[ Tue Dec  4 20:47:48 2018], validation: iter [13100], loss[0.2463523597]\n",
      "[ Tue Dec  4 20:47:48 2018], epoch [13120], lr[0.00156250] ,loss[0.2303163260]\n",
      "[ Tue Dec  4 20:47:48 2018], validation: iter [13120], loss[0.2463527024]\n",
      "[ Tue Dec  4 20:47:49 2018], epoch [13140], lr[0.00156250] ,loss[0.2303163260]\n",
      "[ Tue Dec  4 20:47:49 2018], validation: iter [13140], loss[0.2463522702]\n",
      "[ Tue Dec  4 20:47:49 2018], epoch [13160], lr[0.00156250] ,loss[0.2303169519]\n",
      "[ Tue Dec  4 20:47:49 2018], validation: iter [13160], loss[0.2463525981]\n",
      "[ Tue Dec  4 20:47:50 2018], epoch [13180], lr[0.00156250] ,loss[0.2303162962]\n",
      "[ Tue Dec  4 20:47:50 2018], validation: iter [13180], loss[0.2463528961]\n",
      "[ Tue Dec  4 20:47:50 2018], epoch [13200], lr[0.00156250] ,loss[0.2303163260]\n",
      "[ Tue Dec  4 20:47:50 2018], validation: iter [13200], loss[0.2463527918]\n",
      "[ Tue Dec  4 20:47:51 2018], epoch [13220], lr[0.00156250] ,loss[0.2303168029]\n",
      "[ Tue Dec  4 20:47:51 2018], validation: iter [13220], loss[0.2463527322]\n",
      "[ Tue Dec  4 20:47:51 2018], epoch [13240], lr[0.00156250] ,loss[0.2303175330]\n",
      "[ Tue Dec  4 20:47:51 2018], validation: iter [13240], loss[0.2463524342]\n",
      "[ Tue Dec  4 20:47:52 2018], epoch [13260], lr[0.00156250] ,loss[0.2303174138]\n",
      "[ Tue Dec  4 20:47:52 2018], validation: iter [13260], loss[0.2463528514]\n",
      "[ Tue Dec  4 20:47:52 2018], epoch [13280], lr[0.00156250] ,loss[0.2303164750]\n",
      "[ Tue Dec  4 20:47:52 2018], validation: iter [13280], loss[0.2463527769]\n",
      "[ Tue Dec  4 20:47:53 2018], epoch [13300], lr[0.00156250] ,loss[0.2303160876]\n",
      "[ Tue Dec  4 20:47:53 2018], validation: iter [13300], loss[0.2463524640]\n",
      "[ Tue Dec  4 20:47:53 2018], epoch [13320], lr[0.00156250] ,loss[0.2303167880]\n",
      "[ Tue Dec  4 20:47:53 2018], validation: iter [13320], loss[0.2463525385]\n",
      "[ Tue Dec  4 20:47:54 2018], epoch [13340], lr[0.00156250] ,loss[0.2303164452]\n",
      "[ Tue Dec  4 20:47:54 2018], validation: iter [13340], loss[0.2463526577]\n",
      "[ Tue Dec  4 20:47:54 2018], epoch [13360], lr[0.00156250] ,loss[0.2303163409]\n",
      "[ Tue Dec  4 20:47:54 2018], validation: iter [13360], loss[0.2463518530]\n",
      "[ Tue Dec  4 20:47:55 2018], epoch [13380], lr[0.00156250] ,loss[0.2303212136]\n",
      "[ Tue Dec  4 20:47:55 2018], validation: iter [13380], loss[0.2463521510]\n",
      "[ Tue Dec  4 20:47:55 2018], epoch [13400], lr[0.00156250] ,loss[0.2303201407]\n",
      "[ Tue Dec  4 20:47:55 2018], validation: iter [13400], loss[0.2463518232]\n",
      "[ Tue Dec  4 20:47:56 2018], epoch [13420], lr[0.00156250] ,loss[0.2303171009]\n",
      "[ Tue Dec  4 20:47:56 2018], validation: iter [13420], loss[0.2463446707]\n",
      "[ Tue Dec  4 20:47:56 2018], epoch [13440], lr[0.00156250] ,loss[0.2303339988]\n",
      "[ Tue Dec  4 20:47:56 2018], validation: iter [13440], loss[0.2463500202]\n",
      "[ Tue Dec  4 20:47:57 2018], epoch [13460], lr[0.00156250] ,loss[0.2303175330]\n",
      "[ Tue Dec  4 20:47:57 2018], validation: iter [13460], loss[0.2463444918]\n",
      "[ Tue Dec  4 20:47:57 2018], epoch [13480], lr[0.00156250] ,loss[0.2303106934]\n",
      "[ Tue Dec  4 20:47:57 2018], validation: iter [13480], loss[0.2463563830]\n",
      "[ Tue Dec  4 20:47:58 2018], epoch [13500], lr[0.00156250] ,loss[0.2303135991]\n",
      "[ Tue Dec  4 20:47:58 2018], validation: iter [13500], loss[0.2463410199]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_13500']\n",
      "[ Tue Dec  4 20:47:58 2018], epoch [13520], lr[0.00156250] ,loss[0.2303179204]\n",
      "[ Tue Dec  4 20:47:58 2018], validation: iter [13520], loss[0.2463589013]\n",
      "[ Tue Dec  4 20:47:59 2018], epoch [13540], lr[0.00156250] ,loss[0.2303082496]\n",
      "[ Tue Dec  4 20:47:59 2018], validation: iter [13540], loss[0.2463512868]\n",
      "[ Tue Dec  4 20:47:59 2018], epoch [13560], lr[0.00156250] ,loss[0.2303283364]\n",
      "[ Tue Dec  4 20:47:59 2018], validation: iter [13560], loss[0.2463446259]\n",
      "[ Tue Dec  4 20:48:00 2018], epoch [13580], lr[0.00156250] ,loss[0.2303243428]\n",
      "[ Tue Dec  4 20:48:00 2018], validation: iter [13580], loss[0.2463534325]\n",
      "[ Tue Dec  4 20:48:00 2018], epoch [13600], lr[0.00156250] ,loss[0.2303088754]\n",
      "[ Tue Dec  4 20:48:00 2018], validation: iter [13600], loss[0.2463493347]\n",
      "[ Tue Dec  4 20:48:01 2018], epoch [13620], lr[0.00156250] ,loss[0.2303232104]\n",
      "[ Tue Dec  4 20:48:01 2018], validation: iter [13620], loss[0.2463449091]\n",
      "[ Tue Dec  4 20:48:01 2018], epoch [13640], lr[0.00156250] ,loss[0.2303234786]\n",
      "[ Tue Dec  4 20:48:01 2018], validation: iter [13640], loss[0.2463531196]\n",
      "[ Tue Dec  4 20:48:02 2018], epoch [13660], lr[0.00156250] ,loss[0.2303060591]\n",
      "[ Tue Dec  4 20:48:02 2018], validation: iter [13660], loss[0.2463486344]\n",
      "[ Tue Dec  4 20:48:02 2018], epoch [13680], lr[0.00156250] ,loss[0.2303244770]\n",
      "[ Tue Dec  4 20:48:02 2018], validation: iter [13680], loss[0.2463448793]\n",
      "[ Tue Dec  4 20:48:03 2018], epoch [13700], lr[0.00156250] ,loss[0.2303248793]\n",
      "[ Tue Dec  4 20:48:03 2018], validation: iter [13700], loss[0.2463532686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 20:48:03 2018], epoch [13720], lr[0.00156250] ,loss[0.2303110212]\n",
      "[ Tue Dec  4 20:48:03 2018], validation: iter [13720], loss[0.2463490963]\n",
      "[ Tue Dec  4 20:48:04 2018], epoch [13740], lr[0.00156250] ,loss[0.2303236425]\n",
      "[ Tue Dec  4 20:48:04 2018], validation: iter [13740], loss[0.2463454455]\n",
      "[ Tue Dec  4 20:48:04 2018], epoch [13760], lr[0.00156250] ,loss[0.2303232253]\n",
      "[ Tue Dec  4 20:48:04 2018], validation: iter [13760], loss[0.2463521808]\n",
      "[ Tue Dec  4 20:48:05 2018], epoch [13780], lr[0.00156250] ,loss[0.2303101867]\n",
      "[ Tue Dec  4 20:48:05 2018], validation: iter [13780], loss[0.2463489324]\n",
      "[ Tue Dec  4 20:48:05 2018], epoch [13800], lr[0.00156250] ,loss[0.2303221673]\n",
      "[ Tue Dec  4 20:48:05 2018], validation: iter [13800], loss[0.2463456094]\n",
      "[ Tue Dec  4 20:48:06 2018], epoch [13820], lr[0.00156250] ,loss[0.2303232700]\n",
      "[ Tue Dec  4 20:48:06 2018], validation: iter [13820], loss[0.2463524342]\n",
      "[ Tue Dec  4 20:48:06 2018], epoch [13840], lr[0.00156250] ,loss[0.2303130925]\n",
      "[ Tue Dec  4 20:48:06 2018], validation: iter [13840], loss[0.2463489771]\n",
      "[ Tue Dec  4 20:48:07 2018], epoch [13860], lr[0.00156250] ,loss[0.2303206921]\n",
      "[ Tue Dec  4 20:48:07 2018], validation: iter [13860], loss[0.2463459969]\n",
      "[ Tue Dec  4 20:48:07 2018], epoch [13880], lr[0.00156250] ,loss[0.2303247601]\n",
      "[ Tue Dec  4 20:48:07 2018], validation: iter [13880], loss[0.2463523448]\n",
      "[ Tue Dec  4 20:48:08 2018], epoch [13900], lr[0.00156250] ,loss[0.2303139865]\n",
      "[ Tue Dec  4 20:48:08 2018], validation: iter [13900], loss[0.2463489771]\n",
      "[ Tue Dec  4 20:48:08 2018], epoch [13920], lr[0.00156250] ,loss[0.2303187996]\n",
      "[ Tue Dec  4 20:48:08 2018], validation: iter [13920], loss[0.2463460118]\n",
      "[ Tue Dec  4 20:48:09 2018], epoch [13940], lr[0.00156250] ,loss[0.2303233892]\n",
      "[ Tue Dec  4 20:48:09 2018], validation: iter [13940], loss[0.2463524342]\n",
      "[ Tue Dec  4 20:48:09 2018], epoch [13960], lr[0.00156250] ,loss[0.2303130180]\n",
      "[ Tue Dec  4 20:48:09 2018], validation: iter [13960], loss[0.2463489771]\n",
      "[ Tue Dec  4 20:48:10 2018], epoch [13980], lr[0.00156250] ,loss[0.2303196490]\n",
      "[ Tue Dec  4 20:48:10 2018], validation: iter [13980], loss[0.2463461310]\n",
      "[ Tue Dec  4 20:48:10 2018], epoch [14000], lr[0.00156250] ,loss[0.2303231955]\n",
      "[ Tue Dec  4 20:48:10 2018], validation: iter [14000], loss[0.2463521063]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_14000']\n",
      "[ Tue Dec  4 20:48:11 2018], epoch [14020], lr[0.00078125] ,loss[0.2303184718]\n",
      "[ Tue Dec  4 20:48:11 2018], validation: iter [14020], loss[0.2463537902]\n",
      "[ Tue Dec  4 20:48:11 2018], epoch [14040], lr[0.00078125] ,loss[0.2303173095]\n",
      "[ Tue Dec  4 20:48:11 2018], validation: iter [14040], loss[0.2463518679]\n",
      "[ Tue Dec  4 20:48:12 2018], epoch [14060], lr[0.00078125] ,loss[0.2303142548]\n",
      "[ Tue Dec  4 20:48:12 2018], validation: iter [14060], loss[0.2463518679]\n",
      "[ Tue Dec  4 20:48:12 2018], epoch [14080], lr[0.00078125] ,loss[0.2303143442]\n",
      "[ Tue Dec  4 20:48:12 2018], validation: iter [14080], loss[0.2463515103]\n",
      "[ Tue Dec  4 20:48:13 2018], epoch [14100], lr[0.00078125] ,loss[0.2303138077]\n",
      "[ Tue Dec  4 20:48:13 2018], validation: iter [14100], loss[0.2463524193]\n",
      "[ Tue Dec  4 20:48:13 2018], epoch [14120], lr[0.00078125] ,loss[0.2303144783]\n",
      "[ Tue Dec  4 20:48:13 2018], validation: iter [14120], loss[0.2463524789]\n",
      "[ Tue Dec  4 20:48:14 2018], epoch [14140], lr[0.00078125] ,loss[0.2303145826]\n",
      "[ Tue Dec  4 20:48:14 2018], validation: iter [14140], loss[0.2463521808]\n",
      "[ Tue Dec  4 20:48:14 2018], epoch [14160], lr[0.00078125] ,loss[0.2303141356]\n",
      "[ Tue Dec  4 20:48:14 2018], validation: iter [14160], loss[0.2463523000]\n",
      "[ Tue Dec  4 20:48:15 2018], epoch [14180], lr[0.00078125] ,loss[0.2303147912]\n",
      "[ Tue Dec  4 20:48:15 2018], validation: iter [14180], loss[0.2463524044]\n",
      "[ Tue Dec  4 20:48:15 2018], epoch [14200], lr[0.00078125] ,loss[0.2303145081]\n",
      "[ Tue Dec  4 20:48:15 2018], validation: iter [14200], loss[0.2463524640]\n",
      "[ Tue Dec  4 20:48:16 2018], epoch [14220], lr[0.00078125] ,loss[0.2303149700]\n",
      "[ Tue Dec  4 20:48:16 2018], validation: iter [14220], loss[0.2463520467]\n",
      "[ Tue Dec  4 20:48:16 2018], epoch [14240], lr[0.00078125] ,loss[0.2303149551]\n",
      "[ Tue Dec  4 20:48:16 2018], validation: iter [14240], loss[0.2463527769]\n",
      "[ Tue Dec  4 20:48:17 2018], epoch [14260], lr[0.00078125] ,loss[0.2303151041]\n",
      "[ Tue Dec  4 20:48:17 2018], validation: iter [14260], loss[0.2463524789]\n",
      "[ Tue Dec  4 20:48:17 2018], epoch [14280], lr[0.00078125] ,loss[0.2303146124]\n",
      "[ Tue Dec  4 20:48:17 2018], validation: iter [14280], loss[0.2463526130]\n",
      "[ Tue Dec  4 20:48:18 2018], epoch [14300], lr[0.00078125] ,loss[0.2303147167]\n",
      "[ Tue Dec  4 20:48:18 2018], validation: iter [14300], loss[0.2463528514]\n",
      "[ Tue Dec  4 20:48:18 2018], epoch [14320], lr[0.00078125] ,loss[0.2303150147]\n",
      "[ Tue Dec  4 20:48:18 2018], validation: iter [14320], loss[0.2463526577]\n",
      "[ Tue Dec  4 20:48:19 2018], epoch [14340], lr[0.00078125] ,loss[0.2303148210]\n",
      "[ Tue Dec  4 20:48:19 2018], validation: iter [14340], loss[0.2463529259]\n",
      "[ Tue Dec  4 20:48:19 2018], epoch [14360], lr[0.00078125] ,loss[0.2303148657]\n",
      "[ Tue Dec  4 20:48:19 2018], validation: iter [14360], loss[0.2463529855]\n",
      "[ Tue Dec  4 20:48:20 2018], epoch [14380], lr[0.00078125] ,loss[0.2303150147]\n",
      "[ Tue Dec  4 20:48:20 2018], validation: iter [14380], loss[0.2463529557]\n",
      "[ Tue Dec  4 20:48:20 2018], epoch [14400], lr[0.00078125] ,loss[0.2303149998]\n",
      "[ Tue Dec  4 20:48:20 2018], validation: iter [14400], loss[0.2463530004]\n",
      "[ Tue Dec  4 20:48:21 2018], epoch [14420], lr[0.00078125] ,loss[0.2303150296]\n",
      "[ Tue Dec  4 20:48:21 2018], validation: iter [14420], loss[0.2463532388]\n",
      "[ Tue Dec  4 20:48:21 2018], epoch [14440], lr[0.00078125] ,loss[0.2303151488]\n",
      "[ Tue Dec  4 20:48:21 2018], validation: iter [14440], loss[0.2463528961]\n",
      "[ Tue Dec  4 20:48:22 2018], epoch [14460], lr[0.00078125] ,loss[0.2303151786]\n",
      "[ Tue Dec  4 20:48:22 2018], validation: iter [14460], loss[0.2463533133]\n",
      "[ Tue Dec  4 20:48:22 2018], epoch [14480], lr[0.00078125] ,loss[0.2303152382]\n",
      "[ Tue Dec  4 20:48:22 2018], validation: iter [14480], loss[0.2463532388]\n",
      "[ Tue Dec  4 20:48:23 2018], epoch [14500], lr[0.00078125] ,loss[0.2303153127]\n",
      "[ Tue Dec  4 20:48:23 2018], validation: iter [14500], loss[0.2463528067]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_14500']\n",
      "[ Tue Dec  4 20:48:23 2018], epoch [14520], lr[0.00078125] ,loss[0.2303159237]\n",
      "[ Tue Dec  4 20:48:23 2018], validation: iter [14520], loss[0.2463527322]\n",
      "[ Tue Dec  4 20:48:24 2018], epoch [14540], lr[0.00078125] ,loss[0.2303165793]\n",
      "[ Tue Dec  4 20:48:24 2018], validation: iter [14540], loss[0.2463530898]\n",
      "[ Tue Dec  4 20:48:24 2018], epoch [14560], lr[0.00078125] ,loss[0.2303159833]\n",
      "[ Tue Dec  4 20:48:24 2018], validation: iter [14560], loss[0.2463536114]\n",
      "[ Tue Dec  4 20:48:25 2018], epoch [14580], lr[0.00078125] ,loss[0.2303160429]\n",
      "[ Tue Dec  4 20:48:25 2018], validation: iter [14580], loss[0.2463532835]\n",
      "[ Tue Dec  4 20:48:25 2018], epoch [14600], lr[0.00078125] ,loss[0.2303160131]\n",
      "[ Tue Dec  4 20:48:25 2018], validation: iter [14600], loss[0.2463535517]\n",
      "[ Tue Dec  4 20:48:26 2018], epoch [14620], lr[0.00078125] ,loss[0.2303160727]\n",
      "[ Tue Dec  4 20:48:26 2018], validation: iter [14620], loss[0.2463535368]\n",
      "[ Tue Dec  4 20:48:26 2018], epoch [14640], lr[0.00078125] ,loss[0.2303155661]\n",
      "[ Tue Dec  4 20:48:26 2018], validation: iter [14640], loss[0.2463537306]\n",
      "[ Tue Dec  4 20:48:27 2018], epoch [14660], lr[0.00078125] ,loss[0.2303161472]\n",
      "[ Tue Dec  4 20:48:27 2018], validation: iter [14660], loss[0.2463534325]\n",
      "[ Tue Dec  4 20:48:27 2018], epoch [14680], lr[0.00078125] ,loss[0.2303162217]\n",
      "[ Tue Dec  4 20:48:27 2018], validation: iter [14680], loss[0.2463534623]\n",
      "[ Tue Dec  4 20:48:28 2018], epoch [14700], lr[0.00078125] ,loss[0.2303161770]\n",
      "[ Tue Dec  4 20:48:28 2018], validation: iter [14700], loss[0.2463538796]\n",
      "[ Tue Dec  4 20:48:28 2018], epoch [14720], lr[0.00078125] ,loss[0.2303163558]\n",
      "[ Tue Dec  4 20:48:28 2018], validation: iter [14720], loss[0.2463537455]\n",
      "[ Tue Dec  4 20:48:29 2018], epoch [14740], lr[0.00078125] ,loss[0.2303167731]\n",
      "[ Tue Dec  4 20:48:29 2018], validation: iter [14740], loss[0.2463538796]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 20:48:30 2018], epoch [14760], lr[0.00078125] ,loss[0.2303157300]\n",
      "[ Tue Dec  4 20:48:30 2018], validation: iter [14760], loss[0.2463532388]\n",
      "[ Tue Dec  4 20:48:30 2018], epoch [14780], lr[0.00078125] ,loss[0.2303163856]\n",
      "[ Tue Dec  4 20:48:30 2018], validation: iter [14780], loss[0.2463539690]\n",
      "[ Tue Dec  4 20:48:31 2018], epoch [14800], lr[0.00078125] ,loss[0.2303162813]\n",
      "[ Tue Dec  4 20:48:31 2018], validation: iter [14800], loss[0.2463540435]\n",
      "[ Tue Dec  4 20:48:31 2018], epoch [14820], lr[0.00078125] ,loss[0.2303163707]\n",
      "[ Tue Dec  4 20:48:31 2018], validation: iter [14820], loss[0.2463531643]\n",
      "[ Tue Dec  4 20:48:32 2018], epoch [14840], lr[0.00078125] ,loss[0.2303163856]\n",
      "[ Tue Dec  4 20:48:32 2018], validation: iter [14840], loss[0.2463541031]\n",
      "[ Tue Dec  4 20:48:32 2018], epoch [14860], lr[0.00078125] ,loss[0.2303163260]\n",
      "[ Tue Dec  4 20:48:32 2018], validation: iter [14860], loss[0.2463534027]\n",
      "[ Tue Dec  4 20:48:33 2018], epoch [14880], lr[0.00078125] ,loss[0.2303163558]\n",
      "[ Tue Dec  4 20:48:33 2018], validation: iter [14880], loss[0.2463539094]\n",
      "[ Tue Dec  4 20:48:33 2018], epoch [14900], lr[0.00078125] ,loss[0.2303164005]\n",
      "[ Tue Dec  4 20:48:33 2018], validation: iter [14900], loss[0.2463540286]\n",
      "[ Tue Dec  4 20:48:34 2018], epoch [14920], lr[0.00078125] ,loss[0.2303164303]\n",
      "[ Tue Dec  4 20:48:34 2018], validation: iter [14920], loss[0.2463536263]\n",
      "[ Tue Dec  4 20:48:34 2018], epoch [14940], lr[0.00078125] ,loss[0.2303164750]\n",
      "[ Tue Dec  4 20:48:34 2018], validation: iter [14940], loss[0.2463539392]\n",
      "[ Tue Dec  4 20:48:35 2018], epoch [14960], lr[0.00078125] ,loss[0.2303163856]\n",
      "[ Tue Dec  4 20:48:35 2018], validation: iter [14960], loss[0.2463535815]\n",
      "[ Tue Dec  4 20:48:35 2018], epoch [14980], lr[0.00078125] ,loss[0.2303163856]\n",
      "[ Tue Dec  4 20:48:35 2018], validation: iter [14980], loss[0.2463542223]\n",
      "[ Tue Dec  4 20:48:36 2018], epoch [15000], lr[0.00078125] ,loss[0.2303165048]\n",
      "[ Tue Dec  4 20:48:36 2018], validation: iter [15000], loss[0.2463539988]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_15000']\n",
      "[ Tue Dec  4 20:48:36 2018], epoch [15020], lr[0.00078125] ,loss[0.2303163856]\n",
      "[ Tue Dec  4 20:48:36 2018], validation: iter [15020], loss[0.2463542521]\n",
      "[ Tue Dec  4 20:48:37 2018], epoch [15040], lr[0.00078125] ,loss[0.2303164899]\n",
      "[ Tue Dec  4 20:48:37 2018], validation: iter [15040], loss[0.2463539094]\n",
      "[ Tue Dec  4 20:48:38 2018], epoch [15060], lr[0.00078125] ,loss[0.2303166389]\n",
      "[ Tue Dec  4 20:48:38 2018], validation: iter [15060], loss[0.2463540286]\n",
      "[ Tue Dec  4 20:48:38 2018], epoch [15080], lr[0.00078125] ,loss[0.2303164899]\n",
      "[ Tue Dec  4 20:48:38 2018], validation: iter [15080], loss[0.2463540435]\n",
      "[ Tue Dec  4 20:48:39 2018], epoch [15100], lr[0.00078125] ,loss[0.2303164601]\n",
      "[ Tue Dec  4 20:48:39 2018], validation: iter [15100], loss[0.2463535964]\n",
      "[ Tue Dec  4 20:48:39 2018], epoch [15120], lr[0.00078125] ,loss[0.2303163707]\n",
      "[ Tue Dec  4 20:48:39 2018], validation: iter [15120], loss[0.2463541776]\n",
      "[ Tue Dec  4 20:48:40 2018], epoch [15140], lr[0.00078125] ,loss[0.2303161472]\n",
      "[ Tue Dec  4 20:48:40 2018], validation: iter [15140], loss[0.2463542521]\n",
      "[ Tue Dec  4 20:48:40 2018], epoch [15160], lr[0.00078125] ,loss[0.2303164005]\n",
      "[ Tue Dec  4 20:48:40 2018], validation: iter [15160], loss[0.2463539094]\n",
      "[ Tue Dec  4 20:48:41 2018], epoch [15180], lr[0.00078125] ,loss[0.2303162515]\n",
      "[ Tue Dec  4 20:48:41 2018], validation: iter [15180], loss[0.2463541776]\n",
      "[ Tue Dec  4 20:48:41 2018], epoch [15200], lr[0.00078125] ,loss[0.2303159386]\n",
      "[ Tue Dec  4 20:48:41 2018], validation: iter [15200], loss[0.2463542968]\n",
      "[ Tue Dec  4 20:48:42 2018], epoch [15220], lr[0.00078125] ,loss[0.2303164899]\n",
      "[ Tue Dec  4 20:48:42 2018], validation: iter [15220], loss[0.2463537455]\n",
      "[ Tue Dec  4 20:48:42 2018], epoch [15240], lr[0.00078125] ,loss[0.2303162813]\n",
      "[ Tue Dec  4 20:48:42 2018], validation: iter [15240], loss[0.2463541478]\n",
      "[ Tue Dec  4 20:48:43 2018], epoch [15260], lr[0.00078125] ,loss[0.2303164750]\n",
      "[ Tue Dec  4 20:48:43 2018], validation: iter [15260], loss[0.2463539094]\n",
      "[ Tue Dec  4 20:48:43 2018], epoch [15280], lr[0.00078125] ,loss[0.2303169519]\n",
      "[ Tue Dec  4 20:48:43 2018], validation: iter [15280], loss[0.2463538051]\n",
      "[ Tue Dec  4 20:48:44 2018], epoch [15300], lr[0.00078125] ,loss[0.2303166837]\n",
      "[ Tue Dec  4 20:48:44 2018], validation: iter [15300], loss[0.2463538647]\n",
      "[ Tue Dec  4 20:48:45 2018], epoch [15320], lr[0.00078125] ,loss[0.2303164303]\n",
      "[ Tue Dec  4 20:48:45 2018], validation: iter [15320], loss[0.2463545650]\n",
      "[ Tue Dec  4 20:48:45 2018], epoch [15340], lr[0.00078125] ,loss[0.2303161621]\n",
      "[ Tue Dec  4 20:48:45 2018], validation: iter [15340], loss[0.2463544160]\n",
      "[ Tue Dec  4 20:48:46 2018], epoch [15360], lr[0.00078125] ,loss[0.2303163856]\n",
      "[ Tue Dec  4 20:48:46 2018], validation: iter [15360], loss[0.2463542223]\n",
      "[ Tue Dec  4 20:48:46 2018], epoch [15380], lr[0.00078125] ,loss[0.2303167731]\n",
      "[ Tue Dec  4 20:48:46 2018], validation: iter [15380], loss[0.2463542223]\n",
      "[ Tue Dec  4 20:48:47 2018], epoch [15400], lr[0.00078125] ,loss[0.2303157598]\n",
      "[ Tue Dec  4 20:48:47 2018], validation: iter [15400], loss[0.2463539988]\n",
      "[ Tue Dec  4 20:48:47 2018], epoch [15420], lr[0.00078125] ,loss[0.2303199321]\n",
      "[ Tue Dec  4 20:48:47 2018], validation: iter [15420], loss[0.2463538051]\n",
      "[ Tue Dec  4 20:48:48 2018], epoch [15440], lr[0.00078125] ,loss[0.2303202152]\n",
      "[ Tue Dec  4 20:48:48 2018], validation: iter [15440], loss[0.2463535964]\n",
      "[ Tue Dec  4 20:48:48 2018], epoch [15460], lr[0.00078125] ,loss[0.2303206474]\n",
      "[ Tue Dec  4 20:48:48 2018], validation: iter [15460], loss[0.2463538349]\n",
      "[ Tue Dec  4 20:48:49 2018], epoch [15480], lr[0.00078125] ,loss[0.2303204238]\n",
      "[ Tue Dec  4 20:48:49 2018], validation: iter [15480], loss[0.2463535517]\n",
      "[ Tue Dec  4 20:48:49 2018], epoch [15500], lr[0.00078125] ,loss[0.2303219736]\n",
      "[ Tue Dec  4 20:48:49 2018], validation: iter [15500], loss[0.2463534325]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_15500']\n",
      "[ Tue Dec  4 20:48:50 2018], epoch [15520], lr[0.00078125] ,loss[0.2303192765]\n",
      "[ Tue Dec  4 20:48:50 2018], validation: iter [15520], loss[0.2463537902]\n",
      "[ Tue Dec  4 20:48:50 2018], epoch [15540], lr[0.00078125] ,loss[0.2303153872]\n",
      "[ Tue Dec  4 20:48:50 2018], validation: iter [15540], loss[0.2463541478]\n",
      "[ Tue Dec  4 20:48:51 2018], epoch [15560], lr[0.00078125] ,loss[0.2303165346]\n",
      "[ Tue Dec  4 20:48:51 2018], validation: iter [15560], loss[0.2463536710]\n",
      "[ Tue Dec  4 20:48:52 2018], epoch [15580], lr[0.00078125] ,loss[0.2303252220]\n",
      "[ Tue Dec  4 20:48:52 2018], validation: iter [15580], loss[0.2463528514]\n",
      "[ Tue Dec  4 20:48:52 2018], epoch [15600], lr[0.00078125] ,loss[0.2303214520]\n",
      "[ Tue Dec  4 20:48:52 2018], validation: iter [15600], loss[0.2463532388]\n",
      "[ Tue Dec  4 20:48:53 2018], epoch [15620], lr[0.00078125] ,loss[0.2303164005]\n",
      "[ Tue Dec  4 20:48:53 2018], validation: iter [15620], loss[0.2463535964]\n",
      "[ Tue Dec  4 20:48:53 2018], epoch [15640], lr[0.00078125] ,loss[0.2303186804]\n",
      "[ Tue Dec  4 20:48:53 2018], validation: iter [15640], loss[0.2463535964]\n",
      "[ Tue Dec  4 20:48:54 2018], epoch [15660], lr[0.00078125] ,loss[0.2303176373]\n",
      "[ Tue Dec  4 20:48:54 2018], validation: iter [15660], loss[0.2463533431]\n",
      "[ Tue Dec  4 20:48:54 2018], epoch [15680], lr[0.00078125] ,loss[0.2303204238]\n",
      "[ Tue Dec  4 20:48:54 2018], validation: iter [15680], loss[0.2463534027]\n",
      "[ Tue Dec  4 20:48:55 2018], epoch [15700], lr[0.00078125] ,loss[0.2303260118]\n",
      "[ Tue Dec  4 20:48:55 2018], validation: iter [15700], loss[0.2463534027]\n",
      "[ Tue Dec  4 20:48:55 2018], epoch [15720], lr[0.00078125] ,loss[0.2303196043]\n",
      "[ Tue Dec  4 20:48:55 2018], validation: iter [15720], loss[0.2463532090]\n",
      "[ Tue Dec  4 20:48:56 2018], epoch [15740], lr[0.00078125] ,loss[0.2303219289]\n",
      "[ Tue Dec  4 20:48:56 2018], validation: iter [15740], loss[0.2463528961]\n",
      "[ Tue Dec  4 20:48:56 2018], epoch [15760], lr[0.00078125] ,loss[0.2303220034]\n",
      "[ Tue Dec  4 20:48:56 2018], validation: iter [15760], loss[0.2463531494]\n",
      "[ Tue Dec  4 20:48:57 2018], epoch [15780], lr[0.00078125] ,loss[0.2303197980]\n",
      "[ Tue Dec  4 20:48:57 2018], validation: iter [15780], loss[0.2463525534]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 20:48:57 2018], epoch [15800], lr[0.00078125] ,loss[0.2303145379]\n",
      "[ Tue Dec  4 20:48:57 2018], validation: iter [15800], loss[0.2463523895]\n",
      "[ Tue Dec  4 20:48:58 2018], epoch [15820], lr[0.00078125] ,loss[0.2303172499]\n",
      "[ Tue Dec  4 20:48:58 2018], validation: iter [15820], loss[0.2463513613]\n",
      "[ Tue Dec  4 20:48:58 2018], epoch [15840], lr[0.00078125] ,loss[0.2303149998]\n",
      "[ Tue Dec  4 20:48:58 2018], validation: iter [15840], loss[0.2463507801]\n",
      "[ Tue Dec  4 20:48:59 2018], epoch [15860], lr[0.00078125] ,loss[0.2303135693]\n",
      "[ Tue Dec  4 20:48:59 2018], validation: iter [15860], loss[0.2463501543]\n",
      "[ Tue Dec  4 20:48:59 2018], epoch [15880], lr[0.00078125] ,loss[0.2303135395]\n",
      "[ Tue Dec  4 20:48:59 2018], validation: iter [15880], loss[0.2463496476]\n",
      "[ Tue Dec  4 20:49:00 2018], epoch [15900], lr[0.00078125] ,loss[0.2303120792]\n",
      "[ Tue Dec  4 20:49:00 2018], validation: iter [15900], loss[0.2463494986]\n",
      "[ Tue Dec  4 20:49:00 2018], epoch [15920], lr[0.00078125] ,loss[0.2303106636]\n",
      "[ Tue Dec  4 20:49:00 2018], validation: iter [15920], loss[0.2463483661]\n",
      "[ Tue Dec  4 20:49:01 2018], epoch [15940], lr[0.00078125] ,loss[0.2303128541]\n",
      "[ Tue Dec  4 20:49:01 2018], validation: iter [15940], loss[0.2463471293]\n",
      "[ Tue Dec  4 20:49:01 2018], epoch [15960], lr[0.00078125] ,loss[0.2303110361]\n",
      "[ Tue Dec  4 20:49:01 2018], validation: iter [15960], loss[0.2463467419]\n",
      "[ Tue Dec  4 20:49:02 2018], epoch [15980], lr[0.00078125] ,loss[0.2303179801]\n",
      "[ Tue Dec  4 20:49:02 2018], validation: iter [15980], loss[0.2463475019]\n",
      "[ Tue Dec  4 20:49:02 2018], epoch [16000], lr[0.00078125] ,loss[0.2303179801]\n",
      "[ Tue Dec  4 20:49:02 2018], validation: iter [16000], loss[0.2463462949]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_16000']\n",
      "[ Tue Dec  4 20:49:03 2018], epoch [16020], lr[0.00039063] ,loss[0.2303094417]\n",
      "[ Tue Dec  4 20:49:03 2018], validation: iter [16020], loss[0.2463469952]\n",
      "[ Tue Dec  4 20:49:04 2018], epoch [16040], lr[0.00039063] ,loss[0.2303123325]\n",
      "[ Tue Dec  4 20:49:04 2018], validation: iter [16040], loss[0.2463462055]\n",
      "[ Tue Dec  4 20:49:04 2018], epoch [16060], lr[0.00039063] ,loss[0.2303117514]\n",
      "[ Tue Dec  4 20:49:04 2018], validation: iter [16060], loss[0.2463457435]\n",
      "[ Tue Dec  4 20:49:05 2018], epoch [16080], lr[0.00039063] ,loss[0.2303111106]\n",
      "[ Tue Dec  4 20:49:05 2018], validation: iter [16080], loss[0.2463454753]\n",
      "[ Tue Dec  4 20:49:05 2018], epoch [16100], lr[0.00039063] ,loss[0.2303108573]\n",
      "[ Tue Dec  4 20:49:05 2018], validation: iter [16100], loss[0.2463453859]\n",
      "[ Tue Dec  4 20:49:06 2018], epoch [16120], lr[0.00039063] ,loss[0.2303098887]\n",
      "[ Tue Dec  4 20:49:06 2018], validation: iter [16120], loss[0.2463452369]\n",
      "[ Tue Dec  4 20:49:06 2018], epoch [16140], lr[0.00039063] ,loss[0.2303099930]\n",
      "[ Tue Dec  4 20:49:06 2018], validation: iter [16140], loss[0.2463451922]\n",
      "[ Tue Dec  4 20:49:07 2018], epoch [16160], lr[0.00039063] ,loss[0.2303099781]\n",
      "[ Tue Dec  4 20:49:07 2018], validation: iter [16160], loss[0.2463446856]\n",
      "[ Tue Dec  4 20:49:07 2018], epoch [16180], lr[0.00039063] ,loss[0.2303079516]\n",
      "[ Tue Dec  4 20:49:07 2018], validation: iter [16180], loss[0.2463447303]\n",
      "[ Tue Dec  4 20:49:08 2018], epoch [16200], lr[0.00039063] ,loss[0.2303091735]\n",
      "[ Tue Dec  4 20:49:08 2018], validation: iter [16200], loss[0.2463437170]\n",
      "[ Tue Dec  4 20:49:08 2018], epoch [16220], lr[0.00039063] ,loss[0.2303094268]\n",
      "[ Tue Dec  4 20:49:08 2018], validation: iter [16220], loss[0.2463439107]\n",
      "[ Tue Dec  4 20:49:09 2018], epoch [16240], lr[0.00039063] ,loss[0.2303089201]\n",
      "[ Tue Dec  4 20:49:09 2018], validation: iter [16240], loss[0.2463443577]\n",
      "[ Tue Dec  4 20:49:09 2018], epoch [16260], lr[0.00039063] ,loss[0.2303070128]\n",
      "[ Tue Dec  4 20:49:09 2018], validation: iter [16260], loss[0.2463436723]\n",
      "[ Tue Dec  4 20:49:10 2018], epoch [16280], lr[0.00039063] ,loss[0.2303093821]\n",
      "[ Tue Dec  4 20:49:10 2018], validation: iter [16280], loss[0.2463436276]\n",
      "[ Tue Dec  4 20:49:10 2018], epoch [16300], lr[0.00039063] ,loss[0.2303096503]\n",
      "[ Tue Dec  4 20:49:10 2018], validation: iter [16300], loss[0.2463437468]\n",
      "[ Tue Dec  4 20:49:11 2018], epoch [16320], lr[0.00039063] ,loss[0.2303056568]\n",
      "[ Tue Dec  4 20:49:11 2018], validation: iter [16320], loss[0.2463435531]\n",
      "[ Tue Dec  4 20:49:11 2018], epoch [16340], lr[0.00039063] ,loss[0.2303073853]\n",
      "[ Tue Dec  4 20:49:11 2018], validation: iter [16340], loss[0.2463432848]\n",
      "[ Tue Dec  4 20:49:12 2018], epoch [16360], lr[0.00039063] ,loss[0.2303053886]\n",
      "[ Tue Dec  4 20:49:12 2018], validation: iter [16360], loss[0.2463428080]\n",
      "[ Tue Dec  4 20:49:12 2018], epoch [16380], lr[0.00039063] ,loss[0.2303066999]\n",
      "[ Tue Dec  4 20:49:12 2018], validation: iter [16380], loss[0.2463423759]\n",
      "[ Tue Dec  4 20:49:13 2018], epoch [16400], lr[0.00039063] ,loss[0.2303053886]\n",
      "[ Tue Dec  4 20:49:13 2018], validation: iter [16400], loss[0.2463422269]\n",
      "[ Tue Dec  4 20:49:13 2018], epoch [16420], lr[0.00039063] ,loss[0.2303049415]\n",
      "[ Tue Dec  4 20:49:13 2018], validation: iter [16420], loss[0.2463423610]\n",
      "[ Tue Dec  4 20:49:14 2018], epoch [16440], lr[0.00039063] ,loss[0.2303047180]\n",
      "[ Tue Dec  4 20:49:14 2018], validation: iter [16440], loss[0.2463430315]\n",
      "[ Tue Dec  4 20:49:14 2018], epoch [16460], lr[0.00039063] ,loss[0.2303050011]\n",
      "[ Tue Dec  4 20:49:14 2018], validation: iter [16460], loss[0.2463430613]\n",
      "[ Tue Dec  4 20:49:15 2018], epoch [16480], lr[0.00039063] ,loss[0.2303051353]\n",
      "[ Tue Dec  4 20:49:15 2018], validation: iter [16480], loss[0.2463423312]\n",
      "[ Tue Dec  4 20:49:15 2018], epoch [16500], lr[0.00039063] ,loss[0.2303032875]\n",
      "[ Tue Dec  4 20:49:15 2018], validation: iter [16500], loss[0.2463420331]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_16500']\n",
      "[ Tue Dec  4 20:49:16 2018], epoch [16520], lr[0.00039063] ,loss[0.2303033024]\n",
      "[ Tue Dec  4 20:49:16 2018], validation: iter [16520], loss[0.2463418692]\n",
      "[ Tue Dec  4 20:49:17 2018], epoch [16540], lr[0.00039063] ,loss[0.2303044051]\n",
      "[ Tue Dec  4 20:49:17 2018], validation: iter [16540], loss[0.2463417202]\n",
      "[ Tue Dec  4 20:49:17 2018], epoch [16560], lr[0.00039063] ,loss[0.2303030938]\n",
      "[ Tue Dec  4 20:49:17 2018], validation: iter [16560], loss[0.2463418990]\n",
      "[ Tue Dec  4 20:49:18 2018], epoch [16580], lr[0.00039063] ,loss[0.2303040326]\n",
      "[ Tue Dec  4 20:49:18 2018], validation: iter [16580], loss[0.2463413328]\n",
      "[ Tue Dec  4 20:49:18 2018], epoch [16600], lr[0.00039063] ,loss[0.2303028405]\n",
      "[ Tue Dec  4 20:49:18 2018], validation: iter [16600], loss[0.2463417202]\n",
      "[ Tue Dec  4 20:49:19 2018], epoch [16620], lr[0.00039063] ,loss[0.2303022593]\n",
      "[ Tue Dec  4 20:49:19 2018], validation: iter [16620], loss[0.2463412434]\n",
      "[ Tue Dec  4 20:49:19 2018], epoch [16640], lr[0.00039063] ,loss[0.2303043753]\n",
      "[ Tue Dec  4 20:49:19 2018], validation: iter [16640], loss[0.2463405877]\n",
      "[ Tue Dec  4 20:49:20 2018], epoch [16660], lr[0.00039063] ,loss[0.2303069085]\n",
      "[ Tue Dec  4 20:49:20 2018], validation: iter [16660], loss[0.2463404089]\n",
      "[ Tue Dec  4 20:49:20 2018], epoch [16680], lr[0.00039063] ,loss[0.2302996814]\n",
      "[ Tue Dec  4 20:49:20 2018], validation: iter [16680], loss[0.2463382781]\n",
      "[ Tue Dec  4 20:49:21 2018], epoch [16700], lr[0.00039063] ,loss[0.2303003669]\n",
      "[ Tue Dec  4 20:49:21 2018], validation: iter [16700], loss[0.2463394105]\n",
      "[ Tue Dec  4 20:49:21 2018], epoch [16720], lr[0.00039063] ,loss[0.2303026021]\n",
      "[ Tue Dec  4 20:49:21 2018], validation: iter [16720], loss[0.2463387847]\n",
      "[ Tue Dec  4 20:49:22 2018], epoch [16740], lr[0.00039063] ,loss[0.2303005755]\n",
      "[ Tue Dec  4 20:49:22 2018], validation: iter [16740], loss[0.2463388890]\n",
      "[ Tue Dec  4 20:49:22 2018], epoch [16760], lr[0.00039063] ,loss[0.2302997857]\n",
      "[ Tue Dec  4 20:49:22 2018], validation: iter [16760], loss[0.2463386506]\n",
      "[ Tue Dec  4 20:49:23 2018], epoch [16780], lr[0.00039063] ,loss[0.2303014696]\n",
      "[ Tue Dec  4 20:49:23 2018], validation: iter [16780], loss[0.2463382483]\n",
      "[ Tue Dec  4 20:49:23 2018], epoch [16800], lr[0.00039063] ,loss[0.2303012162]\n",
      "[ Tue Dec  4 20:49:23 2018], validation: iter [16800], loss[0.2463381439]\n",
      "[ Tue Dec  4 20:49:24 2018], epoch [16820], lr[0.00039063] ,loss[0.2303026021]\n",
      "[ Tue Dec  4 20:49:24 2018], validation: iter [16820], loss[0.2463376969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 20:49:24 2018], epoch [16840], lr[0.00039063] ,loss[0.2303003818]\n",
      "[ Tue Dec  4 20:49:24 2018], validation: iter [16840], loss[0.2463386357]\n",
      "[ Tue Dec  4 20:49:25 2018], epoch [16860], lr[0.00039063] ,loss[0.2303005904]\n",
      "[ Tue Dec  4 20:49:25 2018], validation: iter [16860], loss[0.2463382781]\n",
      "[ Tue Dec  4 20:49:25 2018], epoch [16880], lr[0.00039063] ,loss[0.2302987128]\n",
      "[ Tue Dec  4 20:49:25 2018], validation: iter [16880], loss[0.2463376969]\n",
      "[ Tue Dec  4 20:49:26 2018], epoch [16900], lr[0.00039063] ,loss[0.2302997261]\n",
      "[ Tue Dec  4 20:49:26 2018], validation: iter [16900], loss[0.2463373095]\n",
      "[ Tue Dec  4 20:49:26 2018], epoch [16920], lr[0.00039063] ,loss[0.2303003967]\n",
      "[ Tue Dec  4 20:49:26 2018], validation: iter [16920], loss[0.2463373095]\n",
      "[ Tue Dec  4 20:49:27 2018], epoch [16940], lr[0.00039063] ,loss[0.2302986830]\n",
      "[ Tue Dec  4 20:49:27 2018], validation: iter [16940], loss[0.2463378906]\n",
      "[ Tue Dec  4 20:49:27 2018], epoch [16960], lr[0.00039063] ,loss[0.2303019464]\n",
      "[ Tue Dec  4 20:49:27 2018], validation: iter [16960], loss[0.2463370264]\n",
      "[ Tue Dec  4 20:49:28 2018], epoch [16980], lr[0.00039063] ,loss[0.2302978188]\n",
      "[ Tue Dec  4 20:49:28 2018], validation: iter [16980], loss[0.2463365793]\n",
      "[ Tue Dec  4 20:49:28 2018], epoch [17000], lr[0.00039063] ,loss[0.2302998900]\n",
      "[ Tue Dec  4 20:49:28 2018], validation: iter [17000], loss[0.2463373393]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_17000']\n",
      "[ Tue Dec  4 20:49:29 2018], epoch [17020], lr[0.00039063] ,loss[0.2302992493]\n",
      "[ Tue Dec  4 20:49:29 2018], validation: iter [17020], loss[0.2463364005]\n",
      "[ Tue Dec  4 20:49:30 2018], epoch [17040], lr[0.00039063] ,loss[0.2302994579]\n",
      "[ Tue Dec  4 20:49:30 2018], validation: iter [17040], loss[0.2463374585]\n",
      "[ Tue Dec  4 20:49:30 2018], epoch [17060], lr[0.00039063] ,loss[0.2303009331]\n",
      "[ Tue Dec  4 20:49:30 2018], validation: iter [17060], loss[0.2463359982]\n",
      "[ Tue Dec  4 20:49:31 2018], epoch [17080], lr[0.00039063] ,loss[0.2302979231]\n",
      "[ Tue Dec  4 20:49:31 2018], validation: iter [17080], loss[0.2463367432]\n",
      "[ Tue Dec  4 20:49:31 2018], epoch [17100], lr[0.00039063] ,loss[0.2302990258]\n",
      "[ Tue Dec  4 20:49:31 2018], validation: iter [17100], loss[0.2463356256]\n",
      "[ Tue Dec  4 20:49:32 2018], epoch [17120], lr[0.00039063] ,loss[0.2302995771]\n",
      "[ Tue Dec  4 20:49:32 2018], validation: iter [17120], loss[0.2463368773]\n",
      "[ Tue Dec  4 20:49:32 2018], epoch [17140], lr[0.00039063] ,loss[0.2303003073]\n",
      "[ Tue Dec  4 20:49:32 2018], validation: iter [17140], loss[0.2463355809]\n",
      "[ Tue Dec  4 20:49:33 2018], epoch [17160], lr[0.00039063] ,loss[0.2302989513]\n",
      "[ Tue Dec  4 20:49:33 2018], validation: iter [17160], loss[0.2463359535]\n",
      "[ Tue Dec  4 20:49:33 2018], epoch [17180], lr[0.00039063] ,loss[0.2302974761]\n",
      "[ Tue Dec  4 20:49:33 2018], validation: iter [17180], loss[0.2463363707]\n",
      "[ Tue Dec  4 20:49:34 2018], epoch [17200], lr[0.00039063] ,loss[0.2302985489]\n",
      "[ Tue Dec  4 20:49:34 2018], validation: iter [17200], loss[0.2463356256]\n",
      "[ Tue Dec  4 20:49:34 2018], epoch [17220], lr[0.00039063] ,loss[0.2303016633]\n",
      "[ Tue Dec  4 20:49:34 2018], validation: iter [17220], loss[0.2463351041]\n",
      "[ Tue Dec  4 20:49:35 2018], epoch [17240], lr[0.00039063] ,loss[0.2302996218]\n",
      "[ Tue Dec  4 20:49:35 2018], validation: iter [17240], loss[0.2463356853]\n",
      "[ Tue Dec  4 20:49:35 2018], epoch [17260], lr[0.00039063] ,loss[0.2302967757]\n",
      "[ Tue Dec  4 20:49:35 2018], validation: iter [17260], loss[0.2463356256]\n",
      "[ Tue Dec  4 20:49:36 2018], epoch [17280], lr[0.00039063] ,loss[0.2302978486]\n",
      "[ Tue Dec  4 20:49:36 2018], validation: iter [17280], loss[0.2463352382]\n",
      "[ Tue Dec  4 20:49:36 2018], epoch [17300], lr[0.00039063] ,loss[0.2302977294]\n",
      "[ Tue Dec  4 20:49:36 2018], validation: iter [17300], loss[0.2463344336]\n",
      "[ Tue Dec  4 20:49:37 2018], epoch [17320], lr[0.00039063] ,loss[0.2303006202]\n",
      "[ Tue Dec  4 20:49:37 2018], validation: iter [17320], loss[0.2463345528]\n",
      "[ Tue Dec  4 20:49:38 2018], epoch [17340], lr[0.00039063] ,loss[0.2303018421]\n",
      "[ Tue Dec  4 20:49:38 2018], validation: iter [17340], loss[0.2463347614]\n",
      "[ Tue Dec  4 20:49:39 2018], epoch [17360], lr[0.00039063] ,loss[0.2303016037]\n",
      "[ Tue Dec  4 20:49:39 2018], validation: iter [17360], loss[0.2463342249]\n",
      "[ Tue Dec  4 20:49:39 2018], epoch [17380], lr[0.00039063] ,loss[0.2303014547]\n",
      "[ Tue Dec  4 20:49:39 2018], validation: iter [17380], loss[0.2463347316]\n",
      "[ Tue Dec  4 20:49:40 2018], epoch [17400], lr[0.00039063] ,loss[0.2302983105]\n",
      "[ Tue Dec  4 20:49:40 2018], validation: iter [17400], loss[0.2463348508]\n",
      "[ Tue Dec  4 20:49:40 2018], epoch [17420], lr[0.00039063] ,loss[0.2302978784]\n",
      "[ Tue Dec  4 20:49:40 2018], validation: iter [17420], loss[0.2463350594]\n",
      "[ Tue Dec  4 20:49:41 2018], epoch [17440], lr[0.00039063] ,loss[0.2302978635]\n",
      "[ Tue Dec  4 20:49:41 2018], validation: iter [17440], loss[0.2463338673]\n",
      "[ Tue Dec  4 20:49:41 2018], epoch [17460], lr[0.00039063] ,loss[0.2302994728]\n",
      "[ Tue Dec  4 20:49:41 2018], validation: iter [17460], loss[0.2463341057]\n",
      "[ Tue Dec  4 20:49:42 2018], epoch [17480], lr[0.00039063] ,loss[0.2302977443]\n",
      "[ Tue Dec  4 20:49:42 2018], validation: iter [17480], loss[0.2463337183]\n",
      "[ Tue Dec  4 20:49:43 2018], epoch [17500], lr[0.00039063] ,loss[0.2303005606]\n",
      "[ Tue Dec  4 20:49:43 2018], validation: iter [17500], loss[0.2463337183]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_17500']\n",
      "[ Tue Dec  4 20:49:44 2018], epoch [17520], lr[0.00039063] ,loss[0.2303040773]\n",
      "[ Tue Dec  4 20:49:44 2018], validation: iter [17520], loss[0.2463343590]\n",
      "[ Tue Dec  4 20:49:45 2018], epoch [17540], lr[0.00039063] ,loss[0.2302969843]\n",
      "[ Tue Dec  4 20:49:45 2018], validation: iter [17540], loss[0.2463344187]\n",
      "[ Tue Dec  4 20:49:46 2018], epoch [17560], lr[0.00039063] ,loss[0.2302995771]\n",
      "[ Tue Dec  4 20:49:46 2018], validation: iter [17560], loss[0.2463342547]\n",
      "[ Tue Dec  4 20:49:46 2018], epoch [17580], lr[0.00039063] ,loss[0.2302983552]\n",
      "[ Tue Dec  4 20:49:46 2018], validation: iter [17580], loss[0.2463341057]\n",
      "[ Tue Dec  4 20:49:47 2018], epoch [17600], lr[0.00039063] ,loss[0.2302985191]\n",
      "[ Tue Dec  4 20:49:47 2018], validation: iter [17600], loss[0.2463336885]\n",
      "[ Tue Dec  4 20:49:48 2018], epoch [17620], lr[0.00039063] ,loss[0.2302985638]\n",
      "[ Tue Dec  4 20:49:48 2018], validation: iter [17620], loss[0.2463333160]\n",
      "[ Tue Dec  4 20:49:48 2018], epoch [17640], lr[0.00039063] ,loss[0.2303003818]\n",
      "[ Tue Dec  4 20:49:48 2018], validation: iter [17640], loss[0.2463332564]\n",
      "[ Tue Dec  4 20:49:49 2018], epoch [17660], lr[0.00039063] ,loss[0.2303001732]\n",
      "[ Tue Dec  4 20:49:49 2018], validation: iter [17660], loss[0.2463346422]\n",
      "[ Tue Dec  4 20:49:49 2018], epoch [17680], lr[0.00039063] ,loss[0.2302992940]\n",
      "[ Tue Dec  4 20:49:49 2018], validation: iter [17680], loss[0.2463345379]\n",
      "[ Tue Dec  4 20:49:50 2018], epoch [17700], lr[0.00039063] ,loss[0.2302996218]\n",
      "[ Tue Dec  4 20:49:50 2018], validation: iter [17700], loss[0.2463329285]\n",
      "[ Tue Dec  4 20:49:51 2018], epoch [17720], lr[0.00039063] ,loss[0.2302940637]\n",
      "[ Tue Dec  4 20:49:51 2018], validation: iter [17720], loss[0.2463349551]\n",
      "[ Tue Dec  4 20:49:51 2018], epoch [17740], lr[0.00039063] ,loss[0.2302978635]\n",
      "[ Tue Dec  4 20:49:51 2018], validation: iter [17740], loss[0.2463330030]\n",
      "[ Tue Dec  4 20:49:52 2018], epoch [17760], lr[0.00039063] ,loss[0.2302978784]\n",
      "[ Tue Dec  4 20:49:52 2018], validation: iter [17760], loss[0.2463335991]\n",
      "[ Tue Dec  4 20:49:53 2018], epoch [17780], lr[0.00039063] ,loss[0.2302971631]\n",
      "[ Tue Dec  4 20:49:53 2018], validation: iter [17780], loss[0.2463332862]\n",
      "[ Tue Dec  4 20:49:54 2018], epoch [17800], lr[0.00039063] ,loss[0.2302980572]\n",
      "[ Tue Dec  4 20:49:54 2018], validation: iter [17800], loss[0.2463324815]\n",
      "[ Tue Dec  4 20:49:54 2018], epoch [17820], lr[0.00039063] ,loss[0.2303004116]\n",
      "[ Tue Dec  4 20:49:54 2018], validation: iter [17820], loss[0.2463337183]\n",
      "[ Tue Dec  4 20:49:55 2018], epoch [17840], lr[0.00039063] ,loss[0.2303051203]\n",
      "[ Tue Dec  4 20:49:55 2018], validation: iter [17840], loss[0.2463333011]\n",
      "[ Tue Dec  4 20:49:56 2018], epoch [17860], lr[0.00039063] ,loss[0.2303016037]\n",
      "[ Tue Dec  4 20:49:56 2018], validation: iter [17860], loss[0.2463339120]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 20:49:56 2018], epoch [17880], lr[0.00039063] ,loss[0.2302945554]\n",
      "[ Tue Dec  4 20:49:56 2018], validation: iter [17880], loss[0.2463335544]\n",
      "[ Tue Dec  4 20:49:57 2018], epoch [17900], lr[0.00039063] ,loss[0.2302986085]\n",
      "[ Tue Dec  4 20:49:57 2018], validation: iter [17900], loss[0.2463328540]\n",
      "[ Tue Dec  4 20:49:58 2018], epoch [17920], lr[0.00039063] ,loss[0.2302988470]\n",
      "[ Tue Dec  4 20:49:58 2018], validation: iter [17920], loss[0.2463333607]\n",
      "[ Tue Dec  4 20:49:58 2018], epoch [17940], lr[0.00039063] ,loss[0.2302982360]\n",
      "[ Tue Dec  4 20:49:58 2018], validation: iter [17940], loss[0.2463327348]\n",
      "[ Tue Dec  4 20:49:59 2018], epoch [17960], lr[0.00039063] ,loss[0.2302989513]\n",
      "[ Tue Dec  4 20:49:59 2018], validation: iter [17960], loss[0.2463341802]\n",
      "[ Tue Dec  4 20:49:59 2018], epoch [17980], lr[0.00039063] ,loss[0.2302972525]\n",
      "[ Tue Dec  4 20:49:59 2018], validation: iter [17980], loss[0.2463328689]\n",
      "[ Tue Dec  4 20:50:00 2018], epoch [18000], lr[0.00039063] ,loss[0.2303000391]\n",
      "[ Tue Dec  4 20:50:00 2018], validation: iter [18000], loss[0.2463329285]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_18000']\n",
      "[ Tue Dec  4 20:50:01 2018], epoch [18020], lr[0.00019531] ,loss[0.2303000689]\n",
      "[ Tue Dec  4 20:50:01 2018], validation: iter [18020], loss[0.2463326752]\n",
      "[ Tue Dec  4 20:50:02 2018], epoch [18040], lr[0.00019531] ,loss[0.2303000987]\n",
      "[ Tue Dec  4 20:50:02 2018], validation: iter [18040], loss[0.2463328540]\n",
      "[ Tue Dec  4 20:50:03 2018], epoch [18060], lr[0.00019531] ,loss[0.2303000689]\n",
      "[ Tue Dec  4 20:50:03 2018], validation: iter [18060], loss[0.2463327795]\n",
      "[ Tue Dec  4 20:50:03 2018], epoch [18080], lr[0.00019531] ,loss[0.2302987427]\n",
      "[ Tue Dec  4 20:50:03 2018], validation: iter [18080], loss[0.2463327795]\n",
      "[ Tue Dec  4 20:50:04 2018], epoch [18100], lr[0.00019531] ,loss[0.2303003520]\n",
      "[ Tue Dec  4 20:50:04 2018], validation: iter [18100], loss[0.2463330477]\n",
      "[ Tue Dec  4 20:50:05 2018], epoch [18120], lr[0.00019531] ,loss[0.2303001732]\n",
      "[ Tue Dec  4 20:50:05 2018], validation: iter [18120], loss[0.2463329285]\n",
      "[ Tue Dec  4 20:50:05 2018], epoch [18140], lr[0.00019531] ,loss[0.2303000391]\n",
      "[ Tue Dec  4 20:50:05 2018], validation: iter [18140], loss[0.2463328093]\n",
      "[ Tue Dec  4 20:50:06 2018], epoch [18160], lr[0.00019531] ,loss[0.2303000391]\n",
      "[ Tue Dec  4 20:50:06 2018], validation: iter [18160], loss[0.2463329881]\n",
      "[ Tue Dec  4 20:50:06 2018], epoch [18180], lr[0.00019531] ,loss[0.2302999943]\n",
      "[ Tue Dec  4 20:50:06 2018], validation: iter [18180], loss[0.2463325709]\n",
      "[ Tue Dec  4 20:50:07 2018], epoch [18200], lr[0.00019531] ,loss[0.2303001434]\n",
      "[ Tue Dec  4 20:50:07 2018], validation: iter [18200], loss[0.2463329881]\n",
      "[ Tue Dec  4 20:50:08 2018], epoch [18220], lr[0.00019531] ,loss[0.2303000838]\n",
      "[ Tue Dec  4 20:50:08 2018], validation: iter [18220], loss[0.2463325709]\n",
      "[ Tue Dec  4 20:50:09 2018], epoch [18240], lr[0.00019531] ,loss[0.2302972078]\n",
      "[ Tue Dec  4 20:50:09 2018], validation: iter [18240], loss[0.2463325262]\n",
      "[ Tue Dec  4 20:50:09 2018], epoch [18260], lr[0.00019531] ,loss[0.2303001881]\n",
      "[ Tue Dec  4 20:50:09 2018], validation: iter [18260], loss[0.2463329881]\n",
      "[ Tue Dec  4 20:50:10 2018], epoch [18280], lr[0.00019531] ,loss[0.2303001434]\n",
      "[ Tue Dec  4 20:50:10 2018], validation: iter [18280], loss[0.2463330030]\n",
      "[ Tue Dec  4 20:50:10 2018], epoch [18300], lr[0.00019531] ,loss[0.2303000838]\n",
      "[ Tue Dec  4 20:50:10 2018], validation: iter [18300], loss[0.2463327199]\n",
      "[ Tue Dec  4 20:50:11 2018], epoch [18320], lr[0.00019531] ,loss[0.2303000689]\n",
      "[ Tue Dec  4 20:50:11 2018], validation: iter [18320], loss[0.2463326156]\n",
      "[ Tue Dec  4 20:50:12 2018], epoch [18340], lr[0.00019531] ,loss[0.2302972525]\n",
      "[ Tue Dec  4 20:50:12 2018], validation: iter [18340], loss[0.2463322431]\n",
      "[ Tue Dec  4 20:50:13 2018], epoch [18360], lr[0.00019531] ,loss[0.2303000391]\n",
      "[ Tue Dec  4 20:50:13 2018], validation: iter [18360], loss[0.2463328093]\n",
      "[ Tue Dec  4 20:50:14 2018], epoch [18380], lr[0.00019531] ,loss[0.2303001434]\n",
      "[ Tue Dec  4 20:50:14 2018], validation: iter [18380], loss[0.2463328093]\n",
      "[ Tue Dec  4 20:50:14 2018], epoch [18400], lr[0.00019531] ,loss[0.2303001285]\n",
      "[ Tue Dec  4 20:50:14 2018], validation: iter [18400], loss[0.2463326305]\n",
      "[ Tue Dec  4 20:50:15 2018], epoch [18420], lr[0.00019531] ,loss[0.2303001285]\n",
      "[ Tue Dec  4 20:50:15 2018], validation: iter [18420], loss[0.2463326603]\n",
      "[ Tue Dec  4 20:50:16 2018], epoch [18440], lr[0.00019531] ,loss[0.2303001434]\n",
      "[ Tue Dec  4 20:50:16 2018], validation: iter [18440], loss[0.2463327497]\n",
      "[ Tue Dec  4 20:50:17 2018], epoch [18460], lr[0.00019531] ,loss[0.2302971482]\n",
      "[ Tue Dec  4 20:50:17 2018], validation: iter [18460], loss[0.2463326603]\n",
      "[ Tue Dec  4 20:50:17 2018], epoch [18480], lr[0.00019531] ,loss[0.2302999347]\n",
      "[ Tue Dec  4 20:50:17 2018], validation: iter [18480], loss[0.2463328689]\n",
      "[ Tue Dec  4 20:50:18 2018], epoch [18500], lr[0.00019531] ,loss[0.2303000689]\n",
      "[ Tue Dec  4 20:50:18 2018], validation: iter [18500], loss[0.2463329732]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_18500']\n",
      "[ Tue Dec  4 20:50:19 2018], epoch [18520], lr[0.00019531] ,loss[0.2303000689]\n",
      "[ Tue Dec  4 20:50:19 2018], validation: iter [18520], loss[0.2463326901]\n",
      "[ Tue Dec  4 20:50:20 2018], epoch [18540], lr[0.00019531] ,loss[0.2303000540]\n",
      "[ Tue Dec  4 20:50:20 2018], validation: iter [18540], loss[0.2463328093]\n",
      "[ Tue Dec  4 20:50:20 2018], epoch [18560], lr[0.00019531] ,loss[0.2302999943]\n",
      "[ Tue Dec  4 20:50:20 2018], validation: iter [18560], loss[0.2463328093]\n",
      "[ Tue Dec  4 20:50:21 2018], epoch [18580], lr[0.00019531] ,loss[0.2302972227]\n",
      "[ Tue Dec  4 20:50:21 2018], validation: iter [18580], loss[0.2463331223]\n",
      "[ Tue Dec  4 20:50:21 2018], epoch [18600], lr[0.00019531] ,loss[0.2302983999]\n",
      "[ Tue Dec  4 20:50:21 2018], validation: iter [18600], loss[0.2463328093]\n",
      "[ Tue Dec  4 20:50:22 2018], epoch [18620], lr[0.00019531] ,loss[0.2303000838]\n",
      "[ Tue Dec  4 20:50:22 2018], validation: iter [18620], loss[0.2463329881]\n",
      "[ Tue Dec  4 20:50:23 2018], epoch [18640], lr[0.00019531] ,loss[0.2302999943]\n",
      "[ Tue Dec  4 20:50:23 2018], validation: iter [18640], loss[0.2463326305]\n",
      "[ Tue Dec  4 20:50:24 2018], epoch [18660], lr[0.00019531] ,loss[0.2302999943]\n",
      "[ Tue Dec  4 20:50:24 2018], validation: iter [18660], loss[0.2463328838]\n",
      "[ Tue Dec  4 20:50:24 2018], epoch [18680], lr[0.00019531] ,loss[0.2302999943]\n",
      "[ Tue Dec  4 20:50:24 2018], validation: iter [18680], loss[0.2463329285]\n",
      "[ Tue Dec  4 20:50:25 2018], epoch [18700], lr[0.00019531] ,loss[0.2302999943]\n",
      "[ Tue Dec  4 20:50:25 2018], validation: iter [18700], loss[0.2463327348]\n",
      "[ Tue Dec  4 20:50:26 2018], epoch [18720], lr[0.00019531] ,loss[0.2302999943]\n",
      "[ Tue Dec  4 20:50:26 2018], validation: iter [18720], loss[0.2463328540]\n",
      "[ Tue Dec  4 20:50:26 2018], epoch [18740], lr[0.00019531] ,loss[0.2302987427]\n",
      "[ Tue Dec  4 20:50:26 2018], validation: iter [18740], loss[0.2463324070]\n",
      "[ Tue Dec  4 20:50:27 2018], epoch [18760], lr[0.00019531] ,loss[0.2302998751]\n",
      "[ Tue Dec  4 20:50:27 2018], validation: iter [18760], loss[0.2463324964]\n",
      "[ Tue Dec  4 20:50:28 2018], epoch [18780], lr[0.00019531] ,loss[0.2303000391]\n",
      "[ Tue Dec  4 20:50:28 2018], validation: iter [18780], loss[0.2463327497]\n",
      "[ Tue Dec  4 20:50:29 2018], epoch [18800], lr[0.00019531] ,loss[0.2302999943]\n",
      "[ Tue Dec  4 20:50:29 2018], validation: iter [18800], loss[0.2463328093]\n",
      "[ Tue Dec  4 20:50:29 2018], epoch [18820], lr[0.00019531] ,loss[0.2302999943]\n",
      "[ Tue Dec  4 20:50:29 2018], validation: iter [18820], loss[0.2463328540]\n",
      "[ Tue Dec  4 20:50:30 2018], epoch [18840], lr[0.00019531] ,loss[0.2302999794]\n",
      "[ Tue Dec  4 20:50:30 2018], validation: iter [18840], loss[0.2463327795]\n",
      "[ Tue Dec  4 20:50:31 2018], epoch [18860], lr[0.00019531] ,loss[0.2303000242]\n",
      "[ Tue Dec  4 20:50:31 2018], validation: iter [18860], loss[0.2463328540]\n",
      "[ Tue Dec  4 20:50:31 2018], epoch [18880], lr[0.00019531] ,loss[0.2302999943]\n",
      "[ Tue Dec  4 20:50:31 2018], validation: iter [18880], loss[0.2463326901]\n",
      "[ Tue Dec  4 20:50:32 2018], epoch [18900], lr[0.00019531] ,loss[0.2302999645]\n",
      "[ Tue Dec  4 20:50:32 2018], validation: iter [18900], loss[0.2463328540]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 20:50:33 2018], epoch [18920], lr[0.00019531] ,loss[0.2302982807]\n",
      "[ Tue Dec  4 20:50:33 2018], validation: iter [18920], loss[0.2463325411]\n",
      "[ Tue Dec  4 20:50:33 2018], epoch [18940], lr[0.00019531] ,loss[0.2302999645]\n",
      "[ Tue Dec  4 20:50:33 2018], validation: iter [18940], loss[0.2463327348]\n",
      "[ Tue Dec  4 20:50:34 2018], epoch [18960], lr[0.00019531] ,loss[0.2302999347]\n",
      "[ Tue Dec  4 20:50:34 2018], validation: iter [18960], loss[0.2463327944]\n",
      "[ Tue Dec  4 20:50:34 2018], epoch [18980], lr[0.00019531] ,loss[0.2302999943]\n",
      "[ Tue Dec  4 20:50:34 2018], validation: iter [18980], loss[0.2463327795]\n",
      "[ Tue Dec  4 20:50:35 2018], epoch [19000], lr[0.00019531] ,loss[0.2302999794]\n",
      "[ Tue Dec  4 20:50:35 2018], validation: iter [19000], loss[0.2463329434]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_19000']\n",
      "[ Tue Dec  4 20:50:35 2018], epoch [19020], lr[0.00019531] ,loss[0.2302999943]\n",
      "[ Tue Dec  4 20:50:35 2018], validation: iter [19020], loss[0.2463328540]\n",
      "[ Tue Dec  4 20:50:36 2018], epoch [19040], lr[0.00019531] ,loss[0.2302999943]\n",
      "[ Tue Dec  4 20:50:36 2018], validation: iter [19040], loss[0.2463327199]\n",
      "[ Tue Dec  4 20:50:37 2018], epoch [19060], lr[0.00019531] ,loss[0.2302999645]\n",
      "[ Tue Dec  4 20:50:37 2018], validation: iter [19060], loss[0.2463326603]\n",
      "[ Tue Dec  4 20:50:37 2018], epoch [19080], lr[0.00019531] ,loss[0.2302999496]\n",
      "[ Tue Dec  4 20:50:37 2018], validation: iter [19080], loss[0.2463326007]\n",
      "[ Tue Dec  4 20:50:38 2018], epoch [19100], lr[0.00019531] ,loss[0.2302998900]\n",
      "[ Tue Dec  4 20:50:38 2018], validation: iter [19100], loss[0.2463327199]\n",
      "[ Tue Dec  4 20:50:38 2018], epoch [19120], lr[0.00019531] ,loss[0.2302999645]\n",
      "[ Tue Dec  4 20:50:38 2018], validation: iter [19120], loss[0.2463326901]\n",
      "[ Tue Dec  4 20:50:39 2018], epoch [19140], lr[0.00019531] ,loss[0.2302979380]\n",
      "[ Tue Dec  4 20:50:39 2018], validation: iter [19140], loss[0.2463330030]\n",
      "[ Tue Dec  4 20:50:39 2018], epoch [19160], lr[0.00019531] ,loss[0.2302999347]\n",
      "[ Tue Dec  4 20:50:39 2018], validation: iter [19160], loss[0.2463326156]\n",
      "[ Tue Dec  4 20:50:40 2018], epoch [19180], lr[0.00019531] ,loss[0.2302999794]\n",
      "[ Tue Dec  4 20:50:40 2018], validation: iter [19180], loss[0.2463327497]\n",
      "[ Tue Dec  4 20:50:40 2018], epoch [19200], lr[0.00019531] ,loss[0.2302999645]\n",
      "[ Tue Dec  4 20:50:40 2018], validation: iter [19200], loss[0.2463326901]\n",
      "[ Tue Dec  4 20:50:41 2018], epoch [19220], lr[0.00019531] ,loss[0.2302999198]\n",
      "[ Tue Dec  4 20:50:41 2018], validation: iter [19220], loss[0.2463326603]\n",
      "[ Tue Dec  4 20:50:41 2018], epoch [19240], lr[0.00019531] ,loss[0.2302999347]\n",
      "[ Tue Dec  4 20:50:41 2018], validation: iter [19240], loss[0.2463327348]\n",
      "[ Tue Dec  4 20:50:42 2018], epoch [19260], lr[0.00019531] ,loss[0.2302998602]\n",
      "[ Tue Dec  4 20:50:42 2018], validation: iter [19260], loss[0.2463326156]\n",
      "[ Tue Dec  4 20:50:42 2018], epoch [19280], lr[0.00019531] ,loss[0.2302998900]\n",
      "[ Tue Dec  4 20:50:42 2018], validation: iter [19280], loss[0.2463326603]\n",
      "[ Tue Dec  4 20:50:43 2018], epoch [19300], lr[0.00019531] ,loss[0.2302998304]\n",
      "[ Tue Dec  4 20:50:43 2018], validation: iter [19300], loss[0.2463327348]\n",
      "[ Tue Dec  4 20:50:43 2018], epoch [19320], lr[0.00019531] ,loss[0.2302982658]\n",
      "[ Tue Dec  4 20:50:43 2018], validation: iter [19320], loss[0.2463324815]\n",
      "[ Tue Dec  4 20:50:44 2018], epoch [19340], lr[0.00019531] ,loss[0.2302997261]\n",
      "[ Tue Dec  4 20:50:44 2018], validation: iter [19340], loss[0.2463324964]\n",
      "[ Tue Dec  4 20:50:44 2018], epoch [19360], lr[0.00019531] ,loss[0.2302997857]\n",
      "[ Tue Dec  4 20:50:44 2018], validation: iter [19360], loss[0.2463326901]\n",
      "[ Tue Dec  4 20:50:45 2018], epoch [19380], lr[0.00019531] ,loss[0.2302982956]\n",
      "[ Tue Dec  4 20:50:45 2018], validation: iter [19380], loss[0.2463325709]\n",
      "[ Tue Dec  4 20:50:45 2018], epoch [19400], lr[0.00019531] ,loss[0.2302982360]\n",
      "[ Tue Dec  4 20:50:45 2018], validation: iter [19400], loss[0.2463322729]\n",
      "[ Tue Dec  4 20:50:46 2018], epoch [19420], lr[0.00019531] ,loss[0.2302995771]\n",
      "[ Tue Dec  4 20:50:46 2018], validation: iter [19420], loss[0.2463324070]\n",
      "[ Tue Dec  4 20:50:46 2018], epoch [19440], lr[0.00019531] ,loss[0.2302971929]\n",
      "[ Tue Dec  4 20:50:46 2018], validation: iter [19440], loss[0.2463333160]\n",
      "[ Tue Dec  4 20:50:47 2018], epoch [19460], lr[0.00019531] ,loss[0.2302979827]\n",
      "[ Tue Dec  4 20:50:47 2018], validation: iter [19460], loss[0.2463324666]\n",
      "[ Tue Dec  4 20:50:47 2018], epoch [19480], lr[0.00019531] ,loss[0.2302941978]\n",
      "[ Tue Dec  4 20:50:47 2018], validation: iter [19480], loss[0.2463324964]\n",
      "[ Tue Dec  4 20:50:48 2018], epoch [19500], lr[0.00019531] ,loss[0.2302979827]\n",
      "[ Tue Dec  4 20:50:48 2018], validation: iter [19500], loss[0.2463321835]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_19500']\n",
      "[ Tue Dec  4 20:50:48 2018], epoch [19520], lr[0.00019531] ,loss[0.2302979529]\n",
      "[ Tue Dec  4 20:50:48 2018], validation: iter [19520], loss[0.2463323474]\n",
      "[ Tue Dec  4 20:50:49 2018], epoch [19540], lr[0.00019531] ,loss[0.2303001434]\n",
      "[ Tue Dec  4 20:50:49 2018], validation: iter [19540], loss[0.2463326007]\n",
      "[ Tue Dec  4 20:50:49 2018], epoch [19560], lr[0.00019531] ,loss[0.2302998602]\n",
      "[ Tue Dec  4 20:50:49 2018], validation: iter [19560], loss[0.2463324815]\n",
      "[ Tue Dec  4 20:50:50 2018], epoch [19580], lr[0.00019531] ,loss[0.2302982360]\n",
      "[ Tue Dec  4 20:50:50 2018], validation: iter [19580], loss[0.2463322282]\n",
      "[ Tue Dec  4 20:50:50 2018], epoch [19600], lr[0.00019531] ,loss[0.2302982360]\n",
      "[ Tue Dec  4 20:50:50 2018], validation: iter [19600], loss[0.2463324368]\n",
      "[ Tue Dec  4 20:50:51 2018], epoch [19620], lr[0.00019531] ,loss[0.2302999943]\n",
      "[ Tue Dec  4 20:50:51 2018], validation: iter [19620], loss[0.2463324219]\n",
      "[ Tue Dec  4 20:50:51 2018], epoch [19640], lr[0.00019531] ,loss[0.2302995175]\n",
      "[ Tue Dec  4 20:50:51 2018], validation: iter [19640], loss[0.2463324666]\n",
      "[ Tue Dec  4 20:50:52 2018], epoch [19660], lr[0.00019531] ,loss[0.2302970439]\n",
      "[ Tue Dec  4 20:50:52 2018], validation: iter [19660], loss[0.2463324666]\n",
      "[ Tue Dec  4 20:50:52 2018], epoch [19680], lr[0.00019531] ,loss[0.2303020507]\n",
      "[ Tue Dec  4 20:50:52 2018], validation: iter [19680], loss[0.2463329136]\n",
      "[ Tue Dec  4 20:50:53 2018], epoch [19700], lr[0.00019531] ,loss[0.2302976549]\n",
      "[ Tue Dec  4 20:50:53 2018], validation: iter [19700], loss[0.2463323027]\n",
      "[ Tue Dec  4 20:50:53 2018], epoch [19720], lr[0.00019531] ,loss[0.2302975059]\n",
      "[ Tue Dec  4 20:50:53 2018], validation: iter [19720], loss[0.2463325709]\n",
      "[ Tue Dec  4 20:50:54 2018], epoch [19740], lr[0.00019531] ,loss[0.2302970141]\n",
      "[ Tue Dec  4 20:50:54 2018], validation: iter [19740], loss[0.2463323027]\n",
      "[ Tue Dec  4 20:50:54 2018], epoch [19760], lr[0.00019531] ,loss[0.2302992642]\n",
      "[ Tue Dec  4 20:50:54 2018], validation: iter [19760], loss[0.2463324070]\n",
      "[ Tue Dec  4 20:50:55 2018], epoch [19780], lr[0.00019531] ,loss[0.2302999645]\n",
      "[ Tue Dec  4 20:50:55 2018], validation: iter [19780], loss[0.2463324666]\n",
      "[ Tue Dec  4 20:50:55 2018], epoch [19800], lr[0.00019531] ,loss[0.2302981466]\n",
      "[ Tue Dec  4 20:50:55 2018], validation: iter [19800], loss[0.2463323474]\n",
      "[ Tue Dec  4 20:50:56 2018], epoch [19820], lr[0.00019531] ,loss[0.2302999943]\n",
      "[ Tue Dec  4 20:50:56 2018], validation: iter [19820], loss[0.2463325560]\n",
      "[ Tue Dec  4 20:50:56 2018], epoch [19840], lr[0.00019531] ,loss[0.2302997112]\n",
      "[ Tue Dec  4 20:50:56 2018], validation: iter [19840], loss[0.2463325709]\n",
      "[ Tue Dec  4 20:50:57 2018], epoch [19860], lr[0.00019531] ,loss[0.2302997559]\n",
      "[ Tue Dec  4 20:50:57 2018], validation: iter [19860], loss[0.2463325709]\n",
      "[ Tue Dec  4 20:50:57 2018], epoch [19880], lr[0.00019531] ,loss[0.2302999943]\n",
      "[ Tue Dec  4 20:50:57 2018], validation: iter [19880], loss[0.2463324219]\n",
      "[ Tue Dec  4 20:50:58 2018], epoch [19900], lr[0.00019531] ,loss[0.2302981466]\n",
      "[ Tue Dec  4 20:50:58 2018], validation: iter [19900], loss[0.2463326901]\n",
      "[ Tue Dec  4 20:50:58 2018], epoch [19920], lr[0.00019531] ,loss[0.2302995473]\n",
      "[ Tue Dec  4 20:50:58 2018], validation: iter [19920], loss[0.2463324815]\n",
      "[ Tue Dec  4 20:50:59 2018], epoch [19940], lr[0.00019531] ,loss[0.2302975655]\n",
      "[ Tue Dec  4 20:50:59 2018], validation: iter [19940], loss[0.2463322282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Tue Dec  4 20:50:59 2018], epoch [19960], lr[0.00019531] ,loss[0.2302996516]\n",
      "[ Tue Dec  4 20:50:59 2018], validation: iter [19960], loss[0.2463313341]\n",
      "[ Tue Dec  4 20:51:00 2018], epoch [19980], lr[0.00019531] ,loss[0.2302992046]\n",
      "[ Tue Dec  4 20:51:00 2018], validation: iter [19980], loss[0.2463318408]\n",
      "[ Tue Dec  4 20:51:00 2018], epoch [20000], lr[0.00019531] ,loss[0.2302997261]\n",
      "[ Tue Dec  4 20:51:00 2018], validation: iter [20000], loss[0.2463323474]\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_20000']\n",
      "Model saved in file: ['/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_20000']\n",
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "try:\n",
    "    from importlib import reload\n",
    "    reload(MachineLearning)\n",
    "except NameError:\n",
    "    import MachineLearning\n",
    "sys.argv[1] = 'training'\n",
    "MachineLearning.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = MachineLearning._res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.94456288, -0.43266763,  0.92102617, -0.80672541,  0.31518039],\n",
       "       [-0.8305285 ,  0.38174217, -0.82285094,  0.84221054, -0.17611952],\n",
       "       [-0.57274943,  0.05708807, -0.57735351,  0.42954824, -0.16473169],\n",
       "       ...,\n",
       "       [-0.52645838, -0.40329701, -0.52279778,  0.27274291, -0.76685062],\n",
       "       [-0.91602872,  1.00446948, -0.90796218,  1.05074101,  0.49303958],\n",
       "       [ 1.29140127, -1.02907931,  1.2955238 , -1.19941803, -0.6455979 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MachineLearning._train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saver restore from:/Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_20000\n",
      "INFO:tensorflow:Restoring parameters from /Users/siyangjing/Documents/GitHub/Data-Assimilation/FA18/Modularized/DiffInitNormModel/checkpoint_20000\n",
      "Predict complete, cost [  0] seconds\n"
     ]
    }
   ],
   "source": [
    "config.ReadConfigFile()\n",
    "sys.argv[1] = 'evaluation'\n",
    "# config.ResetValue('MachineLearning','normalization','False')\n",
    "# config.ResetValue('MLEvaluation','observation_source',data_dir)\n",
    "# config.ResetValue('MLEvaluation','data_source',data_dir)\n",
    "# config.ResetValue('MachineLearning','save_dir',model_dir)\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "from importlib import reload\n",
    "reload(MachineLearning)\n",
    "pred,loss = MachineLearning.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.6699389746676"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x132d9a978>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MachineLearning._Y\n",
    "\n",
    "X = MachineLearning._X\n",
    "Y = MachineLearning._Y\n",
    "\n",
    "diff = pred - Y\n",
    "diff_seq = (diff ** 2).mean(axis=1)\n",
    "\n",
    "rel_diff_seq = abs(diff/Y).mean(axis=1)\n",
    "\n",
    "diff_norm = (diff ** 2).sum(axis = 1)\n",
    "truth_norm = (Y ** 2).sum(axis = 1)\n",
    "\n",
    "rel_error = diff_norm / truth_norm\n",
    "\n",
    "sort_index = np.argsort(rel_error)\n",
    "sort_index = np.flip(sort_index)\n",
    "\n",
    "sort_index.shape\n",
    "\n",
    "large_error_index = sort_index[:2300]\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "index_sorted = np.sort(large_error_index)\n",
    "\n",
    "np.sort(index_sorted % 1000)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(index_sorted % 1000)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X[:,0],X[:,1],s=0.1)\n",
    "#plt.plot(X[large_error_index,0],X[large_error_index,1],'r.',markersize=0.5)\n",
    "#plt.scatter(X[large_error_index,0],X[large_error_index,1],s=0.1,c='r')\n",
    "th = 2000\n",
    "plt.scatter(X[sort_index[:th],0],X[sort_index[:th],1],s=0.1,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.89888446, 10.73921006, 10.51638625, 10.21753496,  9.92970968,\n",
       "        9.64972879,  8.49230647,  8.48084418,  7.28396833,  6.75061585,\n",
       "        6.32479704,  5.53203764,  5.24506969,  5.23762604,  4.93969094,\n",
       "        4.9247398 ,  4.81715519,  4.18740164,  4.11775258,  3.48693109,\n",
       "        3.41653169,  3.25440786,  3.25394256,  3.25222338,  3.25193381,\n",
       "        3.25075059,  3.24984393,  3.24827381,  3.24797162,  3.24704494,\n",
       "        3.24601968,  3.24555347,  3.24240849,  3.23935819,  3.23732112,\n",
       "        3.23537782,  3.23482414,  3.23329774,  3.22262078,  3.22196602,\n",
       "        3.21745825,  3.2112886 ,  3.20164126,  3.20150225,  3.19020174,\n",
       "        3.19017944,  3.18338299,  3.179516  ,  3.17643232,  3.17587213,\n",
       "        3.17403691,  3.17256665,  3.17083318,  3.16684674,  3.16625497,\n",
       "        3.15948032,  3.15038264,  3.14430336,  3.13723157,  3.12176749,\n",
       "        3.11866074,  3.11010267,  3.08797102,  3.07856116,  3.07471675,\n",
       "        3.05552694,  3.05111834,  3.04850665,  3.03495503,  3.03043853,\n",
       "        3.0299533 ,  3.02825505,  3.02762898,  3.02689192,  3.02675496,\n",
       "        3.02434405,  3.02193029,  2.98461894,  2.98371186,  2.98142642,\n",
       "        2.97892525,  2.97402862,  2.97372229,  2.95463919,  2.94949464,\n",
       "        2.93589209,  2.93585835,  2.93424075,  2.92645889,  2.90312489,\n",
       "        2.8993419 ,  2.89623806,  2.89295415,  2.89062163,  2.88825221,\n",
       "        2.88685976,  2.88466522,  2.88249099,  2.869433  ,  2.85334024,\n",
       "        2.84980273,  2.82372977,  2.81947489,  2.80952247,  2.7984754 ,\n",
       "        2.78927176,  2.78853439,  2.7662585 ,  2.76071056,  2.74609791,\n",
       "        2.73424894,  2.73258215,  2.72804362,  2.6965887 ,  2.68208048,\n",
       "        2.67671523,  2.64145292,  2.63408918,  2.6272314 ,  2.61872432,\n",
       "        2.61172451,  2.60224241,  2.5956114 ,  2.58768046,  2.56389151,\n",
       "        2.56137769,  2.55592763,  2.53929636,  2.53797225,  2.53494934,\n",
       "        2.53410637,  2.52461426,  2.52075401,  2.51107094,  2.50522273,\n",
       "        2.49908051,  2.49712812,  2.49492373,  2.49145086,  2.48747742,\n",
       "        2.4747807 ,  2.473281  ,  2.47209992,  2.47040316,  2.46926373,\n",
       "        2.45861928,  2.45232776,  2.43911097,  2.42308533,  2.39213207,\n",
       "        2.39125923,  2.384315  ,  2.36701378,  2.35925965,  2.35010545,\n",
       "        2.32400353,  2.31959194,  2.31789063,  2.31214496,  2.30644831,\n",
       "        2.3057726 ,  2.29867413,  2.29397381,  2.28629186,  2.26920956,\n",
       "        2.2626785 ,  2.22551666,  2.21595427,  2.20929097,  2.18930934,\n",
       "        2.18698025,  2.18194587,  2.18129733,  2.18082458,  2.17678893,\n",
       "        2.17452512,  2.17224543,  2.16136687,  2.16123321,  2.15900548,\n",
       "        2.15577674,  2.1461669 ,  2.14485288,  2.1428199 ,  2.14050512,\n",
       "        2.13736119,  2.13634054,  2.13263327,  2.13257246,  2.11907773,\n",
       "        2.1179608 ,  2.11133976,  2.10819028,  2.10349452,  2.10289037,\n",
       "        2.10278528,  2.09806375,  2.08689367,  2.08470961,  2.07555937,\n",
       "        2.06340903,  2.06262012,  2.05978019,  2.05628985,  2.04801204,\n",
       "        2.04706642,  2.04219092,  2.03199521,  2.03182982,  2.02979422,\n",
       "        2.0282527 ,  2.01667188,  2.01109825,  2.0050365 ,  1.99300615,\n",
       "        1.99217485,  1.98420566,  1.98209584,  1.9801297 ,  1.97893509,\n",
       "        1.95852252,  1.95739011,  1.95502304,  1.95394761,  1.94758576,\n",
       "        1.93864396,  1.93237487,  1.92889555,  1.92663508,  1.92514965,\n",
       "        1.91990747,  1.91463516,  1.9120838 ,  1.91070975,  1.9093996 ,\n",
       "        1.90939327,  1.90413642,  1.90052136,  1.89897085,  1.8988585 ,\n",
       "        1.89722496,  1.89542921,  1.8935534 ,  1.886557  ,  1.8819764 ,\n",
       "        1.8819429 ,  1.87916781,  1.87795739,  1.8776929 ,  1.87357349,\n",
       "        1.87312957,  1.870825  ,  1.87051646,  1.87004208,  1.86890525,\n",
       "        1.86715392,  1.86049337,  1.85385448,  1.85098623,  1.84780058,\n",
       "        1.84477873,  1.84178555,  1.83901091,  1.83832024,  1.83817159,\n",
       "        1.82993986,  1.82673482,  1.82054484,  1.8161174 ,  1.81215648,\n",
       "        1.81074278,  1.80177633,  1.8010447 ,  1.7990964 ,  1.79577551,\n",
       "        1.79096713,  1.78589955,  1.78239618,  1.77747888,  1.77632546,\n",
       "        1.77381486,  1.76416633,  1.76203732,  1.76139244,  1.76055509,\n",
       "        1.75445272,  1.75261621,  1.75195859,  1.74639779,  1.73256128,\n",
       "        1.72245838,  1.71827607,  1.71483397,  1.71255809,  1.70798355,\n",
       "        1.70695254,  1.69887564,  1.69242959,  1.68323025,  1.68318465,\n",
       "        1.67692107,  1.67356651,  1.6690002 ,  1.66763997,  1.66338975,\n",
       "        1.65686971,  1.64648969,  1.64178451,  1.64002758,  1.6357477 ,\n",
       "        1.6339919 ,  1.63327772,  1.63254985,  1.6177353 ,  1.6146703 ,\n",
       "        1.60967061,  1.60794293,  1.60512192,  1.59849388,  1.59284517,\n",
       "        1.58903006,  1.58393877,  1.58210572,  1.57709093,  1.5764414 ,\n",
       "        1.57573155,  1.57313611,  1.57151437,  1.56398615,  1.55778462,\n",
       "        1.55649713,  1.55381635,  1.55060844,  1.55002292,  1.54928361,\n",
       "        1.54803322,  1.54453001,  1.52796523,  1.52579798,  1.52345082,\n",
       "        1.52324214,  1.52143561,  1.51831564,  1.51218047,  1.50994304,\n",
       "        1.5037843 ,  1.50241846,  1.49664885,  1.49656725,  1.49589444,\n",
       "        1.49478157,  1.49271914,  1.4919577 ,  1.49106945,  1.48824464,\n",
       "        1.48471921,  1.48431974,  1.478857  ,  1.47318423,  1.47112217,\n",
       "        1.46994639,  1.46979909,  1.46881081,  1.46857354,  1.46713644,\n",
       "        1.46286894,  1.46091306,  1.45980307,  1.45425086,  1.45151282,\n",
       "        1.44571005,  1.44264015,  1.43991568,  1.43768024,  1.43528079,\n",
       "        1.43357664,  1.43119101,  1.42943331,  1.42830574,  1.42519578,\n",
       "        1.4229611 ,  1.42102247,  1.42072133,  1.41887872,  1.41859376,\n",
       "        1.41857791,  1.41602139,  1.41512386,  1.41069933,  1.40957522,\n",
       "        1.4090209 ,  1.40841184,  1.40592718,  1.40396367,  1.40312713,\n",
       "        1.39868383,  1.39832935,  1.39735098,  1.39347408,  1.39249388,\n",
       "        1.39167155,  1.39155044,  1.39140333,  1.39102544,  1.39022501,\n",
       "        1.38887741,  1.38882538,  1.37850406,  1.37702963,  1.37404572,\n",
       "        1.37370709,  1.37307654,  1.36977284,  1.36599092,  1.36279847,\n",
       "        1.36124497,  1.3587539 ,  1.3565172 ,  1.35525751,  1.35114019,\n",
       "        1.34859949,  1.34851917,  1.34784586,  1.3448777 ,  1.34469338,\n",
       "        1.34423273,  1.34082004,  1.34038646,  1.34017198,  1.33723016,\n",
       "        1.33315367,  1.3315171 ,  1.33108375,  1.32890623,  1.32885218,\n",
       "        1.32833621,  1.32795178,  1.32780361,  1.32690288,  1.32577622,\n",
       "        1.3256477 ,  1.32191997,  1.32173191,  1.31998363,  1.31788281,\n",
       "        1.31700004,  1.31558819,  1.31279461,  1.31138466,  1.30976466,\n",
       "        1.30816403,  1.30754673,  1.30674928,  1.30615429,  1.30599752,\n",
       "        1.30590556,  1.30294985,  1.30231253,  1.30227525,  1.29889919,\n",
       "        1.2970824 ,  1.29586094,  1.29307034,  1.29183794,  1.29035785,\n",
       "        1.28889946,  1.28847357,  1.28835683,  1.28363769,  1.28134242,\n",
       "        1.27803021,  1.2745764 ,  1.27399487,  1.27258673,  1.27160559,\n",
       "        1.27103374,  1.26794313,  1.26788276,  1.26754784,  1.26744298,\n",
       "        1.26702915,  1.26656104,  1.26651107,  1.26644617,  1.26621752,\n",
       "        1.26170605,  1.2605136 ,  1.25605338,  1.25506895,  1.25469042,\n",
       "        1.25467318,  1.2543493 ,  1.25210355,  1.25061783,  1.24520259,\n",
       "        1.24432365,  1.24330137,  1.24242004,  1.24216956,  1.24177602,\n",
       "        1.23953423,  1.238938  ,  1.23843131,  1.23792458,  1.23696526,\n",
       "        1.23022976,  1.22908766,  1.22722774,  1.22713473,  1.22442345,\n",
       "        1.22387408,  1.22280626,  1.22221837,  1.22148251,  1.22144788,\n",
       "        1.21990429,  1.21700842,  1.21536366,  1.2142935 ,  1.21340769,\n",
       "        1.21226642,  1.21208126,  1.21147279,  1.21145799,  1.20749709,\n",
       "        1.20396468,  1.20240892,  1.20116079,  1.20107846,  1.19978601,\n",
       "        1.19688852,  1.19569254,  1.19408647,  1.19213185,  1.19088531,\n",
       "        1.19073639,  1.1903322 ,  1.18855098,  1.18694067,  1.18620848,\n",
       "        1.18252391,  1.1806375 ,  1.18041665,  1.17880829,  1.17789703,\n",
       "        1.17689304,  1.17509457,  1.17147117,  1.1706227 ,  1.17033437,\n",
       "        1.16896733,  1.16840114,  1.1653518 ,  1.16518703,  1.1644041 ,\n",
       "        1.16156253,  1.16034101,  1.15635008,  1.15477418,  1.15396878,\n",
       "        1.15392693,  1.15351579,  1.15055406,  1.14248978,  1.14143638,\n",
       "        1.13984693,  1.13951259,  1.13900407,  1.13854814,  1.13719796,\n",
       "        1.13420512,  1.1336678 ,  1.12934766,  1.12853009,  1.12803605,\n",
       "        1.12620879,  1.12299324,  1.12185636,  1.11706751,  1.11681797,\n",
       "        1.11526424,  1.11471469,  1.11179056,  1.11041122,  1.11003125,\n",
       "        1.10924182,  1.1087    ,  1.10843541,  1.10827264,  1.10806866,\n",
       "        1.10736144,  1.10687481,  1.10553286,  1.10368917,  1.10052823,\n",
       "        1.0997824 ,  1.09865584,  1.09837572,  1.09520674,  1.09484661,\n",
       "        1.0948408 ,  1.09466071,  1.09463572,  1.09446542,  1.09445126,\n",
       "        1.09147496,  1.09116705,  1.09081275,  1.09039272,  1.08891122,\n",
       "        1.08575352,  1.08507795,  1.08370111,  1.07869777,  1.07769387,\n",
       "        1.07555533,  1.07227723,  1.06745911,  1.06547986,  1.06482391,\n",
       "        1.06374698,  1.05795114,  1.05774422,  1.05742762,  1.05741538,\n",
       "        1.05672949,  1.05628881,  1.05549918,  1.052147  ,  1.04965715,\n",
       "        1.04798295,  1.04766784,  1.04636149,  1.04613079,  1.04339788,\n",
       "        1.04301204,  1.0422369 ,  1.04213543,  1.04027496,  1.03886039,\n",
       "        1.03662508,  1.03557629,  1.03478338,  1.03424353,  1.03309479,\n",
       "        1.0330565 ,  1.0324411 ,  1.0309364 ,  1.03088274,  1.02806529,\n",
       "        1.02720907,  1.0246952 ,  1.02408729,  1.02363275,  1.0221833 ,\n",
       "        1.02140302,  1.02008129,  1.01837193,  1.01809412,  1.01494581,\n",
       "        1.01443003,  1.01382953,  1.0133215 ,  1.01287906,  1.0110408 ,\n",
       "        1.01067715,  1.00934082,  1.00841421,  1.00670072,  1.00491748,\n",
       "        1.004398  ,  1.00324229,  1.00202247,  1.00180667,  1.00011659,\n",
       "        0.99937969,  0.99898211,  0.99599456,  0.98846388,  0.98768323,\n",
       "        0.98667066,  0.98489898,  0.98487344,  0.98412768,  0.98378076,\n",
       "        0.97993412,  0.97942506,  0.97806583,  0.97374272,  0.96889529,\n",
       "        0.96865828,  0.96820482,  0.96646241,  0.96357182,  0.95948331,\n",
       "        0.95780015,  0.95620709,  0.95500996,  0.95248607,  0.95135911,\n",
       "        0.95129311,  0.95000981,  0.94844467,  0.94680079,  0.94381357,\n",
       "        0.9433076 ,  0.94141338,  0.94137674,  0.93893692,  0.93798738,\n",
       "        0.93647956,  0.93646975,  0.9339562 ,  0.93231515,  0.93050841,\n",
       "        0.92961898,  0.92741179,  0.92622401,  0.9253788 ,  0.9228076 ,\n",
       "        0.92259217,  0.92141623,  0.91918443,  0.91740802,  0.9161776 ,\n",
       "        0.91543372,  0.91385025,  0.91318355,  0.91230163,  0.90674638,\n",
       "        0.90669767,  0.9024256 ,  0.90208521,  0.90072486,  0.89758929,\n",
       "        0.89588224,  0.89237784,  0.89105345,  0.88928673,  0.88902845,\n",
       "        0.8867488 ,  0.88660433,  0.88603565,  0.88487343,  0.88023743,\n",
       "        0.87889315,  0.87863584,  0.87780878,  0.87709632,  0.87643492,\n",
       "        0.87503846,  0.87350762,  0.87079564,  0.86997714,  0.86941024,\n",
       "        0.86553898,  0.86348545,  0.86306274,  0.86208331,  0.8615102 ,\n",
       "        0.85875691,  0.85822491,  0.8574058 ,  0.85597081,  0.85459007,\n",
       "        0.85409086,  0.8534532 ,  0.85261755,  0.85162788,  0.85107027,\n",
       "        0.8488917 ,  0.84683231,  0.84525923,  0.84361357,  0.84346238,\n",
       "        0.83942484,  0.83216623,  0.82867893,  0.82631388,  0.82478687,\n",
       "        0.82204007,  0.82170799,  0.82126322,  0.81932312,  0.81883324,\n",
       "        0.81834389,  0.81731527,  0.81163432,  0.81145238,  0.80924217,\n",
       "        0.80919596,  0.80857473,  0.80516078,  0.80453513,  0.80400277,\n",
       "        0.80382654,  0.80098558,  0.79970941,  0.79933287,  0.7979874 ,\n",
       "        0.79595327,  0.79402009,  0.7935712 ,  0.7935459 ,  0.79291169,\n",
       "        0.79230778,  0.79003158,  0.78960094,  0.77630541,  0.77500454,\n",
       "        0.77135913,  0.76894635,  0.76768568,  0.76368135,  0.76268371,\n",
       "        0.76125474,  0.76003347,  0.75872467,  0.75740291,  0.75691072,\n",
       "        0.75659561,  0.75414323,  0.75400897,  0.75309803,  0.75214896,\n",
       "        0.7515918 ,  0.74720739,  0.74651397,  0.74314571,  0.74285918,\n",
       "        0.74219372,  0.73922017,  0.73660596,  0.73538908,  0.73534814,\n",
       "        0.73501774,  0.73219486,  0.73213465,  0.73012875,  0.72947631,\n",
       "        0.72938731,  0.72898956,  0.72520415,  0.72451572,  0.72390993,\n",
       "        0.72377193,  0.72246549,  0.7218888 ,  0.71869964,  0.71528548,\n",
       "        0.71448173,  0.71363418,  0.71234712,  0.71100573,  0.7091567 ,\n",
       "        0.7085059 ,  0.70806905,  0.70733222,  0.7069564 ,  0.70694941,\n",
       "        0.70427912,  0.70418864,  0.70259737,  0.70144369,  0.70060515,\n",
       "        0.69845646,  0.69837237,  0.69711248,  0.69637188,  0.69571288,\n",
       "        0.69126827,  0.68892892,  0.68688064,  0.68443791,  0.68233738,\n",
       "        0.68079699,  0.67996938,  0.67869765,  0.67581442,  0.67226442,\n",
       "        0.67140971,  0.66975877,  0.66964097,  0.66907862,  0.66785144,\n",
       "        0.66765274,  0.66691375,  0.6667482 ,  0.66441354,  0.66219775,\n",
       "        0.65884615,  0.65884284,  0.65658499,  0.65548347,  0.65503124,\n",
       "        0.65329242,  0.65227368,  0.65198257,  0.64844068,  0.64749105,\n",
       "        0.64660793,  0.64467367,  0.64418784,  0.64266992,  0.64169799,\n",
       "        0.64042372,  0.63631713,  0.6354912 ,  0.63038181,  0.62923731,\n",
       "        0.62846989,  0.62607191,  0.62174299,  0.61785111,  0.61747398,\n",
       "        0.61600788,  0.61523727,  0.61328548,  0.61265275,  0.60857449,\n",
       "        0.60806762,  0.60759369,  0.60715916,  0.60679928,  0.6049091 ,\n",
       "        0.60436491,  0.60367998,  0.60353815,  0.60194249,  0.60130909,\n",
       "        0.60088936,  0.60057679,  0.60024433,  0.59824107,  0.59792987,\n",
       "        0.59620026,  0.59508648,  0.593244  ,  0.59001907,  0.5884748 ,\n",
       "        0.58791641,  0.58765386,  0.58630433,  0.58622105,  0.5831913 ,\n",
       "        0.58296466,  0.57818574,  0.57630724,  0.57609277,  0.57582186,\n",
       "        0.57261659,  0.57259345,  0.57020905,  0.56991875,  0.56852698,\n",
       "        0.56797157,  0.56529537,  0.56418662,  0.56403305,  0.56216492,\n",
       "        0.56152901,  0.55935232,  0.55875756,  0.55664138,  0.5557401 ,\n",
       "        0.55523423,  0.55487803,  0.55440582,  0.55344548,  0.55267346,\n",
       "        0.55259509,  0.55173483,  0.55173223,  0.54982452,  0.5485642 ,\n",
       "        0.54829549,  0.54740091,  0.54512699,  0.54377514,  0.54302393,\n",
       "        0.54206218,  0.54016977,  0.53890917,  0.5387193 ,  0.53859274,\n",
       "        0.53853979,  0.53770271,  0.53656358,  0.53649939,  0.53291315,\n",
       "        0.53232722,  0.52879307,  0.52802826,  0.52785037,  0.52754221,\n",
       "        0.52721442,  0.52646387,  0.52594175,  0.5259186 ,  0.52485765,\n",
       "        0.52426069,  0.52392826,  0.52384252,  0.52209762,  0.51811626,\n",
       "        0.51722212,  0.51707953,  0.51634937,  0.51627019,  0.51466509,\n",
       "        0.51296712,  0.51281179,  0.51280161,  0.51195804,  0.51077692,\n",
       "        0.5104917 ,  0.50876384,  0.50856627,  0.50835484,  0.50724254,\n",
       "        0.50684292,  0.50633198,  0.5059161 ,  0.50391869,  0.50354471,\n",
       "        0.50308118,  0.50204088,  0.5012906 ,  0.50108251,  0.50080319,\n",
       "        0.49660521,  0.4963998 ,  0.49596311,  0.49432466,  0.49260783,\n",
       "        0.4921073 ,  0.49140512,  0.49120339,  0.49058438,  0.48782488,\n",
       "        0.48680073,  0.48651392,  0.48362012,  0.48133373,  0.4801455 ,\n",
       "        0.47761622,  0.47681669,  0.47512955,  0.47409903,  0.47152691,\n",
       "        0.47120864,  0.47064023,  0.46962089,  0.46912308,  0.46881673,\n",
       "        0.46833321,  0.46799829,  0.46582913,  0.46458326,  0.4631549 ,\n",
       "        0.4629731 ,  0.46187094,  0.46167688,  0.46140927,  0.46058512,\n",
       "        0.4593963 ,  0.45763739,  0.45588793,  0.45333133,  0.45325162,\n",
       "        0.45309422,  0.45247398,  0.45195876,  0.45029103,  0.44968732,\n",
       "        0.44944502,  0.44929946,  0.44854837,  0.44425328,  0.44160769,\n",
       "        0.44044742,  0.43939668,  0.43824109,  0.43560406,  0.4351127 ,\n",
       "        0.43372414,  0.43366724,  0.43354487,  0.43352452,  0.4335113 ,\n",
       "        0.43070995,  0.42875485,  0.42834893,  0.42814624,  0.42753932,\n",
       "        0.42720477,  0.42607835,  0.42601548,  0.42591371,  0.42321851,\n",
       "        0.42278038,  0.42252939,  0.41827629,  0.41820984,  0.41744333,\n",
       "        0.41708656,  0.41498785,  0.41498368,  0.41288205,  0.41274499,\n",
       "        0.40974861,  0.40941996,  0.40917288,  0.40897213,  0.4087657 ,\n",
       "        0.40844673,  0.40638133,  0.40520517,  0.40479401,  0.40223039,\n",
       "        0.399619  ,  0.39877366,  0.39854576,  0.39725837,  0.39658047,\n",
       "        0.39563475,  0.39118088,  0.3902721 ,  0.38994892,  0.38940899,\n",
       "        0.38829415,  0.38744952,  0.38621269,  0.38593459,  0.38587668,\n",
       "        0.38432614,  0.38386413,  0.38379729,  0.38362275,  0.38349185,\n",
       "        0.3831582 ,  0.38311544,  0.3823629 ,  0.38091708,  0.37621333,\n",
       "        0.37556382,  0.37547558,  0.375338  ,  0.37519611,  0.37454339,\n",
       "        0.37361892,  0.37335387,  0.37279327,  0.37188417,  0.37114156,\n",
       "        0.37061843,  0.36984962,  0.36970157,  0.36942599,  0.36878922,\n",
       "        0.36859092,  0.36855009,  0.36812486,  0.36755248,  0.3671209 ,\n",
       "        0.3666529 ,  0.36586676,  0.36566346,  0.36493071,  0.36465031,\n",
       "        0.36411865,  0.36391449,  0.36331639,  0.36296744,  0.36168539,\n",
       "        0.36154949,  0.35866368,  0.35848097,  0.35825383,  0.35692345,\n",
       "        0.35687103,  0.35610642,  0.35578541,  0.35515031,  0.35494764,\n",
       "        0.35393555,  0.35301157,  0.35148603,  0.35080415,  0.3507673 ,\n",
       "        0.35039128,  0.34894432,  0.3489429 ,  0.34746932,  0.34734716,\n",
       "        0.34638933,  0.3453304 ,  0.34487558,  0.34465728,  0.34462634,\n",
       "        0.34439732,  0.34376201,  0.34343826,  0.34210859,  0.33989084,\n",
       "        0.3378958 ,  0.33759512,  0.33705262,  0.33635838,  0.33612076,\n",
       "        0.33593772,  0.33555223,  0.33481618,  0.33410821,  0.33254862,\n",
       "        0.33250314,  0.33129135,  0.33075022,  0.33072962,  0.3304572 ,\n",
       "        0.33040268,  0.32997554,  0.32949508,  0.32906602,  0.32892167,\n",
       "        0.32884836,  0.32837822,  0.32814408,  0.32735042,  0.32537626,\n",
       "        0.32504878,  0.3247207 ,  0.32423725,  0.32343833,  0.32219103,\n",
       "        0.32177173,  0.32133666,  0.3211161 ,  0.32085678,  0.32053802,\n",
       "        0.32000463,  0.31958413,  0.31913251,  0.31740274,  0.31738135,\n",
       "        0.31722401,  0.31699186,  0.31691132,  0.31628464,  0.31606991,\n",
       "        0.31445173,  0.31430191,  0.31419286,  0.31414459,  0.31405563,\n",
       "        0.31344043,  0.3133651 ,  0.31279404,  0.31243722,  0.31177342,\n",
       "        0.31131453,  0.31081297,  0.3097783 ,  0.30918048,  0.30905917,\n",
       "        0.30679595,  0.30668997,  0.30636708,  0.30567917,  0.30488017,\n",
       "        0.30212332,  0.30195362,  0.30184291,  0.30176854,  0.30166801,\n",
       "        0.30107541,  0.30035076,  0.30006088,  0.29924678,  0.29867509,\n",
       "        0.29805917,  0.29793008,  0.29692246,  0.29666507,  0.29588076,\n",
       "        0.29526445,  0.2951008 ,  0.29474456,  0.29463741,  0.2944335 ,\n",
       "        0.29422933,  0.29419305,  0.29384402,  0.29292836,  0.29145154,\n",
       "        0.29058981,  0.29054981,  0.29042373,  0.28927419,  0.28918694,\n",
       "        0.2881176 ,  0.2878429 ,  0.28739168,  0.28712011,  0.28684394,\n",
       "        0.28677374,  0.28671016,  0.28533317,  0.28506455,  0.28451542,\n",
       "        0.28329922,  0.28294544,  0.28260226,  0.28143079,  0.28101465,\n",
       "        0.28040888,  0.27982543,  0.27961542,  0.27911017,  0.27892787,\n",
       "        0.27881005,  0.27858589,  0.2784926 ,  0.27835691,  0.27810184,\n",
       "        0.27724255,  0.27656896,  0.27624736,  0.27622818,  0.27612428,\n",
       "        0.27604772,  0.27602353,  0.27590246,  0.27542671,  0.27488836,\n",
       "        0.274619  ,  0.27444371,  0.27323717,  0.27253929,  0.27147062,\n",
       "        0.2714539 ,  0.27131293,  0.27101109,  0.27037527,  0.27002316,\n",
       "        0.26908178,  0.26908063,  0.2684071 ,  0.26806416,  0.2678495 ,\n",
       "        0.26708249,  0.26627465,  0.26617441,  0.26613775,  0.26610223,\n",
       "        0.26585576,  0.2656773 ,  0.26533134,  0.26460214,  0.26349437,\n",
       "        0.2632998 ,  0.26314198,  0.26290555,  0.26270663,  0.2623821 ,\n",
       "        0.26221101,  0.26203151,  0.26144274,  0.2611151 ,  0.26051554,\n",
       "        0.25988057,  0.25958605,  0.25937264,  0.25929513,  0.25919217,\n",
       "        0.259181  ,  0.25890984,  0.25860834,  0.25788615,  0.25727506,\n",
       "        0.2569727 ,  0.25669931,  0.255665  ,  0.25561769,  0.25491912,\n",
       "        0.25477609,  0.254023  ,  0.25400608,  0.25390535,  0.25342378,\n",
       "        0.25294268,  0.25116737,  0.2510459 ,  0.24959616,  0.24904244,\n",
       "        0.24882304,  0.24832928,  0.24800477,  0.24738422,  0.24565095,\n",
       "        0.24530601,  0.24465134,  0.2445874 ,  0.24387708,  0.24383903,\n",
       "        0.24354037,  0.2429941 ,  0.24218045,  0.24186165,  0.24129416,\n",
       "        0.24089016,  0.24059864,  0.24021155,  0.23899414,  0.2383597 ,\n",
       "        0.23769985,  0.23759759,  0.2375801 ,  0.23739335,  0.23667521,\n",
       "        0.23667427,  0.23640738,  0.23636987,  0.23625578,  0.23525644,\n",
       "        0.23511879,  0.23395327,  0.23388096,  0.2336745 ,  0.23334302,\n",
       "        0.23283878,  0.23278648,  0.23271634,  0.2323742 ,  0.23212986,\n",
       "        0.23111137,  0.23098348,  0.2304717 ,  0.2304688 ,  0.23010338,\n",
       "        0.2294509 ,  0.22916292,  0.22907942,  0.22862786,  0.22847191,\n",
       "        0.22793996,  0.22769788,  0.22765705,  0.22751417,  0.22750972,\n",
       "        0.22712904,  0.22708422,  0.22707554,  0.22676427,  0.22602745,\n",
       "        0.22574554,  0.22481161,  0.22444221,  0.22422233,  0.22405042,\n",
       "        0.22387449,  0.22383114,  0.2236932 ,  0.22356653,  0.22337845,\n",
       "        0.22328052,  0.22309669,  0.2227536 ,  0.2226471 ,  0.22166   ,\n",
       "        0.22099416,  0.22040601,  0.21962061,  0.21951047,  0.21893504,\n",
       "        0.21852777,  0.21843387,  0.21839061,  0.21811744,  0.21796561,\n",
       "        0.21789505,  0.21769206,  0.21758019,  0.21754297,  0.21687659,\n",
       "        0.21622945,  0.21622873,  0.21616102,  0.2159315 ,  0.21525095,\n",
       "        0.21469565,  0.21449656,  0.21434363,  0.21417711,  0.21346379,\n",
       "        0.21325834,  0.21273733,  0.21182383,  0.21165947,  0.2115701 ,\n",
       "        0.21103685,  0.21090555,  0.21080521,  0.2105901 ,  0.20979239,\n",
       "        0.2092146 ,  0.20908283,  0.20782974,  0.20730946,  0.20651309,\n",
       "        0.20641845,  0.2062842 ,  0.20616586,  0.20586834,  0.20508942,\n",
       "        0.20418292,  0.20399016,  0.2039076 ,  0.20387973,  0.2036872 ,\n",
       "        0.20364316,  0.20357291,  0.20292224,  0.20261586,  0.20229919,\n",
       "        0.20223678,  0.20193631,  0.20193323,  0.2018961 ,  0.20129402,\n",
       "        0.20120756,  0.20099747,  0.20020082,  0.20015237,  0.19968626,\n",
       "        0.19955627,  0.19954952,  0.19939156,  0.19933052,  0.19917572,\n",
       "        0.19914405,  0.19901039,  0.19888641,  0.19830306,  0.19813144,\n",
       "        0.19804956,  0.19750271,  0.19729126,  0.1971693 ,  0.19619862,\n",
       "        0.19612232,  0.19553214,  0.19509974,  0.19394675,  0.19389833,\n",
       "        0.19381189,  0.19368103,  0.1933412 ,  0.19304   ,  0.19199427,\n",
       "        0.1915973 ,  0.19136682,  0.19117245,  0.19106997,  0.1908772 ,\n",
       "        0.19018064,  0.19007579,  0.18989514,  0.18973128,  0.18901499,\n",
       "        0.18887503,  0.18766582,  0.18742081,  0.18732265,  0.18715618,\n",
       "        0.18686749,  0.1865507 ,  0.18651313,  0.18644315,  0.18501537,\n",
       "        0.18495446,  0.18493723,  0.18468971,  0.18454804,  0.18448991,\n",
       "        0.18389617,  0.18375204,  0.18370526,  0.18267287,  0.18228698,\n",
       "        0.18227021,  0.18213845,  0.1813363 ,  0.18083466,  0.18076197,\n",
       "        0.18073236,  0.18072737,  0.18069852,  0.18021364,  0.17999015,\n",
       "        0.17990369,  0.17965324,  0.17935554,  0.17931546,  0.17926541,\n",
       "        0.17896488,  0.17876723,  0.17849838,  0.17816168,  0.17803556,\n",
       "        0.17801775,  0.17787404,  0.17729453,  0.17727021,  0.17696744,\n",
       "        0.17683646,  0.17659222,  0.1762683 ,  0.17623558,  0.17551765,\n",
       "        0.17525049,  0.17498456,  0.17487657,  0.17449399,  0.17442425,\n",
       "        0.17434428,  0.17430886,  0.17425917,  0.17396686,  0.17386106,\n",
       "        0.17369485,  0.17367179,  0.17349217,  0.17334426,  0.17331743,\n",
       "        0.17305268,  0.17295665,  0.17269503,  0.17258454,  0.17231878,\n",
       "        0.17217593,  0.17201278,  0.17198315,  0.17171801,  0.17164327,\n",
       "        0.17164281,  0.17144804,  0.17141416,  0.17111687,  0.17097937,\n",
       "        0.17094201,  0.17066485,  0.17050599,  0.17042593,  0.17038318,\n",
       "        0.1703293 ,  0.17030359,  0.17021443,  0.17009798,  0.16997457,\n",
       "        0.16991776,  0.16948809,  0.16945991,  0.16928836,  0.16917034,\n",
       "        0.16913078,  0.16849594,  0.16843983,  0.16821721,  0.16802048,\n",
       "        0.1677291 ,  0.1677008 ,  0.16763588,  0.1673728 ,  0.16733615,\n",
       "        0.16683627,  0.16650856,  0.16631471,  0.16612055,  0.16594057,\n",
       "        0.1658977 ,  0.16581835,  0.16579075,  0.16557736,  0.16539038,\n",
       "        0.16485419,  0.16464318,  0.16444105,  0.16412699,  0.1638659 ,\n",
       "        0.16386206,  0.16374842,  0.16350904,  0.16336616,  0.16295716,\n",
       "        0.16233357,  0.16215299,  0.16190061,  0.16162038,  0.16159721,\n",
       "        0.16120564,  0.1609836 ,  0.16049156,  0.16003517,  0.159701  ,\n",
       "        0.15950674,  0.15928095,  0.15919693,  0.15918926,  0.15916609,\n",
       "        0.15868152,  0.15837748,  0.15835283,  0.15800431,  0.15777752,\n",
       "        0.15774972,  0.1577106 ,  0.15754813,  0.15747899,  0.15731722,\n",
       "        0.1569833 ,  0.15671246,  0.15632627,  0.15541401,  0.15534656,\n",
       "        0.15519098,  0.15484867,  0.15465378,  0.15445084,  0.15426431,\n",
       "        0.15423279,  0.15413028,  0.15397687,  0.15391923,  0.15385153,\n",
       "        0.15359856,  0.15343946,  0.15333326,  0.15333033,  0.15332041,\n",
       "        0.15316376,  0.15307917,  0.15302621,  0.15272384,  0.15255092,\n",
       "        0.15191679,  0.15180232,  0.15173621,  0.15150916,  0.15129289,\n",
       "        0.15097023,  0.15091507,  0.15081274,  0.15067147,  0.15065144,\n",
       "        0.1505908 ,  0.15053091,  0.15028934,  0.1502216 ,  0.15013033,\n",
       "        0.14959793,  0.14949839,  0.14939231,  0.14932077,  0.1493124 ,\n",
       "        0.14927255,  0.14899154,  0.1486213 ,  0.14830936,  0.1482755 ,\n",
       "        0.14796114,  0.14782285,  0.1478227 ,  0.14744918,  0.14742819,\n",
       "        0.14733798,  0.14728949,  0.14709497,  0.1468018 ,  0.14673179,\n",
       "        0.1467243 ,  0.14650229,  0.14646643,  0.14646035,  0.14640986,\n",
       "        0.14627727,  0.14604058,  0.14598312,  0.14570285,  0.14561459,\n",
       "        0.14496058,  0.14492692,  0.14485243,  0.14473491,  0.14469014,\n",
       "        0.14454095,  0.14452858,  0.1441638 ,  0.14415715,  0.14411731,\n",
       "        0.14407532,  0.14402774,  0.14378995,  0.14368899,  0.14351726,\n",
       "        0.143445  ,  0.14334048,  0.14293205,  0.14240911,  0.14212137,\n",
       "        0.14211033,  0.14186154,  0.14175373,  0.14173571,  0.1416746 ,\n",
       "        0.14156615,  0.14154896,  0.14154211,  0.14146437,  0.14134349,\n",
       "        0.14126912,  0.1411861 ,  0.14117358,  0.14111058,  0.14094746,\n",
       "        0.14081824,  0.14058422,  0.14045135,  0.14012943,  0.13984843,\n",
       "        0.13954518,  0.13933386,  0.13919161,  0.13914798,  0.1390189 ,\n",
       "        0.13889512,  0.13873714,  0.13868129,  0.13861729,  0.138574  ,\n",
       "        0.13856072,  0.13845131,  0.13839071,  0.13831205,  0.1379339 ,\n",
       "        0.1378506 ,  0.13772536,  0.13764947,  0.13756771,  0.13756179,\n",
       "        0.13704808,  0.13689599,  0.13668659,  0.13667261,  0.13645276,\n",
       "        0.13599604,  0.13589779,  0.13580696,  0.13574744,  0.13543006,\n",
       "        0.13499709,  0.13498251,  0.13496342,  0.13472767,  0.13469662,\n",
       "        0.13468867,  0.13464868,  0.13455796,  0.13416777,  0.13412942,\n",
       "        0.13410663,  0.13381704,  0.13347859,  0.13345701,  0.13309928,\n",
       "        0.13309152,  0.13277912,  0.13266775,  0.13251589,  0.13222724,\n",
       "        0.13214638,  0.13211112,  0.13169719,  0.13159648,  0.13159451,\n",
       "        0.13159294,  0.13146083,  0.1313022 ,  0.13099448,  0.13094426,\n",
       "        0.13092388,  0.13073382,  0.13072206,  0.13071471,  0.13068376,\n",
       "        0.13063852,  0.13039977,  0.13020619,  0.13018653,  0.13015283,\n",
       "        0.13011367,  0.13009022,  0.12996507,  0.12986089,  0.12980573,\n",
       "        0.12979007,  0.12970578,  0.12937399,  0.12936827,  0.12924994,\n",
       "        0.12913036,  0.12898413,  0.12896989,  0.12896493,  0.12888719,\n",
       "        0.12860312,  0.12854573,  0.12828699,  0.12816479,  0.12807429,\n",
       "        0.12792287,  0.12780242,  0.12750775,  0.12738088,  0.12731198,\n",
       "        0.12728421,  0.12700491,  0.12678488,  0.12669303,  0.12647021,\n",
       "        0.12633009,  0.12621743,  0.12616364,  0.12613062,  0.12611397,\n",
       "        0.12605796,  0.12605139,  0.12589892,  0.12580048,  0.12578154,\n",
       "        0.1256614 ,  0.12536862,  0.12535381,  0.12534089,  0.12532086,\n",
       "        0.12531825,  0.12518373,  0.12506325,  0.12497932,  0.12497684,\n",
       "        0.12489447,  0.12489355,  0.12484284,  0.12480282,  0.12478397,\n",
       "        0.12457163,  0.12450825,  0.12434217,  0.12432925,  0.12405296,\n",
       "        0.12400716,  0.12387221,  0.12375826,  0.12375684,  0.12363269,\n",
       "        0.12337141,  0.12321521,  0.12317955,  0.12313321,  0.12269109,\n",
       "        0.1225934 ,  0.12242268,  0.12200116,  0.12180217,  0.12153527,\n",
       "        0.12143246,  0.12136522,  0.12118044,  0.12108615,  0.12107102,\n",
       "        0.1209196 ,  0.12087987,  0.12086809,  0.12078524,  0.12030979,\n",
       "        0.1198476 ,  0.11983747,  0.11974413,  0.11961064,  0.11955976,\n",
       "        0.11953864,  0.11950167,  0.11919879,  0.11918859,  0.11917111,\n",
       "        0.11915237,  0.1187806 ,  0.11859342,  0.11847714,  0.11845046,\n",
       "        0.11842453,  0.11823203,  0.11822377,  0.11814389,  0.11784946,\n",
       "        0.11772734,  0.11771296,  0.11761715,  0.11736258,  0.11729025,\n",
       "        0.11726798,  0.1172157 ,  0.11686559,  0.11685481,  0.11675259,\n",
       "        0.11668932,  0.11656838,  0.11653007,  0.11651274,  0.11640135,\n",
       "        0.11631485,  0.11577578,  0.11575679,  0.11565563,  0.11560951,\n",
       "        0.11545278,  0.11527917,  0.11527029,  0.11505573,  0.11482118,\n",
       "        0.11450902,  0.11443846,  0.11443099,  0.11438302,  0.11438296,\n",
       "        0.11436854,  0.11403302,  0.11400768,  0.11389584,  0.11379748,\n",
       "        0.11360435,  0.11359869,  0.11350718,  0.11350509,  0.11310844,\n",
       "        0.11307606,  0.11295627,  0.11284619,  0.11269053,  0.11245469,\n",
       "        0.11237897,  0.11235111,  0.11211439,  0.11206397,  0.11158473,\n",
       "        0.11153301,  0.11131356,  0.11128231,  0.11100871,  0.11097951,\n",
       "        0.11070708,  0.11065549,  0.11061975,  0.11060683,  0.11050428,\n",
       "        0.11041489,  0.11023436,  0.11012318,  0.11007546,  0.10998041,\n",
       "        0.10979396,  0.10961815,  0.10954527,  0.10946512,  0.10930447,\n",
       "        0.10920596,  0.10902011,  0.10888624,  0.10888288,  0.10883758,\n",
       "        0.1087388 ,  0.10862123,  0.10852995,  0.10852437,  0.10841787,\n",
       "        0.10836192,  0.10835103,  0.10821167,  0.10820294,  0.10810523,\n",
       "        0.10809784,  0.10809301,  0.1080907 ,  0.1080378 ,  0.10803   ,\n",
       "        0.10750609,  0.107476  ,  0.10743604,  0.1068951 ,  0.10675549,\n",
       "        0.10674533,  0.10642302,  0.10642278,  0.10632191,  0.10626346,\n",
       "        0.10618233,  0.10615969,  0.10612216,  0.10611903,  0.10602893,\n",
       "        0.10602204,  0.10578926,  0.10575516,  0.10574544,  0.1057253 ,\n",
       "        0.10558864,  0.10556784,  0.10556091,  0.10542157,  0.10525188,\n",
       "        0.10517604,  0.10491212,  0.10488868,  0.10483923,  0.10461934,\n",
       "        0.10450981,  0.10444459,  0.10441885,  0.10404185,  0.10382925,\n",
       "        0.10382608,  0.10382563,  0.10362929,  0.10347139,  0.10344525,\n",
       "        0.10317785,  0.10309009,  0.10300565,  0.10294909,  0.10287852,\n",
       "        0.10285066,  0.10281116,  0.10274275,  0.10257787,  0.10255115,\n",
       "        0.10243541,  0.10237701,  0.10225691,  0.10225323,  0.10222164,\n",
       "        0.10222041,  0.10207337,  0.10206157,  0.10204301,  0.10185556,\n",
       "        0.10184094,  0.10161462,  0.10161259,  0.10154445,  0.10138163,\n",
       "        0.10137406,  0.10132238,  0.10113801,  0.10105755,  0.10078958,\n",
       "        0.1007678 ,  0.10069584,  0.10050772,  0.1004009 ,  0.10036929,\n",
       "        0.10025736,  0.10013914,  0.10012814,  0.10009057,  0.10002628,\n",
       "        0.0999779 ,  0.09982555,  0.09957543,  0.09944666,  0.09936165,\n",
       "        0.09930199,  0.09929211,  0.09925135,  0.09923745,  0.09916295,\n",
       "        0.09905812,  0.09903715,  0.09900253,  0.09870191,  0.09863765,\n",
       "        0.09856965,  0.09837116,  0.09814046,  0.09793008,  0.09790081,\n",
       "        0.09785312,  0.097792  ,  0.09778583,  0.09772547,  0.09769384,\n",
       "        0.09755462,  0.09736481,  0.09723573,  0.09720374,  0.09718117,\n",
       "        0.09716246,  0.09708053,  0.09698884,  0.09695326,  0.09685706,\n",
       "        0.09654981,  0.09638546,  0.09625987,  0.09617159,  0.09591528,\n",
       "        0.09571506,  0.09565414,  0.09554195,  0.09553779,  0.09552162,\n",
       "        0.09534533,  0.0952093 ,  0.09520418,  0.09512533,  0.09508733,\n",
       "        0.09504466,  0.09494513,  0.09492713,  0.09485462,  0.09482988,\n",
       "        0.09456886,  0.09452734,  0.09444382,  0.09434294,  0.09429806,\n",
       "        0.09418918,  0.09410657,  0.09404155,  0.09395535,  0.09394813,\n",
       "        0.09393143,  0.09381022,  0.09377654,  0.09368394,  0.09364964,\n",
       "        0.0936244 ,  0.0934787 ,  0.09343848,  0.09341774,  0.09338784,\n",
       "        0.09322707,  0.09298873,  0.09297469,  0.0928957 ,  0.09283008,\n",
       "        0.09252721,  0.09250748,  0.09250595,  0.0924266 ,  0.09227306,\n",
       "        0.09205052,  0.09204665,  0.09203091,  0.09200437,  0.09182382,\n",
       "        0.09164804,  0.09162992,  0.09141082,  0.09120089,  0.09117247,\n",
       "        0.0910928 ,  0.09104797,  0.09103628,  0.09088985,  0.09082884,\n",
       "        0.09081086,  0.09071015,  0.09053366,  0.09040753,  0.09033976,\n",
       "        0.09032475,  0.09015906,  0.09013292,  0.08999769,  0.08989402,\n",
       "        0.08986459,  0.08968936,  0.08935811,  0.08933775,  0.08929464,\n",
       "        0.08907244,  0.08895594,  0.08883789,  0.08874344,  0.08862924,\n",
       "        0.08859807,  0.08857093,  0.08850876,  0.08829824,  0.08785615,\n",
       "        0.08774645,  0.08772738,  0.08752057,  0.08736621,  0.08732554,\n",
       "        0.08722661,  0.08711137,  0.08702609,  0.08702103,  0.08701566,\n",
       "        0.0869569 ,  0.08684171,  0.08683501,  0.08675989,  0.08674968,\n",
       "        0.08659059,  0.08658575,  0.08647687,  0.08643705,  0.08635575,\n",
       "        0.08626656,  0.08623379,  0.08615712,  0.08578255,  0.08572272,\n",
       "        0.08569714,  0.08568039,  0.08547563,  0.08546979,  0.08536045,\n",
       "        0.0851658 ,  0.08513811,  0.08512013,  0.08501079,  0.08484557,\n",
       "        0.08484047,  0.08470848,  0.08461162,  0.08457754,  0.0845747 ,\n",
       "        0.08453995,  0.08441558,  0.08430026,  0.08429323,  0.08425758,\n",
       "        0.08416234,  0.08414132,  0.08403829,  0.0839633 ,  0.08390995,\n",
       "        0.08381977,  0.08371928,  0.08357335,  0.08355153,  0.08322192,\n",
       "        0.08316496,  0.08304666,  0.08291127,  0.08287841,  0.08273183,\n",
       "        0.08266741,  0.08262534,  0.08260341,  0.08259777,  0.08245041,\n",
       "        0.08238163,  0.08231855,  0.08218717,  0.08190009,  0.08188362,\n",
       "        0.08185205,  0.08174828,  0.08167108,  0.08164232,  0.08160972,\n",
       "        0.08155706,  0.08153057,  0.08148357,  0.08148079,  0.08133117,\n",
       "        0.08126303,  0.08122213,  0.08117382,  0.08115292,  0.08108114,\n",
       "        0.08097735,  0.0808625 ,  0.08085162,  0.08080954,  0.08079441,\n",
       "        0.08078645,  0.08077345,  0.0807503 ,  0.08074585,  0.08074024,\n",
       "        0.08068382,  0.08050741,  0.08041235,  0.08037566,  0.08023134,\n",
       "        0.08010364,  0.07999189,  0.07993447,  0.07992731,  0.07971832,\n",
       "        0.07961882,  0.07958706,  0.07954682,  0.0794194 ,  0.07935472,\n",
       "        0.079236  ,  0.07901636,  0.07877589,  0.07864399,  0.07859122,\n",
       "        0.07853288,  0.07796629,  0.07786147,  0.07772162,  0.0776958 ,\n",
       "        0.07768998,  0.0776843 ,  0.07766222,  0.07761972,  0.07761287,\n",
       "        0.07750735,  0.07742703,  0.07737836,  0.0771032 ,  0.07707091,\n",
       "        0.07705279,  0.0769045 ,  0.07687865,  0.0766797 ,  0.07654045,\n",
       "        0.07636675,  0.07630306,  0.07624274,  0.07614828,  0.0760127 ,\n",
       "        0.0760031 ,  0.0759917 ,  0.07589299,  0.07583308,  0.07570931,\n",
       "        0.07570755,  0.07563111,  0.07542092,  0.07541231,  0.07534616,\n",
       "        0.07524918,  0.0751742 ,  0.07515995,  0.07513486,  0.07508502,\n",
       "        0.07501751,  0.07500693,  0.07497005,  0.07459033,  0.07448557,\n",
       "        0.07444967,  0.07444179,  0.07442831,  0.07440277,  0.07429307,\n",
       "        0.07424076,  0.0742092 ,  0.07416043,  0.07412379,  0.07405044,\n",
       "        0.07391174,  0.07376904,  0.07366951,  0.07364826,  0.07358939,\n",
       "        0.07358504,  0.07352853,  0.07339987,  0.07321195,  0.07307086,\n",
       "        0.07295783,  0.07282369,  0.0728197 ,  0.07278772,  0.07266467,\n",
       "        0.07265697,  0.07246909,  0.07245178,  0.07244238,  0.07239653,\n",
       "        0.07234792,  0.0723283 ,  0.07232196,  0.07230467,  0.07225311,\n",
       "        0.07223626,  0.07217948,  0.07217881,  0.07212155,  0.07210187,\n",
       "        0.07203089,  0.07199405,  0.071983  ,  0.07194979,  0.0716778 ,\n",
       "        0.0716254 ,  0.07162127,  0.07159637,  0.07154907,  0.07154492,\n",
       "        0.07149975,  0.07148739,  0.0714625 ,  0.07137609,  0.07137468,\n",
       "        0.07136761,  0.07131477,  0.07125999,  0.07121836,  0.07121425,\n",
       "        0.07113955,  0.07096303,  0.07095781,  0.07095429,  0.07085911,\n",
       "        0.07085351,  0.07077494,  0.07075712,  0.0707209 ,  0.07071901,\n",
       "        0.07067616,  0.07067165,  0.0706685 ,  0.07054747,  0.070477  ,\n",
       "        0.07046271,  0.07041528,  0.07038825,  0.07025948,  0.07024932,\n",
       "        0.07016052,  0.07015981,  0.07009231,  0.07005463,  0.06991829,\n",
       "        0.06990252,  0.06984094,  0.06977403,  0.06975529,  0.06972511,\n",
       "        0.06972404,  0.06969448,  0.0696058 ,  0.06957425,  0.06954189,\n",
       "        0.06953388,  0.06953054,  0.06936218,  0.06935108,  0.06934679,\n",
       "        0.06934288,  0.06932934,  0.06923605,  0.06912477,  0.0690508 ,\n",
       "        0.06904752,  0.06886872,  0.06886064,  0.06883857,  0.06871049,\n",
       "        0.06861675,  0.06861211,  0.06850301,  0.06822216,  0.06820539,\n",
       "        0.0681443 ,  0.06814339,  0.06806066,  0.06805317,  0.06804338,\n",
       "        0.0680059 ,  0.06786698,  0.06783968,  0.06781902,  0.06781366,\n",
       "        0.06778377,  0.06778344,  0.06775946,  0.06775896,  0.06773432,\n",
       "        0.06766131,  0.06763718,  0.06753023,  0.06743624,  0.06742988,\n",
       "        0.06741621,  0.067387  ,  0.06738287,  0.06733975,  0.06733838,\n",
       "        0.06727686,  0.06724182,  0.06719175,  0.06701533,  0.06682773,\n",
       "        0.06671887,  0.06668628,  0.0666258 ,  0.06658418,  0.06650539,\n",
       "        0.06650182,  0.06646736,  0.06646119,  0.06638624,  0.06624713,\n",
       "        0.06624094,  0.06614247,  0.06614243,  0.06603592,  0.06603072,\n",
       "        0.06586712,  0.06575966,  0.06573993,  0.06568287,  0.06557937,\n",
       "        0.0655703 ,  0.06547823,  0.06540683,  0.06516823,  0.06511688,\n",
       "        0.06503782,  0.06500153,  0.06492981,  0.06489307,  0.06488656,\n",
       "        0.06481291,  0.06481049,  0.0647705 ,  0.06469813,  0.06460001,\n",
       "        0.06454875,  0.06446522,  0.06445899,  0.06441665,  0.06431283,\n",
       "        0.06427666,  0.06410545,  0.06405945,  0.06390425,  0.06379965,\n",
       "        0.06373839,  0.06369697,  0.06347816,  0.06344137,  0.06341702,\n",
       "        0.06335028,  0.063307  ,  0.06329757,  0.06324808,  0.06320229,\n",
       "        0.06317701,  0.06312312,  0.06309651,  0.06296928,  0.06292825,\n",
       "        0.0628583 ,  0.06275718,  0.06274317,  0.06246322,  0.06231988,\n",
       "        0.06227359,  0.06226218,  0.06221217,  0.06219525,  0.06202407,\n",
       "        0.06199397,  0.06198209,  0.06194664,  0.06191088,  0.06182001,\n",
       "        0.06177697,  0.06176836,  0.06173192,  0.06154327,  0.0614957 ,\n",
       "        0.06131991,  0.0613064 ,  0.06122999,  0.0611401 ,  0.06106773,\n",
       "        0.06106754,  0.06096789,  0.06094452,  0.06093598,  0.06083827,\n",
       "        0.06083176,  0.06069198,  0.06060539,  0.06050368,  0.06047056,\n",
       "        0.06041424,  0.06041082,  0.06040365,  0.06040094,  0.06038774,\n",
       "        0.06026565,  0.06023384,  0.06017879,  0.06017613,  0.06016564,\n",
       "        0.06016458,  0.06016209,  0.06006462,  0.06000671,  0.05991327,\n",
       "        0.0598994 ,  0.05977086,  0.05974773,  0.05965542,  0.05949935,\n",
       "        0.05943136,  0.05939204,  0.05937044,  0.05927863,  0.05914329,\n",
       "        0.05909449,  0.05907143,  0.05902998,  0.05893907,  0.05892562,\n",
       "        0.05891859,  0.0589103 ,  0.05878578,  0.05876834,  0.05875222,\n",
       "        0.05858258,  0.05854723,  0.05852922,  0.0584844 ,  0.05847844,\n",
       "        0.05845803,  0.05844723,  0.05835148,  0.05820882,  0.05813943,\n",
       "        0.05803933,  0.05800845,  0.05799675,  0.05793383,  0.05789899,\n",
       "        0.0578209 ,  0.05776727,  0.05767023,  0.05762022,  0.05761064,\n",
       "        0.0575983 ,  0.0575289 ,  0.05736656,  0.05736386,  0.05735545,\n",
       "        0.05732122,  0.0573048 ,  0.05729059,  0.05716996,  0.05700036,\n",
       "        0.05675145,  0.05667104,  0.05666171,  0.0565531 ,  0.05649806,\n",
       "        0.05646115,  0.05636837,  0.05633971,  0.05628045,  0.05624619,\n",
       "        0.05623994,  0.05618241,  0.05615781,  0.05613864,  0.05599891,\n",
       "        0.05590665,  0.05586743,  0.05580891,  0.05571244,  0.0556112 ,\n",
       "        0.05545037,  0.0553034 ,  0.05530149,  0.05529948,  0.05510584,\n",
       "        0.05498246,  0.05496752,  0.05495218,  0.05487223,  0.0548212 ,\n",
       "        0.05465152,  0.05463302,  0.05458278,  0.05458018,  0.05431185,\n",
       "        0.05428023,  0.05427959,  0.05426626,  0.05423871,  0.05391725,\n",
       "        0.05364848,  0.05363582,  0.0536229 ,  0.0535986 ,  0.05349717,\n",
       "        0.05346089,  0.05341773,  0.05333159,  0.05329441,  0.05325772,\n",
       "        0.05318534,  0.05315679,  0.05311278,  0.05310198,  0.05288367,\n",
       "        0.05270423,  0.05267131,  0.05265288,  0.05260516,  0.05258707,\n",
       "        0.0525736 ,  0.05253155,  0.05250234,  0.05249457,  0.05242639,\n",
       "        0.05242299,  0.05242039,  0.05236374,  0.05234154,  0.05231391,\n",
       "        0.05225596,  0.05218114,  0.05217227,  0.05214124,  0.05210927,\n",
       "        0.05209143,  0.0520197 ,  0.05198474,  0.0518985 ,  0.05184469,\n",
       "        0.05180608,  0.05175786,  0.05173591,  0.05172688,  0.05170948,\n",
       "        0.0516555 ,  0.05163593,  0.05151611,  0.05150199,  0.05148255,\n",
       "        0.05145924,  0.0514068 ,  0.05131275,  0.0510377 ,  0.05103606,\n",
       "        0.0510318 ,  0.05102364,  0.05102306,  0.05099102,  0.05096613,\n",
       "        0.05084475,  0.05077366,  0.05072474,  0.05071908,  0.05069331,\n",
       "        0.05066035,  0.0506476 ,  0.05064284,  0.05060025,  0.05057827,\n",
       "        0.0504961 ,  0.05041869,  0.05039922,  0.05033736,  0.05031006,\n",
       "        0.05028697,  0.0502703 ,  0.05025712,  0.0502157 ,  0.05013939,\n",
       "        0.04992181,  0.04991047,  0.04985434,  0.0498539 ,  0.04971108,\n",
       "        0.04970046,  0.04967352,  0.04942326,  0.04938462,  0.04922509,\n",
       "        0.049139  ,  0.04905377,  0.04898178,  0.04889074,  0.04888923,\n",
       "        0.04883034,  0.04877302,  0.04873571,  0.04873012,  0.04858136,\n",
       "        0.04844171,  0.04841797,  0.04839523,  0.04828322,  0.04820195,\n",
       "        0.04816527,  0.04814077,  0.04808594,  0.0480467 ,  0.04803504,\n",
       "        0.04803011,  0.04800261,  0.04796995,  0.04792428,  0.0479088 ,\n",
       "        0.04789027,  0.04784937,  0.04782017,  0.04781161,  0.04775718,\n",
       "        0.04774915,  0.04742702,  0.04742181,  0.04741728,  0.04736837,\n",
       "        0.04736649,  0.04734848,  0.04728925,  0.04723305,  0.04719918,\n",
       "        0.04712105,  0.04710696,  0.04705489,  0.04704069,  0.04703688,\n",
       "        0.04703568,  0.0470356 ,  0.04703554,  0.04703551,  0.04699237,\n",
       "        0.04695734,  0.04692294,  0.04691287,  0.04691121,  0.04685761,\n",
       "        0.04684173,  0.04680503,  0.04677883,  0.04674272,  0.04657829,\n",
       "        0.04656839,  0.04653338,  0.04650034,  0.04649904,  0.04648112,\n",
       "        0.04647927,  0.04643075,  0.04641388,  0.04640894,  0.04635766,\n",
       "        0.04635347,  0.0461968 ,  0.04617899,  0.04614617,  0.04611211,\n",
       "        0.04610762,  0.0460753 ,  0.0460373 ,  0.04599506,  0.04596371,\n",
       "        0.04591614,  0.0458703 ,  0.04582395,  0.04580112,  0.04576471,\n",
       "        0.04576471,  0.04573104,  0.04563029,  0.04551437,  0.04540106,\n",
       "        0.0453909 ,  0.04538562,  0.04534049,  0.04532297,  0.04529368,\n",
       "        0.04525299,  0.04523835,  0.04520889,  0.04515096,  0.04513891,\n",
       "        0.04510554,  0.04509849,  0.04509711,  0.04509709,  0.04509705,\n",
       "        0.04509698,  0.04507242,  0.04505514,  0.04495765,  0.04493333,\n",
       "        0.04491157,  0.04486863,  0.04479492,  0.0447669 ,  0.04472047,\n",
       "        0.04464991,  0.04464951,  0.04459314,  0.0445931 ,  0.04459303,\n",
       "        0.044593  ,  0.04455836,  0.04455003,  0.04447942,  0.04443409,\n",
       "        0.04433888,  0.0443024 ,  0.04428941,  0.04422057,  0.04422053,\n",
       "        0.04422042,  0.04422042,  0.04415145,  0.04413143,  0.04404374,\n",
       "        0.04395972,  0.04393358,  0.04392193,  0.04391074,  0.04384879,\n",
       "        0.04374291,  0.04374255,  0.04371915,  0.04363698,  0.04362551,\n",
       "        0.04361831,  0.04351613,  0.04350312,  0.04348286,  0.04334681,\n",
       "        0.04334531,  0.04333965,  0.04331715,  0.04331177,  0.04327463,\n",
       "        0.04326646,  0.04324527,  0.04322327,  0.043151  ,  0.04311965,\n",
       "        0.04309235,  0.04309022,  0.04297662,  0.04297186,  0.04294671,\n",
       "        0.0429251 ,  0.04292472,  0.04292467,  0.04292462,  0.04292459,\n",
       "        0.04288154,  0.04287693,  0.04287277,  0.04284997,  0.04283963,\n",
       "        0.04283071,  0.04281679,  0.04273564,  0.04273266,  0.0427164 ,\n",
       "        0.04267312,  0.04264671,  0.04251737,  0.04247091,  0.04237856,\n",
       "        0.04207203,  0.04206425,  0.04206418,  0.04206413,  0.04206407,\n",
       "        0.04205728,  0.04204146,  0.04198377,  0.04197492,  0.04181039,\n",
       "        0.04178005,  0.04177727,  0.04173545,  0.04171816,  0.04169588,\n",
       "        0.04166541,  0.04157504,  0.04156848,  0.04146094,  0.04145161,\n",
       "        0.04135886,  0.04132511,  0.0412662 ,  0.04118887,  0.04117408,\n",
       "        0.0411521 ,  0.04107566,  0.0410716 ,  0.04105927,  0.04099025,\n",
       "        0.04093925,  0.04093918,  0.04093913,  0.04093909,  0.04093718,\n",
       "        0.04092835,  0.04080827,  0.04071653,  0.0406925 ,  0.04067209,\n",
       "        0.04066544,  0.04063474,  0.04063   ,  0.04061998,  0.04058249,\n",
       "        0.04054842,  0.04053283,  0.04052109,  0.04050724,  0.04045239,\n",
       "        0.04043627,  0.04043622,  0.0404362 ,  0.04043616,  0.0404326 ,\n",
       "        0.04038611,  0.0403796 ,  0.04036536,  0.04034785,  0.04033157,\n",
       "        0.04032825,  0.0402377 ,  0.04021342,  0.04016048,  0.04012603,\n",
       "        0.04012132,  0.04010218,  0.04009707,  0.03999905,  0.03986779,\n",
       "        0.03985797,  0.03983564,  0.0397864 ,  0.03976039,  0.03973832,\n",
       "        0.03962917,  0.03956684,  0.03953788,  0.03952512,  0.03951974,\n",
       "        0.0394659 ,  0.03945355,  0.03943688,  0.03943473,  0.0393243 ,\n",
       "        0.03931285,  0.03930774,  0.03927106,  0.03926095,  0.03925033,\n",
       "        0.03924233,  0.03920824,  0.0391986 ,  0.03917622,  0.03915625,\n",
       "        0.03913836,  0.03913313,  0.03911345,  0.03910219,  0.03906084,\n",
       "        0.03904427,  0.03903498,  0.03889173,  0.03889167,  0.0388916 ,\n",
       "        0.03889156,  0.03887522,  0.03883611,  0.03882447,  0.03881903,\n",
       "        0.03879997,  0.03878376,  0.03877297,  0.03875639,  0.03870646,\n",
       "        0.03864727,  0.03860561,  0.03855526,  0.03855102,  0.0385382 ,\n",
       "        0.03851073,  0.03846194,  0.03844829,  0.03837278,  0.03832026,\n",
       "        0.0382626 ,  0.03822536,  0.03821466,  0.03816813,  0.03815283,\n",
       "        0.03808266,  0.03802806,  0.03799271,  0.03791688,  0.03784926,\n",
       "        0.0377884 ,  0.03778373,  0.03771391,  0.03766541,  0.03759994,\n",
       "        0.03754693,  0.03747315,  0.03743658,  0.03742142,  0.03740103,\n",
       "        0.03740102,  0.03735907,  0.03734747,  0.03731431,  0.03729608,\n",
       "        0.03727167,  0.0372523 ,  0.03725228,  0.03725224,  0.03725221,\n",
       "        0.03724772,  0.03723243,  0.03722144,  0.03714896,  0.03713801,\n",
       "        0.03712844,  0.0371242 ,  0.03712318,  0.03711941,  0.03711685,\n",
       "        0.03709273,  0.0370791 ,  0.03706388,  0.03704202,  0.03702815,\n",
       "        0.03700503,  0.03696626,  0.03693362,  0.03688643,  0.03681947,\n",
       "        0.03680087,  0.03675974,  0.03671662,  0.03668198,  0.03668191,\n",
       "        0.03668177,  0.03668169,  0.0366722 ,  0.03665908,  0.03659976,\n",
       "        0.03656745,  0.03653265,  0.03651207,  0.03644767,  0.03641413,\n",
       "        0.03637899,  0.03636593,  0.03636034,  0.0363229 ,  0.03632229,\n",
       "        0.03630457,  0.03630151,  0.03624883,  0.03620511,  0.03617248,\n",
       "        0.03613531,  0.03611362,  0.03602674,  0.03602532,  0.03599955,\n",
       "        0.03599187,  0.03594335,  0.03593267,  0.03592921,  0.03591381,\n",
       "        0.03590306,  0.03589177,  0.03586159,  0.03586108,  0.03586052,\n",
       "        0.03582318,  0.0357308 ,  0.03564745,  0.03563284,  0.03560238,\n",
       "        0.03547454,  0.03543759,  0.03537026,  0.03532408,  0.03532223,\n",
       "        0.03530319,  0.03527378,  0.03527377,  0.03527198,  0.03525941,\n",
       "        0.03519206,  0.0351638 ,  0.03513173,  0.03511362,  0.03511359,\n",
       "        0.03511351,  0.03511348,  0.0350683 ,  0.03506409,  0.03504432,\n",
       "        0.0350443 ,  0.03504421,  0.03504417,  0.0350359 ,  0.03502379,\n",
       "        0.03499856,  0.03484703,  0.03480839,  0.03475612,  0.03474048,\n",
       "        0.03468684,  0.03467884,  0.03466953,  0.03463403,  0.03462349,\n",
       "        0.03460432,  0.03455705,  0.03453425,  0.03452992,  0.03452589,\n",
       "        0.03447631,  0.03446725,  0.03443396,  0.03436539,  0.03435915,\n",
       "        0.03435024,  0.03433615,  0.03432672,  0.03423414,  0.03423034,\n",
       "        0.03414703,  0.03405542,  0.03402242,  0.03397776,  0.03392133,\n",
       "        0.03390119,  0.03377645,  0.03377222,  0.03373615,  0.03364471,\n",
       "        0.03362165,  0.0336101 ,  0.03360306,  0.03359088,  0.03358877,\n",
       "        0.03356012,  0.03355996,  0.03354239,  0.03352963,  0.03352289,\n",
       "        0.03344896,  0.03340996,  0.03335808,  0.0333063 ,  0.03327434,\n",
       "        0.0332713 ,  0.03327128,  0.03327125,  0.0332712 ,  0.0332227 ,\n",
       "        0.03318727,  0.03317773,  0.03316727,  0.03316095,  0.03310358,\n",
       "        0.03307762,  0.03307348,  0.03305391,  0.0330203 ,  0.03301525,\n",
       "        0.03295603,  0.0329354 ,  0.03292528,  0.03292151,  0.03283854,\n",
       "        0.03281119,  0.03279315,  0.03271796,  0.0327062 ,  0.03261905,\n",
       "        0.03253175,  0.03246599,  0.03239445,  0.03234428,  0.03229246,\n",
       "        0.03228135,  0.03217353,  0.03215752,  0.03215346,  0.03206941,\n",
       "        0.03204445,  0.03196267,  0.0319551 ,  0.03189826,  0.03179822,\n",
       "        0.03174274,  0.03169129,  0.03168797,  0.03167966,  0.03167633,\n",
       "        0.03165122,  0.03159514,  0.03158201,  0.03156888,  0.031568  ,\n",
       "        0.03153026,  0.03150263,  0.03146424,  0.03146417,  0.0314485 ,\n",
       "        0.0313666 ,  0.03136517,  0.03135687,  0.03132197,  0.03130764,\n",
       "        0.03129842,  0.03120193,  0.0312019 ,  0.03120182,  0.03120176,\n",
       "        0.03117616,  0.03114571,  0.03114194,  0.03112886,  0.03109661,\n",
       "        0.03108205,  0.03106053,  0.03096716,  0.03096645,  0.03096102,\n",
       "        0.03092812,  0.03091016,  0.03089547,  0.03088061,  0.03085758,\n",
       "        0.03085142,  0.03082298,  0.03081002,  0.03076498,  0.03074105,\n",
       "        0.03073962,  0.03072933,  0.03071679,  0.03070682,  0.03065947,\n",
       "        0.0306535 ,  0.03061945,  0.03060168,  0.03051192,  0.03047712,\n",
       "        0.03047708,  0.03047701,  0.03047696,  0.03045684,  0.03039741,\n",
       "        0.03035529,  0.03030146,  0.03029291,  0.03023413,  0.0302079 ,\n",
       "        0.03019072,  0.03018072,  0.03011674,  0.03008187,  0.03007355,\n",
       "        0.03002164,  0.03000506,  0.02998099,  0.02992946,  0.02991625,\n",
       "        0.029879  ,  0.0298786 ,  0.02986307,  0.02979466,  0.02975552,\n",
       "        0.02975236,  0.02972671,  0.02967531,  0.02967095,  0.02966231,\n",
       "        0.02964838,  0.02964063,  0.02962284,  0.02961886,  0.02960965,\n",
       "        0.02957971,  0.02955039,  0.02954192,  0.02953157,  0.02949539,\n",
       "        0.02946303,  0.02935342,  0.02934881,  0.02934558,  0.02923145,\n",
       "        0.02918517,  0.02917018,  0.02913564,  0.02911684,  0.02909983,\n",
       "        0.02908254,  0.02908198,  0.02905818,  0.02905297,  0.0290239 ,\n",
       "        0.02901476,  0.02900986,  0.02891296,  0.02890514,  0.02887724,\n",
       "        0.02881421,  0.02878241,  0.02877467,  0.02877402,  0.02872644,\n",
       "        0.02872264,  0.02869673,  0.02869669,  0.02868266,  0.02865694,\n",
       "        0.0286373 ,  0.02861057,  0.02858987,  0.02857365,  0.02853737,\n",
       "        0.02853735,  0.02853729,  0.02853726,  0.02851322,  0.02851317,\n",
       "        0.02851311,  0.02851306,  0.02849158,  0.02844612,  0.02840782,\n",
       "        0.0284007 ,  0.02838017,  0.02833348,  0.02831196,  0.02829183,\n",
       "        0.02824648,  0.02823621,  0.02821458,  0.0281932 ,  0.02817691,\n",
       "        0.02817293,  0.02817256,  0.02816898,  0.02816388,  0.02816077,\n",
       "        0.02815967,  0.0281256 ,  0.02812393,  0.0281223 ,  0.02812229,\n",
       "        0.02811821,  0.02811817,  0.02811809,  0.02811807,  0.02810658,\n",
       "        0.0280995 ,  0.02806902,  0.02806441,  0.02802423,  0.02802129,\n",
       "        0.02801204,  0.02800419,  0.02799762,  0.02799323,  0.02797461,\n",
       "        0.02793768,  0.02791181,  0.02790321,  0.02790239,  0.02790195,\n",
       "        0.02789275,  0.0278331 ,  0.02779828,  0.02778003,  0.02774106,\n",
       "        0.02771712,  0.02770897,  0.02769981,  0.02766647,  0.02763806,\n",
       "        0.02762187,  0.02761012,  0.02758729,  0.02758665,  0.02758448,\n",
       "        0.02756024,  0.02755985,  0.02752761,  0.02751768,  0.02751761,\n",
       "        0.02751574,  0.02749496,  0.0274077 ,  0.02732436,  0.02732255,\n",
       "        0.02727855,  0.02726193,  0.02723375,  0.02719611,  0.02716123,\n",
       "        0.02715929,  0.02715607,  0.0271558 ,  0.02710528,  0.02709304,\n",
       "        0.02707298,  0.02707118,  0.02702299,  0.02700052,  0.0269986 ,\n",
       "        0.02699261,  0.02697928,  0.02694965,  0.02694889,  0.02693022,\n",
       "        0.02689421,  0.0268876 ,  0.02684814,  0.02683531,  0.02683103,\n",
       "        0.02682834,  0.02676867,  0.02674728,  0.02673224,  0.02670509,\n",
       "        0.0266937 ,  0.02669357,  0.02661354,  0.02660091,  0.02658189,\n",
       "        0.02653827,  0.02653664,  0.02649228,  0.02649049,  0.02647958,\n",
       "        0.02646809,  0.02641166,  0.0263612 ,  0.02629604,  0.02626579,\n",
       "        0.02622184,  0.02620362,  0.02619484,  0.02618848,  0.02617767,\n",
       "        0.02615438,  0.02614484,  0.02613351,  0.02612331,  0.02612071,\n",
       "        0.02611828,  0.02610984,  0.02609292,  0.02598035,  0.02595371,\n",
       "        0.02593712,  0.02593496,  0.02589067,  0.02581353,  0.02577544,\n",
       "        0.02574072,  0.02573038,  0.02572591,  0.02564107,  0.02561996,\n",
       "        0.02560382,  0.02560179,  0.02558836,  0.02556786,  0.02555005,\n",
       "        0.02550752,  0.02550603,  0.02548542,  0.02548346,  0.02548239,\n",
       "        0.02548187,  0.02540426,  0.02538369,  0.02536936,  0.02536908,\n",
       "        0.02535926,  0.0253504 ,  0.02533411,  0.02530995,  0.02527733,\n",
       "        0.02526335,  0.02523778,  0.02522645,  0.02521778,  0.02521121,\n",
       "        0.02518236,  0.02515825,  0.02514869,  0.02513323,  0.02511975,\n",
       "        0.02505611,  0.02503413,  0.02502874,  0.02502243,  0.02501615,\n",
       "        0.0250089 ,  0.02497941,  0.02497587,  0.02496866,  0.02494975,\n",
       "        0.02494154,  0.02493343,  0.02487695,  0.02487652,  0.02486526,\n",
       "        0.02486348,  0.02484187,  0.02483682,  0.02483594,  0.02483039,\n",
       "        0.02478619,  0.02476396,  0.02469849,  0.02468082,  0.02466751,\n",
       "        0.0246138 ,  0.02461204,  0.02458433,  0.02453738,  0.02449851,\n",
       "        0.02449183,  0.02446971,  0.0244604 ,  0.02445187,  0.0244174 ,\n",
       "        0.02438792,  0.02435516,  0.02433715,  0.02433316,  0.02432704,\n",
       "        0.02430005,  0.02427321,  0.02426334,  0.02418232,  0.02411791,\n",
       "        0.02407349,  0.02404547,  0.02404498,  0.02403992,  0.0240278 ,\n",
       "        0.02401819,  0.02390339,  0.02383639,  0.02382614,  0.0237813 ,\n",
       "        0.02378116,  0.0237384 ,  0.0237038 ,  0.02368298,  0.02365656,\n",
       "        0.02364688,  0.02363297,  0.0236237 ,  0.02361507,  0.02361213,\n",
       "        0.02359678,  0.02354388,  0.02354042,  0.0235393 ,  0.02351268,\n",
       "        0.02350627,  0.02349688,  0.02349078,  0.02343922,  0.02343758,\n",
       "        0.02343753,  0.0234375 ,  0.02343747,  0.02340943,  0.0234019 ,\n",
       "        0.02336576,  0.02334951,  0.02334656,  0.02332431,  0.02329966,\n",
       "        0.0232416 ,  0.02321552,  0.02320898,  0.02319778,  0.02319636,\n",
       "        0.02317368,  0.02315071,  0.02305009,  0.0230492 ,  0.02298466,\n",
       "        0.02298041,  0.02296978,  0.02296089,  0.02293495,  0.02293312,\n",
       "        0.02292001,  0.02285102,  0.02280438,  0.02280193,  0.0227826 ,\n",
       "        0.02277965,  0.02274135,  0.02272227,  0.02270876,  0.02269337,\n",
       "        0.02265791,  0.02263374,  0.02262817,  0.02262785,  0.02261289,\n",
       "        0.02260829,  0.02253227,  0.02251216,  0.02250881,  0.02247841,\n",
       "        0.02239031,  0.02238779,  0.02235977,  0.02232492,  0.02228225,\n",
       "        0.02228214,  0.02226313,  0.02225034,  0.02222722,  0.0222134 ,\n",
       "        0.02215926,  0.02213924,  0.02212308,  0.02209874,  0.0220963 ,\n",
       "        0.0220909 ,  0.02207201,  0.02206931,  0.02206199,  0.02201872,\n",
       "        0.02199939,  0.02197802,  0.02193304,  0.02191746,  0.02191014,\n",
       "        0.02190486,  0.02187702,  0.02186505,  0.02185188,  0.02184591,\n",
       "        0.02184433,  0.02183554,  0.02180954,  0.0217904 ,  0.02176745,\n",
       "        0.02173455,  0.02169146,  0.02167431,  0.02167241,  0.02166959,\n",
       "        0.02165209,  0.02160252,  0.02152988,  0.02152021,  0.02150838,\n",
       "        0.02150454,  0.02149137,  0.02148429,  0.02148334,  0.02146591,\n",
       "        0.02144558,  0.0214364 ,  0.02143135,  0.02142925,  0.02140995,\n",
       "        0.02138638,  0.02134286,  0.02130885,  0.02130732,  0.02128198,\n",
       "        0.0212631 ,  0.02125527,  0.02124564,  0.02122902,  0.02121244,\n",
       "        0.02121156,  0.02119656,  0.02117758,  0.02117409,  0.0211587 ,\n",
       "        0.02113784,  0.02111992,  0.02108576,  0.02107022,  0.02103417,\n",
       "        0.0210285 ,  0.02100488,  0.02100488,  0.02100487,  0.02100487,\n",
       "        0.02099256,  0.02098973,  0.02096134,  0.02096103,  0.02093569,\n",
       "        0.02093358,  0.0209229 ,  0.0208986 ,  0.02088923,  0.02088032,\n",
       "        0.02074489,  0.02073988,  0.02073566,  0.02072683,  0.02072162,\n",
       "        0.02068691,  0.02065749,  0.02064904,  0.02063666,  0.02060398,\n",
       "        0.02058326,  0.02058225,  0.02057031,  0.02055115,  0.02055033,\n",
       "        0.02054404,  0.02053715,  0.02053457,  0.02053318,  0.02051593,\n",
       "        0.02047194,  0.0204597 ,  0.02043195,  0.02042437,  0.02041664,\n",
       "        0.02040717,  0.02036737,  0.02036504,  0.02028894,  0.02027235,\n",
       "        0.02023264,  0.02023047,  0.0202199 ,  0.02019738,  0.02015556,\n",
       "        0.02013826,  0.02013119,  0.02011764,  0.02011174,  0.02009963,\n",
       "        0.02009156,  0.02006396,  0.02004064,  0.020022  ,  0.020022  ,\n",
       "        0.02002198,  0.02002198,  0.01999498,  0.01997192,  0.01995508,\n",
       "        0.01994978,  0.01992999,  0.01989778,  0.01987303,  0.01986215,\n",
       "        0.0198411 ,  0.01982489,  0.01981725,  0.01978937,  0.01976697,\n",
       "        0.0197614 ,  0.01974846,  0.01972248,  0.01970999,  0.01970951,\n",
       "        0.01969547,  0.01965745,  0.01965312,  0.01964216,  0.01963827,\n",
       "        0.01963346,  0.01960308,  0.01959939,  0.01959842,  0.01954547,\n",
       "        0.01954219,  0.01953689,  0.01947459,  0.01947285,  0.01946129,\n",
       "        0.0194567 ,  0.01945203,  0.01945096,  0.01945084,  0.01943148,\n",
       "        0.01942009,  0.01940726,  0.01940061,  0.01939873,  0.01936659,\n",
       "        0.0193576 ,  0.01934499,  0.01933109,  0.01932523,  0.01931407,\n",
       "        0.01931043,  0.01930221,  0.01929602,  0.01927098,  0.01926572,\n",
       "        0.01926552,  0.01924989,  0.01924972,  0.01924883,  0.0192418 ,\n",
       "        0.01921615,  0.01921586,  0.01921409,  0.01920834,  0.0192081 ,\n",
       "        0.01920422,  0.01920327,  0.01920289,  0.01920285,  0.0192023 ,\n",
       "        0.0192018 ,  0.01920172,  0.01920148,  0.0191999 ,  0.01919524,\n",
       "        0.019192  ,  0.01919196,  0.01918758,  0.01918514,  0.01918333,\n",
       "        0.01918276,  0.01918236,  0.01917988,  0.01917955,  0.0191778 ,\n",
       "        0.01917721,  0.01917715,  0.01917479,  0.01917303,  0.0191729 ,\n",
       "        0.0191715 ,  0.01917024,  0.0191672 ,  0.01915636,  0.01914793,\n",
       "        0.01914699,  0.01914498,  0.01914284,  0.01914249,  0.01914051,\n",
       "        0.01914034,  0.01913147,  0.01913147,  0.01913061,  0.01912959,\n",
       "        0.01912896,  0.01912886,  0.01912652,  0.01912652,  0.01912651,\n",
       "        0.01912651,  0.01912207,  0.0191205 ,  0.0191192 ,  0.0191172 ,\n",
       "        0.01911702,  0.0191107 ,  0.01910913,  0.01910646,  0.01910485,\n",
       "        0.0191045 ,  0.01910223,  0.01910199,  0.01910023,  0.01909525,\n",
       "        0.01908555,  0.01908279,  0.019081  ,  0.01908002,  0.01907659,\n",
       "        0.0190744 ,  0.01907438,  0.01907368,  0.01907368,  0.01907368,\n",
       "        0.01907368,  0.01906613,  0.01906232,  0.0190575 ,  0.01905739,\n",
       "        0.01905506,  0.01905064,  0.01904963,  0.01904841,  0.01904666,\n",
       "        0.01904665,  0.01904515,  0.01904507,  0.01904494,  0.01904235,\n",
       "        0.01903853,  0.0190352 ,  0.01903257,  0.01903035,  0.01902717,\n",
       "        0.01902605,  0.01902502,  0.01902335,  0.01902329,  0.01902319,\n",
       "        0.01902109,  0.01902093,  0.01901823,  0.01901717,  0.01901597,\n",
       "        0.01901586,  0.01901542,  0.01901433,  0.01901343,  0.01900807,\n",
       "        0.01900764,  0.01900528,  0.01900427,  0.01900311,  0.01900059,\n",
       "        0.01899954,  0.01899927,  0.01899886,  0.01899676,  0.01899548,\n",
       "        0.01899482,  0.01899432,  0.01899357,  0.01899259,  0.01898846,\n",
       "        0.0189884 ,  0.01898756,  0.01898567,  0.01898565,  0.01897985,\n",
       "        0.01897768,  0.01897707,  0.01897496,  0.01897467,  0.01897351,\n",
       "        0.0189716 ,  0.01897137,  0.01897085,  0.01896824,  0.01896767,\n",
       "        0.01896719,  0.01896622,  0.01896241,  0.01895912,  0.01895846,\n",
       "        0.01895749,  0.01895446,  0.0189544 ,  0.01895219,  0.0189502 ,\n",
       "        0.01894999,  0.01894974,  0.01894788,  0.01894686,  0.01894642,\n",
       "        0.0189452 ,  0.01894501,  0.01894375,  0.01894303,  0.01894289,\n",
       "        0.01894185,  0.01894144,  0.01894107,  0.01893849,  0.01893816,\n",
       "        0.01893799,  0.01893797,  0.01893784,  0.01893776,  0.01893776,\n",
       "        0.01893776,  0.01893776,  0.01893764,  0.01893719,  0.01893708,\n",
       "        0.01893644,  0.0189364 ,  0.01893631,  0.0189363 ,  0.0189362 ,\n",
       "        0.01893613,  0.01893587,  0.01893577,  0.0189357 ,  0.0189357 ,\n",
       "        0.0189357 ,  0.0189357 ,  0.0189357 ,  0.01893554,  0.01893554,\n",
       "        0.01893554,  0.01893554,  0.01893544,  0.01893527,  0.018935  ,\n",
       "        0.01893496,  0.01893495,  0.01893491,  0.01893489,  0.01893483,\n",
       "        0.01893482,  0.01893479,  0.01893478,  0.01893477,  0.01893477,\n",
       "        0.01893477,  0.01893477,  0.01893477,  0.01893477,  0.01893476,\n",
       "        0.01893476,  0.01893476,  0.01893476,  0.01893476,  0.01893476,\n",
       "        0.01893475,  0.01893474,  0.01893474,  0.01893473,  0.01893473,\n",
       "        0.01893472,  0.01893471,  0.0189347 ,  0.0189347 ,  0.0189347 ,\n",
       "        0.0189347 ,  0.0189347 ,  0.01893469,  0.01893468,  0.01893468,\n",
       "        0.01893467,  0.01893466,  0.01893465,  0.01893465,  0.01893465,\n",
       "        0.01893465,  0.01893464,  0.01893464,  0.01893464,  0.01893464,\n",
       "        0.01893463,  0.01893463,  0.01893463,  0.01893462,  0.01893462,\n",
       "        0.01893462,  0.01893461,  0.01893461,  0.0189346 ,  0.0189346 ,\n",
       "        0.01893459,  0.01893459,  0.01893458,  0.01893458,  0.01893457,\n",
       "        0.01893456,  0.01893456,  0.01893456,  0.01893456,  0.01893455,\n",
       "        0.01893455,  0.01893454,  0.01893454,  0.01893454,  0.01893454,\n",
       "        0.01893454,  0.01893453,  0.01893453,  0.01893451,  0.01893451,\n",
       "        0.01893451,  0.01893451,  0.0189345 ,  0.0189345 ,  0.0189345 ,\n",
       "        0.01893449,  0.01893449,  0.01893449,  0.01893447,  0.01893445,\n",
       "        0.01893445,  0.01893445,  0.01893445,  0.01893444,  0.01893444,\n",
       "        0.01893442,  0.01893441,  0.01893441,  0.01893441,  0.01893441,\n",
       "        0.01893441,  0.01893441,  0.01893441,  0.01893441,  0.0189344 ,\n",
       "        0.0189344 ,  0.01893439,  0.01893439,  0.01893438,  0.01893438,\n",
       "        0.01893437,  0.01893437,  0.01893437,  0.01893437,  0.01893437,\n",
       "        0.01893437,  0.01893437,  0.01893435,  0.01893435,  0.01893435,\n",
       "        0.01893435,  0.01893435,  0.01893435,  0.01893435,  0.01893434,\n",
       "        0.01893434,  0.01893432,  0.01893432,  0.01893432,  0.01893432,\n",
       "        0.01893432,  0.01893431,  0.01893431,  0.01893431,  0.01893431,\n",
       "        0.01893431,  0.01893431,  0.0189343 ,  0.0189343 ,  0.0189343 ,\n",
       "        0.0189343 ,  0.0189343 ,  0.0189343 ,  0.0189343 ,  0.0189343 ,\n",
       "        0.0189343 ,  0.01893429,  0.01893428,  0.01893428,  0.01893428,\n",
       "        0.01893428,  0.01893428,  0.01893428,  0.01893428,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427,\n",
       "        0.01893427,  0.01893427,  0.01893427,  0.01893427,  0.01893427])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_error[sort_index[:5000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1377b4748>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[large_error_index,0],X[large_error_index,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13391eef0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X[:,0],Y[:,4])\n",
    "plt.plot(X[:,0],pred[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x133588ba8>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Y[:,0],pred[:,0])\n",
    "plt.plot(Y[:,0],Y[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x12a6b0dd8>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[0:2000,0],Y[0:2000,4])\n",
    "plt.scatter(X[0:2000,0],pred[0:2000,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-600, 300, 1e-07, 100.0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0],rel_error)\n",
    "plt.yscale('log')\n",
    "plt.axis([-600,300,1e-7,1e2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-600, 300, 1e-07, 1.0]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0],rel_diff_seq)\n",
    "plt.yscale('log')\n",
    "plt.axis([-600,300,1e-7,1e0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-600, 300, 0.0001, 100000.0]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0],diff_seq)\n",
    "plt.yscale('log')\n",
    "plt.axis([-600,300,1e-4,1e5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x129197d30>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0],X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1291f1f98>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X[1000:2000,0],X[1000:2000,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
